# íŒ€ë³„ AI í”„ë¡œì íŠ¸ ì¢…í•© ê¸°ìˆ  ë¦¬ë·°

> **í‰ê°€ ì¼ì**: 2025ë…„ 12ì›” 3ì¼  
> **í‰ê°€ ëŒ€ìƒ**: 1íŒ€, 2íŒ€, 3íŒ€, 4íŒ€, 5íŒ€ (ì´ 5ê°œ íŒ€)  
> **í‰ê°€ ê´€ì **: ì½”ë“œ í’ˆì§ˆ, ë¼ì´ë¸ŒëŸ¬ë¦¬ ìµœì‹ ì„±, êµ¬ì¡°ì  ì„¤ê³„, ë³´ì•ˆ, ì„±ëŠ¥, ë¬¸ì„œí™”

---

## [1íŒ€] ì€í–‰ ê³ ê° ì´íƒˆ ì˜ˆì¸¡ í”„ë¡œì íŠ¸

### âœ… ì˜í•œ ì 

ì´ íŒ€ì€ í”„ë¡œì íŠ¸ì˜ ì‹¤ë¬´ ì ìš©ì„±ì„ ì˜ ê³ ë ¤í–ˆë‹¤. Streamlitì„ í™œìš©í•œ ëŒ€ì‹œë³´ë“œê°€ 1,289ë¼ì¸ì— ë‹¬í•  ì •ë„ë¡œ ì„¸ì‹¬í•˜ê²Œ êµ¬í˜„ë˜ì–´ ìˆê³ , ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ë„ ì§ê´€ì ìœ¼ë¡œ ì„¤ê³„ë˜ì–´ ìˆë‹¤. íŠ¹íˆ IQR ê¸°ë°˜ì˜ ì´ìƒì¹˜ íƒì§€ì™€ í¬ê·€ ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬ë¥¼ í•¨ìˆ˜í™”í•´ì„œ ì¬ì‚¬ìš©ì„±ì„ ë†’ì¸ ì ì´ ì¢‹ë‹¤. 

ëª¨ë¸ë§ ì¸¡ë©´ì—ì„œëŠ” 8ê°œì˜ ë‹¤ì–‘í•œ ì•Œê³ ë¦¬ì¦˜(Logistic Regression, RandomForest, KNN, SVC, DecisionTree, Bagging, NN, AdaBoost)ì„ ë¹„êµ í‰ê°€í–ˆê³ , `class_weight='balanced'` ì „ëµìœ¼ë¡œ í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œë¥¼ í•´ê²°í•˜ë ¤ê³  ì‹œë„í•œ ì ë„ ì‹¤ìš©ì ì´ë‹¤. Train/Test ì„±ëŠ¥ ë¹„êµë¥¼ í†µí•´ ê³¼ì í•© ì—¬ë¶€ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ê²€ì¦í•œ ë¶€ë¶„ë„ íƒ„íƒ„í•˜ë‹¤.

README ë¬¸ì„œë„ ìƒë‹¹íˆ ì˜ ì‘ì„±ë˜ì–´ ìˆë‹¤. íŒ€ì› ì†Œê°œë¶€í„° EDA ì‹œê°í™”, ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ, ìµœì¢… ì¸ì‚¬ì´íŠ¸ê¹Œì§€ í”„ë¡œì íŠ¸ì˜ ì „ì²´ íë¦„ì´ ëª…í™•í•˜ê²Œ ë³´ì¸ë‹¤.

### âŒ ë¬¸ì œì 

**ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ ëª…ì‹œ ëˆ„ë½**  
`requirements.txt`ì— ë¼ì´ë¸ŒëŸ¬ë¦¬ ì´ë¦„ë§Œ ë‚˜ì—´ë˜ì–´ ìˆê³  ë²„ì „ì´ í•˜ë‚˜ë„ ëª…ì‹œë˜ì§€ ì•Šì•˜ë‹¤. `numpy`, `pandas`, `scikit-learn`, `matplotlib` ë“± ëª¨ë“  íŒ¨í‚¤ì§€ê°€ ë²„ì „ ì—†ì´ ê¸°ë¡ë˜ì–´ ìˆì–´, ë‚˜ì¤‘ì— í™˜ê²½ì„ ì¬í˜„í•˜ë ¤ê³  í•  ë•Œ í˜¸í™˜ì„± ë¬¸ì œê°€ ë°œìƒí•  ê°€ëŠ¥ì„±ì´ í¬ë‹¤. íŠ¹íˆ scikit-learnì˜ ê²½ìš° ë²„ì „ë§ˆë‹¤ API ë³€ê²½ì´ ìˆì–´ì„œ íŠ¹ì • ë²„ì „ì„ ê³ ì •í•˜ì§€ ì•Šìœ¼ë©´ ì½”ë“œê°€ ê¹¨ì§ˆ ìˆ˜ ìˆë‹¤.

**ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ë¶€ì¬**  
Streamlit ì•±ì—ì„œ `LabelEncoder`ì™€ `StandardScaler`ë¥¼ ì‚¬ìš©í•˜ëŠ”ë°, ì´ê²Œ í•™ìŠµ ì‹œì™€ ì¶”ë¡  ì‹œì— ì¼ê´€ì„±ì´ ë³´ì¥ë˜ëŠ”ì§€ ë¶ˆë¶„ëª…í•˜ë‹¤. íŠ¹íˆ `fit_transform`ì„ ì—¬ëŸ¬ ê³³ì—ì„œ ë°˜ë³µ í˜¸ì¶œí•˜ê³  ìˆëŠ”ë°, í•™ìŠµ ë°ì´í„°ë¡œ fitëœ scaler/encoder ê°ì²´ë¥¼ ì €ì¥í•´ì„œ ì¬ì‚¬ìš©í•˜ëŠ” êµ¬ì¡°ê°€ ì•„ë‹ˆë¼ ë§¤ë²ˆ ìƒˆë¡œ fití•˜ëŠ” ê²ƒì²˜ëŸ¼ ë³´ì¸ë‹¤. ì´ëŸ¬ë©´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ì¼ê´€ëœ ë³€í™˜ì´ ë³´ì¥ë˜ì§€ ì•ŠëŠ”ë‹¤.

**í•˜ë“œì½”ë”©ëœ ê²½ë¡œì™€ íŒŒì¼ëª…**  
`'Bank Customer Churn Prediction.csv'`ì²˜ëŸ¼ íŒŒì¼ ê²½ë¡œê°€ í•˜ë“œì½”ë”©ë˜ì–´ ìˆê³ , ìƒëŒ€ ê²½ë¡œ ì²˜ë¦¬ë„ ëª…í™•í•˜ì§€ ì•Šë‹¤. ìš´ì˜ í™˜ê²½ì—ì„œëŠ” íŒŒì¼ ìœ„ì¹˜ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆëŠ”ë°, Path ê°ì²´ë¥¼ ì œëŒ€ë¡œ í™œìš©í•˜ì§€ ëª»í•˜ê³  ìˆë‹¤.

**ì˜ˆì™¸ ì²˜ë¦¬ ë¯¸ë¹„**  
íŒŒì¼ ë¡œë“œ í•¨ìˆ˜ì— `try-except`ê°€ ìˆê¸´ í•œë°, ì˜ˆì™¸ë¥¼ ì¡ì€ í›„ `st.error`ë¡œ ë©”ì‹œì§€ë§Œ ì¶œë ¥í•˜ê³  `None`ì„ ë¦¬í„´í•œë‹¤. ì´í›„ ì½”ë“œì—ì„œ `None` ì²´í¬ ì—†ì´ DataFrameì„ ì‚¬ìš©í•˜ë©´ ë°”ë¡œ í¬ë˜ì‹œê°€ ë‚  ìˆ˜ ìˆë‹¤.

**í…ŒìŠ¤íŠ¸ ì½”ë“œ ë¶€ì¬**  
ëª¨ë¸ì˜ ì„±ëŠ¥ ê²€ì¦ì€ ìˆì§€ë§Œ, ì „ì²˜ë¦¬ í•¨ìˆ˜ë‚˜ ì´ìƒì¹˜ íƒì§€ ë¡œì§ì— ëŒ€í•œ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ê°€ ì „í˜€ ì—†ë‹¤. ë¦¬íŒ©í† ë§ì´ë‚˜ ìœ ì§€ë³´ìˆ˜ ì‹œ íšŒê·€ ë²„ê·¸ê°€ ë°œìƒí•  ìœ„í—˜ì´ ìˆë‹¤.

### ğŸ”§ ê°œì„  ë°©í–¥

**1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ ê³ ì •**  
í˜„ì¬ ìš´ì˜ ì¤‘ì¸ í™˜ê²½ì—ì„œ `pip freeze > requirements.txt`ë¥¼ ì‹¤í–‰í•´ì„œ ì •í™•í•œ ë²„ì „ì„ ê³ ì •í•´ë¼. ìµœì†Œí•œ ë©”ì´ì € ë²„ì „ì´ë¼ë„ ëª…ì‹œí•´ì•¼ í•œë‹¤:
```
numpy==1.24.3
pandas==2.0.3
scikit-learn==1.3.2
matplotlib==3.7.2
seaborn==0.12.2
streamlit==1.28.0
```

**2. sklearn Pipeline ë„ì…**  
ì „ì²˜ë¦¬ì™€ ëª¨ë¸ì„ í•˜ë‚˜ì˜ Pipelineìœ¼ë¡œ ë¬¶ì–´ì„œ í•™ìŠµ ì‹œì™€ ì¶”ë¡  ì‹œì˜ ì¼ê´€ì„±ì„ ë³´ì¥í•´ë¼:
```python
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer

preprocessor = ColumnTransformer([
    ('num', StandardScaler(), numerical_cols),
    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)
])

model_pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(class_weight='balanced'))
])
```
ì´ë ‡ê²Œ í•˜ë©´ `model_pipeline.pkl` íŒŒì¼ í•˜ë‚˜ì— ì „ì²˜ë¦¬ì™€ ëª¨ë¸ì´ ëª¨ë‘ ì €ì¥ë˜ì–´ ì¬í˜„ì„±ì´ ë³´ì¥ëœë‹¤.

**3. ì„¤ì • íŒŒì¼ ë¶„ë¦¬**  
íŒŒì¼ ê²½ë¡œ, í”¼ì²˜ ì´ë¦„, í•˜ì´í¼íŒŒë¼ë¯¸í„° ë“±ì„ YAMLì´ë‚˜ JSON ì„¤ì • íŒŒì¼ë¡œ ë¶„ë¦¬í•´ë¼:
```python
# config.yaml
data:
  raw_path: "data/raw/Bank_Customer_Churn_Prediction.csv"
  processed_path: "data/processed/"
  
features:
  numerical: ["credit_score", "age", "balance", ...]
  categorical: ["gender", "country"]
```

**4. ê²¬ê³ í•œ ì˜ˆì™¸ ì²˜ë¦¬**  
```python
def load_data(filepath):
    try:
        if not Path(filepath).exists():
            raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filepath}")
        df = pd.read_csv(filepath)
        if df.empty:
            raise ValueError("ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        return df
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        st.stop()  # ì•± ì‹¤í–‰ ì¤‘ë‹¨
```

**5. ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì¶”ê°€**  
pytestë¥¼ ì¶”ê°€í•´ì„œ í•µì‹¬ ë¡œì§ì„ í…ŒìŠ¤íŠ¸í•´ë¼:
```python
def test_outlier_detection():
    test_df = pd.DataFrame({'age': [20, 25, 30, 100, 35]})
    outliers, lower, upper = detect_outliers_iqr(test_df, 'age')
    assert len(outliers) == 1
    assert outliers['age'].values[0] == 100
```

---

## [2íŒ€] í—¬ìŠ¤ì¥ íšŒì› ì´íƒˆ ì˜ˆì¸¡ ëª¨ë¸

### âœ… ì˜í•œ ì 

ì´ íŒ€ì€ 5ê°œ íŒ€ ì¤‘ ê°€ì¥ ì²´ê³„ì ì¸ í”„ë¡œì íŠ¸ êµ¬ì¡°ë¥¼ ë³´ì—¬ì¤¬ë‹¤. ë…¸íŠ¸ë¶ì´ EDA, Model Training, Model Evaluationìœ¼ë¡œ ëª…í™•í•˜ê²Œ ë¶„ë¦¬ë˜ì–´ ìˆê³ , ê° ë‹¨ê³„ì˜ ì‚°ì¶œë¬¼ë„ ë§ˆí¬ë‹¤ìš´ê³¼ PDFë¡œ ì˜ ì •ë¦¬ë˜ì–´ ìˆë‹¤. íŠ¹íˆ F1 Scoreë¥¼ 0.7373ì—ì„œ 0.9657ê¹Œì§€ ëŒì–´ì˜¬ë¦° ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ì¶”ì í•˜ê³  ë¬¸ì„œí™”í•œ ì ì´ ì¸ìƒì ì´ë‹¤.

ê¸°ìˆ ì ìœ¼ë¡œëŠ” SMOTEë¥¼ í™œìš©í•œ í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²°, 11ê°œì˜ íŒŒìƒ íŠ¹ì„± ìƒì„±(Lifetime_per_Month, Is_New_Member, Class_Engagement ë“±), RandomizedSearchCVë¥¼ í†µí•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹, ê·¸ë¦¬ê³  Ultimate Stacking Ensembleê¹Œì§€ ê³ ê¸‰ ê¸°ë²•ë“¤ì„ ì ì ˆíˆ í™œìš©í–ˆë‹¤. íŠ¹íˆ XGBoostì™€ LightGBMì„ 50íšŒì”© íŠœë‹í•´ì„œ 30% ì´ìƒì˜ ì„±ëŠ¥ í–¥ìƒì„ ë‹¬ì„±í•œ ê±´ í›Œë¥­í•˜ë‹¤.

READMEë„ êµ‰ì¥íˆ ìƒì„¸í•˜ë‹¤. í”„ë¡œì íŠ¸ êµ¬ì¡°, ê¸°ìˆ  ìŠ¤íƒ, ì„¤ì¹˜ ë°©ë²•, ì‹¤í–‰ ê°€ì´ë“œ, ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ê¹Œì§€ ì‹¤ë¬´ì—ì„œ ë°”ë¡œ ì“¸ ìˆ˜ ìˆì„ ë§Œí¼ ì™„ì„±ë„ê°€ ë†’ë‹¤.

### âŒ ë¬¸ì œì 

**ë¼ì´ë¸ŒëŸ¬ë¦¬ ì˜ì¡´ì„± ê´€ë¦¬ ë¶€ì¬**  
ì•„ì´ëŸ¬ë‹ˆí•˜ê²Œë„ ì´ë ‡ê²Œ ì™„ì„±ë„ ë†’ì€ í”„ë¡œì íŠ¸ì¸ë° `requirements.txt`ê°€ ì•„ì˜ˆ ì—†ë‹¤. READMEì— "í•„ìš”í•œ íŒ¨í‚¤ì§€"ë¡œ í…ìŠ¤íŠ¸ë§Œ ë‚˜ì—´ë˜ì–´ ìˆëŠ”ë°, ë²„ì „ ì •ë³´ê°€ ì „í˜€ ì—†ë‹¤. `tensorflow >= 2.13.0` ê°™ì€ ì‹ìœ¼ë¡œ ìµœì†Œ ë²„ì „ë§Œ ì–¸ê¸‰í–ˆëŠ”ë°, ì‹¤ì œë¡œëŠ” ë” êµ¬ì²´ì ì¸ ë²„ì „ ê³ ì •ì´ í•„ìš”í•˜ë‹¤.

**ëª¨ë¸ íŒŒì¼ ê²½ë¡œ í•˜ë“œì½”ë”©**  
`'project/models/2024_churn_model/stacking_ultimate.pkl'` ê°™ì€ ê²½ë¡œê°€ í•˜ë“œì½”ë”©ë˜ì–´ ìˆë‹¤. ì´ëŸ° ì ˆëŒ€ ê²½ë¡œëŠ” ë‹¤ë¥¸ í™˜ê²½ì—ì„œ ì‹¤í–‰í•  ë•Œ ë¬¸ì œê°€ ëœë‹¤. íŠ¹íˆ Streamlit ë°°í¬ ì‹œ ê²½ë¡œ êµ¬ì¡°ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆë‹¤.

**ëŒ€ìš©ëŸ‰ ëª¨ë¸ íŒŒì¼ ê´€ë¦¬**  
`nn_model.h5`, `stacking_ultimate.pkl` ë“± í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ë“¤ì´ Gitì— í¬í•¨ë˜ì–´ ìˆì„ ê°€ëŠ¥ì„±ì´ ìˆë‹¤(í™•ì¸ í•„ìš”). ëª¨ë¸ íŒŒì¼ì€ ìš©ëŸ‰ì´ í¬ê¸° ë•Œë¬¸ì— Git LFSë‚˜ ë³„ë„ ìŠ¤í† ë¦¬ì§€ë¥¼ ì‚¬ìš©í•´ì•¼ í•œë‹¤.

**Deprecated TensorFlow API ì‚¬ìš© ê°€ëŠ¥ì„±**  
TensorFlow 2.13+ë¥¼ ì‚¬ìš©í•œë‹¤ê³  í–ˆëŠ”ë°, ë…¸íŠ¸ë¶ì—ì„œ `model.fit()` í˜¸ì¶œ ì‹œ `validation_split` ê°™ì€ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ì´ ìµœì‹  ê¶Œì¥ì‚¬í•­ê³¼ ë§ëŠ”ì§€ í™•ì¸ì´ í•„ìš”í•˜ë‹¤. TensorFlow 2.xì—ì„œëŠ” `tf.keras.callbacks`ì™€ `tf.data` API ì‚¬ìš©ì´ ê¶Œì¥ëœë‹¤.

**ì„±ëŠ¥ ìµœì í™” ì—¬ì§€**  
Stacking Ensembleì— 4ê°œì˜ Base ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ”ë°, ì¶”ë¡  ì‹œ 4ê°œ ëª¨ë¸ì„ ëª¨ë‘ ë¡œë“œí•˜ê³  ì‹¤í–‰í•´ì•¼ í•´ì„œ ë©”ëª¨ë¦¬ì™€ ì‘ë‹µ ì‹œê°„ ì¸¡ë©´ì—ì„œ ë¹„íš¨ìœ¨ì ì¼ ìˆ˜ ìˆë‹¤. ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” ë‹¨ì¼ ìµœì  ëª¨ë¸ì´ë‚˜ ê²½ëŸ‰í™”ëœ ì•™ìƒë¸”ì´ ë” ë‚˜ì„ ìˆ˜ë„ ìˆë‹¤.

### ğŸ”§ ê°œì„  ë°©í–¥

**1. requirements.txt ìƒì„± ë° ë²„ì „ ê³ ì •**  
í˜„ì¬ í™˜ê²½ì—ì„œ ì •í™•í•œ ë²„ì „ì„ ì¶”ì¶œí•´ì„œ ê³ ì •í•´ë¼:
```
pandas==2.0.3
numpy==1.24.3
scikit-learn==1.3.2
xgboost==2.0.3
lightgbm==4.1.0
tensorflow==2.15.0
imbalanced-learn==0.11.0
matplotlib==3.8.2
seaborn==0.13.0
streamlit==1.29.0
```

**2. í™˜ê²½ ë³€ìˆ˜ì™€ ê²½ë¡œ ê´€ë¦¬**  
`.env` íŒŒì¼ê³¼ `python-dotenv`ë¥¼ ì‚¬ìš©í•´ì„œ ê²½ë¡œë¥¼ ê´€ë¦¬í•´ë¼:
```python
# .env
MODEL_DIR=./models/2024_churn_model
DATA_DIR=./data

# ì½”ë“œì—ì„œ
from dotenv import load_dotenv
import os
load_dotenv()
model_path = os.getenv('MODEL_DIR') + '/stacking_ultimate.pkl'
```

**3. Git LFS ì„¤ì •**  
ëŒ€ìš©ëŸ‰ ëª¨ë¸ íŒŒì¼ì€ Git LFSë¡œ ê´€ë¦¬í•´ë¼:
```bash
git lfs install
git lfs track "*.pkl"
git lfs track "*.h5"
git add .gitattributes
```

**4. TensorFlow ìµœì‹  API í™œìš©**  
ì½œë°±ê³¼ ë°ì´í„° íŒŒì´í”„ë¼ì¸ì„ í˜„ëŒ€ì ì¸ ë°©ì‹ìœ¼ë¡œ ì‘ì„±í•´ë¼:
```python
early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True
)

model.fit(
    train_dataset,  # tf.data.Dataset ì‚¬ìš©
    validation_data=val_dataset,
    epochs=100,
    callbacks=[early_stopping]
)
```

**5. ëª¨ë¸ ì„œë¹™ ìµœì í™”**  
ì‹¤ì‹œê°„ ì¶”ë¡ ì´ í•„ìš”í•˜ë©´ ê²½ëŸ‰í™”ë¥¼ ê³ ë ¤í•´ë¼:
- ì•™ìƒë¸”ì˜ Top 1-2 ëª¨ë¸ë§Œ ì‚¬ìš©
- ONNXë¡œ ë³€í™˜í•´ì„œ ì¶”ë¡  ì†ë„ í–¥ìƒ
- ëª¨ë¸ ì–‘ìí™”(Quantization) ì ìš©
```python
import onnxruntime as ort
# sklearn ëª¨ë¸ì„ ONNXë¡œ ë³€í™˜
from skl2onnx import convert_sklearn
onnx_model = convert_sklearn(model, ...)
```

**6. ë¡œê¹… ì¶”ê°€**  
ìš´ì˜ í™˜ê²½ì—ì„œëŠ” ë¡œê¹…ì´ í•„ìˆ˜ë‹¤:
```python
import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

logger.info(f"Model loaded from {model_path}")
logger.warning(f"Low confidence prediction: {proba}")
```

---

## [3íŒ€] ì¸í„°ë„· ê³ ê° ì´íƒˆ ë¶„ì„

### âœ… ì˜í•œ ì 

ì´ íŒ€ì€ ë”¥ëŸ¬ë‹ ì‹¤í—˜ì„ êµ‰ì¥íˆ ë‹¤ì–‘í•˜ê²Œ ì‹œë„í–ˆë‹¤. PyTorch MLP, sklearn MLPClassifier, TensorFlow ëª¨ë¸ê¹Œì§€ 3ê°€ì§€ í”„ë ˆì„ì›Œí¬ë¥¼ ëª¨ë‘ ë‹¤ë¤„ë´¤ê³ , íŠ¹íˆ `torch_model_randomsearch.ipynb`ì—ì„œ PyTorchë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ê¹Œì§€ êµ¬í˜„í•œ ê±´ ì˜ìš•ì´ ë‹ë³´ì¸ë‹¤. 

MLê³¼ DL ë””ë ‰í† ë¦¬ë¥¼ ë¶„ë¦¬í•´ì„œ ì „í†µì  ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ ì ‘ê·¼ì„ ëª¨ë‘ ì‹œë„í•œ ì ë„ ì¢‹ë‹¤. ë°ì´í„° ì „ì²˜ë¦¬ì™€ EDAë„ ë³„ë„ë¡œ ë…¸íŠ¸ë¶ì„ ë§Œë“¤ì–´ì„œ ì •ë¦¬í–ˆê³ , ê° ë‹¨ê³„ì˜ PDF ì‚°ì¶œë¬¼ë„ ì˜ ì¤€ë¹„ë˜ì–´ ìˆë‹¤.

### âŒ ë¬¸ì œì 

**Python ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ë¶€ì¬**  
ëª¨ë“  ì½”ë“œê°€ Jupyter ë…¸íŠ¸ë¶ìœ¼ë¡œë§Œ ì¡´ì¬í•œë‹¤. ì‹¤ë¬´ì—ì„œëŠ” ë…¸íŠ¸ë¶ì„ ëª¨ë“ˆí™”ëœ Python ìŠ¤í¬ë¦½íŠ¸ë¡œ ë³€í™˜í•´ì•¼ í•˜ëŠ”ë°, ê·¸ ë‹¨ê³„ê°€ ì™„ì „íˆ ë¹ ì ¸ ìˆë‹¤. Streamlitì´ë‚˜ FastAPI ê°™ì€ ë°°í¬ ì¸í„°í˜ì´ìŠ¤ë„ ì—†ë‹¤.

**requirements.txt ì—†ìŒ**  
5íŒ€ ì¤‘ì—ì„œ ìœ ì¼í•˜ê²Œ ì˜ì¡´ì„± ê´€ë¦¬ íŒŒì¼ì´ ì•„ì˜ˆ ì—†ë‹¤. PyTorch, TensorFlow, scikit-learnì„ ëª¨ë‘ ì‚¬ìš©í–ˆëŠ”ë°, ì–´ë–¤ ë²„ì „ì„ ì‚¬ìš©í–ˆëŠ”ì§€ ì „í˜€ ì•Œ ìˆ˜ ì—†ë‹¤. ì´ê±´ ì¬í˜„ì„± ì¸¡ë©´ì—ì„œ ì¹˜ëª…ì ì´ë‹¤.

**ì½”ë“œ ì¤‘ë³µê³¼ ëª¨ë“ˆí™” ë¶€ì¡±**  
ë¹„ìŠ·í•œ ì „ì²˜ë¦¬ ë¡œì§ì´ ì—¬ëŸ¬ ë…¸íŠ¸ë¶ì— ë°˜ë³µë˜ì–´ ìˆë‹¤. `data_preprocessing_ml.ipynb`ì™€ `data_preprocessing_tree_EDA.ipynb`ì— ì¤‘ë³µ ì½”ë“œê°€ ë§ì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤. ê³µí†µ í•¨ìˆ˜ë¥¼ ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆë¡œ ë¶„ë¦¬í•˜ì§€ ì•Šì•˜ë‹¤.

**PyTorchì™€ TensorFlow í˜¼ìš©ì˜ ë¹„íš¨ìœ¨**  
ë‘ í”„ë ˆì„ì›Œí¬ë¥¼ ë™ì‹œì— ì‚¬ìš©í•˜ëŠ” ê±´ ì¢‹ì€ë°, ì™œ ë‘˜ ë‹¤ í•„ìš”í•œì§€ ëª…í™•í•œ ì´ìœ ê°€ ì—†ë‹¤. ê°ê°ì˜ ì¥ë‹¨ì ì„ ë¹„êµ ë¶„ì„í–ˆë‹¤ë©´ ì¢‹ì•˜ì„ í…ë°, ë‹¨ìˆœíˆ ì‹¤í—˜ë§Œ í•œ ê²ƒì²˜ëŸ¼ ë³´ì¸ë‹¤. ì‹¤ë¬´ì—ì„œëŠ” í•˜ë‚˜ë¥¼ ì„ íƒí•´ì„œ ê¹Šê²Œ íŒŒëŠ” ê²Œ ë” ë‚«ë‹¤.

**í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ì˜ ë¹„ì²´ê³„ì„±**  
`randomsearch`ë¥¼ ìˆ˜ë™ìœ¼ë¡œ êµ¬í˜„í•œ ê²ƒ ê°™ì€ë°, Optunaë‚˜ Ray Tune ê°™ì€ ì „ë¬¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì“°ëŠ” ê²Œ í›¨ì”¬ íš¨ìœ¨ì ì´ë‹¤. íŠ¹íˆ PyTorch ëª¨ë¸ì˜ ê²½ìš° Early Stopping, Learning Rate Scheduling ê°™ì€ ëª¨ë²” ì‚¬ë¡€ê°€ ì ìš©ë˜ì—ˆëŠ”ì§€ ë¶ˆë¶„ëª…í•˜ë‹¤.

**ë¬¸ì„œí™” ë¶€ì¡±**  
EDA ë³´ê³ ì„œëŠ” ìˆëŠ”ë°, ëª¨ë¸ ì„ íƒ ê·¼ê±°ë‚˜ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼ê°€ READMEì— ëª…í™•í•˜ê²Œ ì •ë¦¬ë˜ì–´ ìˆì§€ ì•Šë‹¤. ì–´ë–¤ ëª¨ë¸ì´ ìµœì¢…ì ìœ¼ë¡œ ì„ íƒë˜ì—ˆëŠ”ì§€, ì™œ ì„ íƒë˜ì—ˆëŠ”ì§€ ì•Œê¸° ì–´ë µë‹¤.

### ğŸ”§ ê°œì„  ë°©í–¥

**1. ì½”ë“œ ëª¨ë“ˆí™” ë° íŒ¨í‚¤ì§•**  
ë…¸íŠ¸ë¶ì˜ í•µì‹¬ ë¡œì§ì„ Python ëª¨ë“ˆë¡œ ë¶„ë¦¬í•´ë¼:
```
project/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ cleaner.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ ml_models.py
â”‚   â”‚   â””â”€â”€ dl_models.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ evaluation.py
â”œâ”€â”€ notebooks/  # ì‹¤í—˜ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©
â””â”€â”€ app/  # Streamlit ë˜ëŠ” API
```

**2. ì˜ì¡´ì„± ëª…ì‹œ ë° í™˜ê²½ ê´€ë¦¬**  
PyTorchì™€ TensorFlowë¥¼ ëª¨ë‘ ì“´ë‹¤ë©´ ë²„ì „ í˜¸í™˜ì„±ì— ì£¼ì˜í•´ë¼:
```
torch==2.1.0
torchvision==0.16.0
tensorflow==2.15.0
scikit-learn==1.3.2
numpy==1.24.3
pandas==2.0.3
optuna==3.4.0  # í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ìš©
```

**3. í”„ë ˆì„ì›Œí¬ í†µì¼ ë˜ëŠ” ëª…í™•í•œ ë¶„ë¦¬**  
PyTorchì™€ TensorFlowë¥¼ ë‘˜ ë‹¤ ì“¸ ê±°ë©´ ê°ê°ì˜ ì‚¬ìš© ëª©ì ì„ ëª…í™•íˆ í•´ë¼:
- PyTorch: ì—°êµ¬ìš© í”„ë¡œí† íƒ€ì´í•‘, ì»¤ìŠ¤í…€ êµ¬ì¡° ì‹¤í—˜
- TensorFlow: í”„ë¡œë•ì…˜ ë°°í¬, TF Serving í™œìš©

ë˜ëŠ” í•˜ë‚˜ë¡œ í†µì¼í•´ì„œ ê¹Šì´ ìˆê²Œ ìµœì í™”í•˜ëŠ” ê²Œ ë‚˜ì„ ìˆ˜ë„ ìˆë‹¤.

**4. Optuna ë„ì…**  
í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì€ Optunaë¡œ ì²´ê³„í™”í•´ë¼:
```python
import optuna

def objective(trial):
    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)
    hidden_size = trial.suggest_int('hidden_size', 32, 512)
    
    model = MLP(hidden_size=hidden_size)
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    
    # í•™ìŠµ ë° ê²€ì¦
    val_loss = train_and_evaluate(model, optimizer)
    return val_loss

study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=100)
```

**5. MLflowë¡œ ì‹¤í—˜ ê´€ë¦¬**  
ì—¬ëŸ¬ ì‹¤í—˜ì„ ì²´ê³„ì ìœ¼ë¡œ íŠ¸ë˜í‚¹í•´ë¼:
```python
import mlflow

with mlflow.start_run():
    mlflow.log_params({"lr": 0.001, "hidden_size": 128})
    mlflow.log_metric("val_loss", val_loss)
    mlflow.pytorch.log_model(model, "model")
```

**6. README ê°œì„ **  
ìµœì¢… ëª¨ë¸ ì„ íƒ ê·¼ê±°ì™€ ì„±ëŠ¥ ë¹„êµí‘œë¥¼ ëª…í™•íˆ ì‘ì„±í•´ë¼:
```markdown
## ëª¨ë¸ ë¹„êµ ê²°ê³¼

| ëª¨ë¸ | Framework | F1 Score | í•™ìŠµ ì‹œê°„ | ì¶”ë¡  ì‹œê°„ |
|------|-----------|----------|-----------|-----------|
| Logistic Regression | sklearn | 0.82 | 1s | <1ms |
| Random Forest | sklearn | 0.85 | 30s | 5ms |
| MLP (sklearn) | sklearn | 0.83 | 15s | 2ms |
| MLP (PyTorch) | PyTorch | 0.87 | 120s | 3ms |
| CNN (TensorFlow) | TensorFlow | 0.84 | 180s | 4ms |

**ìµœì¢… ì„ íƒ**: PyTorch MLP (F1=0.87, ì¶”ë¡  ì†ë„ ì–‘í˜¸)
```

**7. ë°°í¬ ì¸í„°í˜ì´ìŠ¤ ì¶”ê°€**  
ìµœì†Œí•œ Streamlit ì•±ì´ë¼ë„ ë§Œë“¤ì–´ë¼:
```python
# app.py
import streamlit as st
import torch
from src.models.dl_models import MLP

model = MLP.load_from_checkpoint('best_model.pth')

st.title("ê³ ê° ì´íƒˆ ì˜ˆì¸¡")
features = st.form("input_form")
# ... ì…ë ¥ ë°›ê¸°
prediction = model.predict(features)
st.write(f"ì´íƒˆ í™•ë¥ : {prediction:.2%}")
```

---

## [4íŒ€] ê³ ê° ì´íƒˆ ì˜ˆì¸¡ (ë³´í—˜/ê¸ˆìœµ)

### âœ… ì˜í•œ ì 

ì´ íŒ€ì€ ì½”ë“œ í’ˆì§ˆ ë©´ì—ì„œ ê°€ì¥ ìš°ìˆ˜í•˜ë‹¤. Type Hintsë¥¼ ì œëŒ€ë¡œ ì‚¬ìš©í–ˆê³ (`typing.Any, Dict, List, Optional` ë“±), Streamlit ì½”ë“œì—ì„œ `ColumnTransformer`, `Pipeline` ê°™ì€ scikit-learn ëª¨ë²” ì‚¬ë¡€ë¥¼ ì •í™•íˆ ì ìš©í–ˆë‹¤. íŠ¹íˆ `OneHotEncoder(handle_unknown='ignore')`ë¥¼ ì¨ì„œ ë¯¸ì§€ì˜ ì¹´í…Œê³ ë¦¬ë¥¼ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•œ ì ì´ ì¢‹ë‹¤.

requirements.txtë„ ë²„ì „ì„ ëª…í™•íˆ ëª…ì‹œí–ˆë‹¤. `pandas==2.0.3`, `scikit-learn==1.3.0`, `xgboost==1.7.6` ë“± ë©”ì´ì € ë²„ì „ê¹Œì§€ ê³ ì •ë˜ì–´ ìˆì–´ í™˜ê²½ ì¬í˜„ì´ ì‰½ë‹¤. SHAPì„ ì‚¬ìš©í•œ ëª¨ë¸ í•´ì„ ê°€ëŠ¥ì„± í™•ë³´ë„ í›Œë¥­í•˜ë‹¤.

ë…¸íŠ¸ë¶ë„ ì—­í• ë³„ë¡œ ì˜ ë¶„ë¦¬ë˜ì–´ ìˆë‹¤: EDA, Model Training Pipeline, Model Evaluation. ê° ë‹¨ê³„ì˜ ì‚°ì¶œë¬¼ë„ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ê¹”ë”í•˜ê²Œ ì •ë¦¬ë˜ì–´ ìˆë‹¤.

### âŒ ë¬¸ì œì 

**ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ì´ ë‹¤ì†Œ êµ¬ì‹**  
`xgboost==1.7.6`ëŠ” 2023ë…„ ì´ˆ ë²„ì „ì´ë‹¤. ìµœì‹  ë²„ì „ì€ 2.0.3ì¸ë°, 1.x ëŒ€ ì‚¬ìš©ìœ¼ë¡œ ì„±ëŠ¥ ê°œì„ ê³¼ ìƒˆë¡œìš´ ê¸°ëŠ¥ì„ ëª» ì“°ê³  ìˆë‹¤. `lightgbm==4.0.0`ë„ ë§ˆì°¬ê°€ì§€ë¡œ ìµœì‹ ì€ 4.1.0+ì´ë‹¤. 

`streamlit==1.25.0`ë„ ê½¤ ì˜›ë‚  ë²„ì „ì´ë‹¤. ìµœì‹  Streamlit(1.28+)ì—ëŠ” `st.fragment`, `st.dialog` ê°™ì€ ìœ ìš©í•œ ê¸°ëŠ¥ì´ ì¶”ê°€ë˜ì—ˆëŠ”ë° í™œìš©í•˜ì§€ ëª»í•˜ê³  ìˆë‹¤.

**imbalanced-learn ì‚¬ìš© ì—¬ë¶€ ë¶ˆëª…í™•**  
requirements.txtì—ëŠ” `imbalanced-learn==0.11.0`ì´ ìˆëŠ”ë°, ì‹¤ì œ ì½”ë“œì—ì„œ SMOTEë‚˜ ADASYNì„ ì‚¬ìš©í–ˆëŠ”ì§€ í™•ì¸ì´ í•„ìš”í•˜ë‹¤. ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì˜ì¡´ì„±ì— í¬í•¨ì‹œí‚¤ëŠ” ê±´ ë¶ˆí•„ìš”í•œ ìš©ëŸ‰ ë‚­ë¹„ë‹¤.

**Joblib ëŒ€ì‹  Pickle ê³ ë ¤**  
ëª¨ë¸ ì €ì¥ì— `joblib`ì„ ì“°ëŠ” ê±´ ì¢‹ì€ë°, scikit-learn 1.3+ë¶€í„°ëŠ” ìì²´ `sklearn.externals.joblib`ì´ deprecatedë˜ê³  ë…ë¦½ joblib ì‚¬ìš©ì´ ê¶Œì¥ëœë‹¤. ì´ë¯¸ ê·¸ë ‡ê²Œ í•˜ê³  ìˆë‹¤ë©´ ë¬¸ì œì—†ì§€ë§Œ, ì½”ë“œì—ì„œ í™•ì¸ì´ í•„ìš”í•˜ë‹¤.

**ì—ëŸ¬ í•¸ë“¤ë§ ë¶€ì¡±**  
Pipelineì„ ì‚¬ìš©í•˜ëŠ” ê±´ ì¢‹ì€ë°, Pipeline ì‹¤í–‰ ì¤‘ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì˜ˆì™¸(ì˜ˆ: ìƒˆë¡œìš´ ì¹´í…Œê³ ë¦¬ ê°’, ê²°ì¸¡ì¹˜ ë“±)ì— ëŒ€í•œ í•¸ë“¤ë§ ë¡œì§ì´ ë¶€ì¡±í•´ ë³´ì¸ë‹¤. `handle_unknown='ignore'`ëŠ” ìˆì§€ë§Œ, ê·¸ ì™¸ edge case ì²˜ë¦¬ê°€ ëª…í™•í•˜ì§€ ì•Šë‹¤.

**ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë¶€ì¬**  
SHAPìœ¼ë¡œ í•´ì„ì€ í•˜ëŠ”ë°, ëª¨ë¸ì˜ ì‹¤ì‹œê°„ ì„±ëŠ¥(ì¶”ë¡  ì†ë„, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰) ëª¨ë‹ˆí„°ë§ì€ ì—†ë‹¤. í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” ì´ëŸ° ë©”íŠ¸ë¦­ë„ ì¤‘ìš”í•˜ë‹¤.

### ğŸ”§ ê°œì„  ë°©í–¥

**1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ ì—…ë°ì´íŠ¸**  
ìµœì‹  ì•ˆì • ë²„ì „ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œí•´ë¼:
```
pandas==2.1.4
numpy==1.26.2
scikit-learn==1.3.2
xgboost==2.0.3  # ì£¼ìš” ì—…ê·¸ë ˆì´ë“œ
lightgbm==4.1.0
matplotlib==3.8.2
seaborn==0.13.0
streamlit==1.29.0  # ìƒˆ ê¸°ëŠ¥ í™œìš© ê°€ëŠ¥
plotly==5.18.0
shap==0.43.0
```

ì—…ê·¸ë ˆì´ë“œ í›„ í…ŒìŠ¤íŠ¸ë¥¼ ëŒë ¤ì„œ API ë³€ê²½ì‚¬í•­ì´ ì—†ëŠ”ì§€ í™•ì¸í•´ë¼.

**2. ì˜ì¡´ì„± ê°ì‚¬ (Dependency Audit)**  
ì‹¤ì œë¡œ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ì œê±°í•´ra:
```python
# ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” import ì°¾ê¸°
pip install pipreqs
pipreqs . --force  # ì‹¤ì œ ì‚¬ìš©ëœ íŒ¨í‚¤ì§€ë§Œ ì¶”ì¶œ
```

**3. ê²¬ê³ í•œ Pipeline ì—ëŸ¬ í•¸ë“¤ë§**  
```python
from sklearn.pipeline import Pipeline
from sklearn.base import BaseEstimator, TransformerMixin

class SafeTransformer(BaseEstimator, TransformerMixin):
    def __init__(self, transformer):
        self.transformer = transformer
    
    def fit(self, X, y=None):
        try:
            self.transformer.fit(X, y)
        except Exception as e:
            logger.error(f"Transformer fit failed: {e}")
            raise
        return self
    
    def transform(self, X):
        try:
            return self.transformer.transform(X)
        except Exception as e:
            logger.error(f"Transform failed: {e}")
            # ê¸°ë³¸ê°’ìœ¼ë¡œ ëŒ€ì²´í•˜ê±°ë‚˜ ì˜ˆì™¸ ì¬ë°œìƒ
            raise
```

**4. ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ì¶”ê°€**  
ì¶”ë¡  ì‹œê°„ê³¼ ë©”ëª¨ë¦¬ë¥¼ ì¸¡ì •í•´ë¼:
```python
import time
import psutil
import streamlit as st

start_time = time.time()
memory_before = psutil.virtual_memory().used / 1024**2

prediction = pipeline.predict(input_df)[0]

memory_after = psutil.virtual_memory().used / 1024**2
elapsed_time = time.time() - start_time

st.sidebar.metric("ì¶”ë¡  ì‹œê°„", f"{elapsed_time*1000:.1f}ms")
st.sidebar.metric("ë©”ëª¨ë¦¬ ì‚¬ìš©", f"{memory_after - memory_before:.1f}MB")
```

**5. XGBoost 2.0 ì‹ ê¸°ëŠ¥ í™œìš©**  
XGBoost 2.0ì—ì„œëŠ” ìƒˆë¡œìš´ `device='cuda'` íŒŒë¼ë¯¸í„°ì™€ ê°œì„ ëœ categorical feature ì§€ì›ì´ ìˆë‹¤:
```python
from xgboost import XGBClassifier

model = XGBClassifier(
    device='cuda',  # GPU ì‚¬ìš© (ìˆìœ¼ë©´)
    enable_categorical=True,  # ë²”ì£¼í˜• ì§ì ‘ ì§€ì›
    tree_method='hist',  # ë¹ ë¥¸ íˆìŠ¤í† ê·¸ë¨ ê¸°ë°˜
)
```

**6. Streamlit ìµœì‹  ê¸°ëŠ¥ í™œìš©**  
Streamlit 1.28+ì˜ ìƒˆ ê¸°ëŠ¥ì„ ì¨ë¼:
```python
# Fragmentë¡œ ë¶€ë¶„ ì¬ì‹¤í–‰
@st.fragment
def prediction_section():
    if st.button("ì˜ˆì¸¡ ì‹¤í–‰"):
        result = model.predict(...)
        st.write(result)

# Dialogë¡œ ëª¨ë‹¬ íŒì—…
@st.dialog("ì˜ˆì¸¡ ê²°ê³¼ ìƒì„¸")
def show_details():
    st.write("ìƒì„¸ ë¶„ì„...")
```

**7. ëª¨ë¸ ë©”íƒ€ë°ì´í„° ì €ì¥**  
ëª¨ë¸ê³¼ í•¨ê»˜ ë©”íƒ€ë°ì´í„°ë¥¼ ì €ì¥í•´ì„œ ë²„ì „ ê´€ë¦¬ë¥¼ ëª…í™•íˆ í•´ë¼:
```python
import joblib
from datetime import datetime

model_metadata = {
    'model_version': '1.0.0',
    'trained_date': datetime.now().isoformat(),
    'sklearn_version': sklearn.__version__,
    'xgboost_version': xgboost.__version__,
    'feature_names': X_train.columns.tolist(),
    'metrics': {'f1': 0.89, 'auc': 0.92}
}

joblib.dump({
    'model': pipeline,
    'metadata': model_metadata
}, 'model_with_metadata.pkl')
```

---

## [5íŒ€] Netflix ê³ ê° ì´íƒˆ ì˜ˆì¸¡

### âœ… ì˜í•œ ì 

ì´ íŒ€ì€ í”„ë¡œì íŠ¸ êµ¬ì¡°í™”ì™€ ëª¨ë“ˆí™”ì—ì„œ ê°€ì¥ ìš°ìˆ˜í•˜ë‹¤. `streamlit_netflix/utils/`ì— `model_utils.py`, `preprocessing_utils.py`, `styles.py`ë¥¼ ë¶„ë¦¬í•´ì„œ ê´€ì‹¬ì‚¬ë¥¼ ëª…í™•íˆ êµ¬ë¶„í–ˆë‹¤. Streamlit ë©€í‹°í˜ì´ì§€ ì•± êµ¬ì¡°ë„ ì œëŒ€ë¡œ êµ¬í˜„í–ˆë‹¤(`pages/` ë””ë ‰í† ë¦¬ í™œìš©).

requirements.txtë„ ìµœì†Œ ë²„ì „ì„ ëª…ì‹œí•˜ë©´ì„œ ìœ ì—°ì„±ì„ í™•ë³´í–ˆë‹¤(`>=` ì‚¬ìš©). Optunaë¥¼ ì˜ì¡´ì„±ì— í¬í•¨ì‹œí‚¨ ê²ƒë„ ì¢‹ë‹¤ - í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ ì œëŒ€ë¡œ í•˜ë ¤ëŠ” ì˜ì§€ê°€ ë³´ì¸ë‹¤.

READMEë„ ë¹„ì£¼ì–¼ì´ í’ë¶€í•˜ê³ , íŒ€ ì†Œê°œë¶€í„° ê¸°ìˆ  ìŠ¤íƒê¹Œì§€ ë§ˆì¼€íŒ… ìë£Œì²˜ëŸ¼ ì˜ ë§Œë“¤ì–´ì ¸ ìˆë‹¤. Netflix í…Œë§ˆë¥¼ ì‚´ë¦° UI ìŠ¤íƒ€ì¼ë§ë„ ì„¸ì‹¬í•˜ë‹¤.

### âŒ ë¬¸ì œì 

**ìµœì†Œ ë²„ì „ ëª…ì‹œì˜ ìœ„í—˜ì„±**  
`numpy>=1.21.0` ê°™ì€ ì‹ìœ¼ë¡œ ìµœì†Œ ë²„ì „ë§Œ ëª…ì‹œí–ˆëŠ”ë°, ì´ê²Œ ì–‘ë‚ ì˜ ê²€ì´ë‹¤. ìµœì‹  ë²„ì „ìœ¼ë¡œ ìë™ ì—…ê·¸ë ˆì´ë“œë  ë•Œ breaking changeê°€ ìˆìœ¼ë©´ ì½”ë“œê°€ ê¹¨ì§ˆ ìˆ˜ ìˆë‹¤. íŠ¹íˆ numpy 2.0ì´ ë‚˜ì˜¤ë©´ì„œ ë§ì€ APIê°€ ë³€ê²½ë˜ì—ˆëŠ”ë°, ì´ë¥¼ ê³ ë ¤í•˜ì§€ ì•Šì€ ê²ƒ ê°™ë‹¤.

**ëª¨ë“ˆ ê°„ ìˆœí™˜ ì°¸ì¡° ìœ„í—˜**  
utils ë””ë ‰í† ë¦¬ì— ì—¬ëŸ¬ ëª¨ë“ˆì´ ìˆëŠ”ë°, ì„œë¡œ importí•˜ëŠ” êµ¬ì¡°ê°€ ìˆœí™˜ ì°¸ì¡°ë¥¼ ì¼ìœ¼í‚¬ ìˆ˜ ìˆë‹¤. `model_utils.py`ê°€ `preprocessing_utils.py`ë¥¼ importí•˜ê³ , ë°˜ëŒ€ë¡œë„ importí•˜ë©´ ë¬¸ì œê°€ ìƒê¸´ë‹¤.

**AdaBoostì™€ RandomForest ë™ì‹œ ì‚¬ìš©**  
`model_utils.py`ì—ì„œ `adaboost_model`ê³¼ `rf_proba_model`ì„ ë™ì‹œì— ë¡œë“œí•˜ëŠ” ê²ƒ ê°™ì€ë°, ì™œ ë‘ ëª¨ë¸ì„ ë™ì‹œì— ì“°ëŠ”ì§€ ë¶ˆë¶„ëª…í•˜ë‹¤. í•˜ë‚˜ëŠ” ë¶„ë¥˜ìš©ì´ê³  í•˜ë‚˜ëŠ” í™•ë¥  ì˜ˆì¸¡ìš©ì¸ ê²ƒ ê°™ì€ë°, ì´ê²Œ ì‚¬ìš©ìì—ê²Œ í˜¼ë€ì„ ì¤„ ìˆ˜ ìˆë‹¤.

**Streamlit ë¡œê·¸ íŒŒì¼**  
`streamlit.log` íŒŒì¼ì´ ë ˆí¬ì§€í† ë¦¬ì— í¬í•¨ë˜ì–´ ìˆëŠ”ë°, ì´ê±´ `.gitignore`ì— ì¶”ê°€í•´ì•¼ í•œë‹¤. ë¡œê·¸ íŒŒì¼ì€ ì‹¤í–‰ ì¤‘ì— ìƒì„±ë˜ëŠ” ê²ƒì´ë¼ ë²„ì „ ê´€ë¦¬ ëŒ€ìƒì´ ì•„ë‹ˆë‹¤.

**SHAP ë¯¸ì‚¬ìš©**  
requirements.txtì— SHAPì„ í¬í•¨í–ˆì§€ë§Œ, ì‹¤ì œë¡œ ì‚¬ìš©í•˜ëŠ”ì§€ ë¶ˆë¶„ëª…í•˜ë‹¤. ëª¨ë¸ í•´ì„ ê°€ëŠ¥ì„±ì„ ìœ„í•´ ì¶”ê°€í–ˆë‹¤ë©´ ì½”ë“œì—ì„œ ì ê·¹ì ìœ¼ë¡œ í™œìš©í•´ì•¼ í•œë‹¤.

**í…ŒìŠ¤íŠ¸ ë° íƒ€ì… ì²´í¬ ë¶€ì¬**  
utils ëª¨ë“ˆì„ ë§Œë“¤ì—ˆìœ¼ë©´ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ì™€ type hintsë¥¼ ì¶”ê°€í•´ì•¼ í•˜ëŠ”ë° ì—†ë‹¤. íŠ¹íˆ `model_utils.py`ì²˜ëŸ¼ í•µì‹¬ ë¡œì§ì€ ë°˜ë“œì‹œ í…ŒìŠ¤íŠ¸ê°€ í•„ìš”í•˜ë‹¤.

### ğŸ”§ ê°œì„  ë°©í–¥

**1. ë²„ì „ ë²”ìœ„ êµ¬ì²´í™”**  
ìµœì†Œ ë²„ì „ê³¼ ìµœëŒ€ ë²„ì „ì„ í•¨ê»˜ ëª…ì‹œí•´ì„œ ì•ˆì •ì„±ì„ í™•ë³´í•´ë¼:
```
numpy>=1.24.0,<2.0.0  # numpy 2.0 breaking change íšŒí”¼
pandas>=1.5.0,<3.0.0
scikit-learn>=1.3.0,<1.4.0
xgboost>=1.7.0,<2.0.0
```

ë˜ëŠ” poetryë¥¼ ì‚¬ìš©í•´ì„œ ì˜ì¡´ì„±ì„ ë” ì •êµí•˜ê²Œ ê´€ë¦¬í•´ë¼:
```toml
[tool.poetry.dependencies]
python = "^3.10"
numpy = "^1.24.0"
pandas = "^2.0.0"
```

**2. .gitignore ë³´ì™„**  
```gitignore
# ë¡œê·¸ íŒŒì¼
*.log
streamlit.log

# ìºì‹œ
__pycache__/
*.pyc
.pytest_cache/

# í™˜ê²½
.env
.venv/

# Jupyter
.ipynb_checkpoints/

# ëª¨ë¸ íŒŒì¼ (í¬ê¸°ê°€ í¬ë©´)
*.pkl
*.h5
*.pth
```

**3. ëª¨ë“ˆ êµ¬ì¡° ê°œì„  ë° íƒ€ì… íŒíŠ¸ ì¶”ê°€**  
```python
# preprocessing_utils.py
from typing import List, Dict, Any
import pandas as pd
import numpy as np

def preprocess_features(
    data: pd.DataFrame,
    categorical_cols: List[str],
    numerical_cols: List[str]
) -> np.ndarray:
    """íŠ¹ì„± ì „ì²˜ë¦¬
    
    Args:
        data: ì…ë ¥ ë°ì´í„°í”„ë ˆì„
        categorical_cols: ë²”ì£¼í˜• ì»¬ëŸ¼ ëª©ë¡
        numerical_cols: ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ëª©ë¡
    
    Returns:
        ì „ì²˜ë¦¬ëœ numpy ë°°ì—´
    """
    # êµ¬í˜„...
    return processed_data
```

**4. ëª¨ë¸ ë˜í¼ í´ë˜ìŠ¤**  
ì—¬ëŸ¬ ëª¨ë¸ì„ ì‚¬ìš©í•œë‹¤ë©´ í†µí•© ì¸í„°í˜ì´ìŠ¤ë¥¼ ë§Œë“¤ì–´ë¼:
```python
# model_utils.py
from abc import ABC, abstractmethod
from typing import Optional

class ChurnPredictor(ABC):
    @abstractmethod
    def predict(self, features: np.ndarray) -> int:
        pass
    
    @abstractmethod
    def predict_proba(self, features: np.ndarray) -> float:
        pass

class EnsemblePredictor(ChurnPredictor):
    def __init__(self, adaboost_path: str, rf_path: str):
        self.adaboost = joblib.load(adaboost_path)
        self.rf = joblib.load(rf_path)
    
    def predict(self, features):
        # AdaBoost ì‚¬ìš©
        return self.adaboost.predict(features)[0]
    
    def predict_proba(self, features):
        # RandomForest í™•ë¥  ì‚¬ìš©
        return self.rf.predict_proba(features)[0, 1]
```

**5. pytestë¡œ ìœ ë‹› í…ŒìŠ¤íŠ¸ ì¶”ê°€**  
```python
# tests/test_preprocessing.py
import pytest
import pandas as pd
from streamlit_netflix.utils.preprocessing_utils import preprocess_features

def test_preprocess_basic():
    df = pd.DataFrame({
        'age': [25, 30, 35],
        'region': ['A', 'B', 'A']
    })
    result = preprocess_features(df, ['region'], ['age'])
    assert result.shape[0] == 3

def test_preprocess_missing_values():
    df = pd.DataFrame({
        'age': [25, None, 35],
        'region': ['A', 'B', None]
    })
    with pytest.raises(ValueError):
        preprocess_features(df, ['region'], ['age'])
```

**6. SHAP ì ê·¹ í™œìš©**  
ëª¨ë¸ í•´ì„ì„ ìœ„í•´ SHAPì„ ì œëŒ€ë¡œ í™œìš©í•´ë¼:
```python
import shap

# Streamlit ì•±ì—ì„œ
if st.checkbox("ì˜ˆì¸¡ ì„¤ëª… ë³´ê¸°"):
    explainer = shap.TreeExplainer(model)
    shap_values = explainer.shap_values(input_features)
    
    fig = shap.waterfall_plot(
        shap.Explanation(
            values=shap_values[0],
            base_values=explainer.expected_value,
            data=input_features[0],
            feature_names=feature_names
        )
    )
    st.pyplot(fig)
```

**7. ì„¤ì • ê´€ë¦¬ ê°œì„ **  
`config.py`ë¥¼ ë§Œë“¤ì–´ì„œ í•˜ë“œì½”ë”©ëœ ê°’ë“¤ì„ ì¤‘ì•™ì§‘ì¤‘í™”í•´ë¼:
```python
# config.py
from dataclasses import dataclass
from pathlib import Path

@dataclass
class ModelConfig:
    adaboost_path: Path = Path("models/adaboost_model.pkl")
    rf_path: Path = Path("models/rf_proba_model.pkl")
    features: list = None
    
    def __post_init__(self):
        self.features = [
            'age', 'subscription_type', 'watch_hours',
            'last_login_days', 'device', 'monthly_fee'
        ]

config = ModelConfig()
```

**8. ë¡œê¹… ê°œì„ **  
Python loggingì„ ì œëŒ€ë¡œ ì„¤ì •í•´ë¼:
```python
# logging_config.py
import logging
from pathlib import Path

def setup_logging(log_file: str = "app.log"):
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file),
            logging.StreamHandler()
        ]
    )

# ì‚¬ìš©
from logging_config import setup_logging
setup_logging()
logger = logging.getLogger(__name__)
logger.info("ì•± ì‹œì‘")
```

---

## ì¢…í•© í‰ê°€ ë° ê¶Œì¥ì‚¬í•­

### ì „ì²´ íŒ€ ê³µí†µ ì´ìŠˆ

1. **ì˜ì¡´ì„± ê´€ë¦¬ì˜ ì¤‘ìš”ì„± ì¸ì‹ ë¶€ì¡±**  
   - 5ê°œ íŒ€ ì¤‘ 3ê°œ íŒ€ì´ ë²„ì „ ê³ ì •ì„ ì œëŒ€ë¡œ í•˜ì§€ ì•ŠìŒ
   - ì¬í˜„ ê°€ëŠ¥í•œ í™˜ê²½ êµ¬ì¶•ì´ í”„ë¡œì íŠ¸ ì„±ê³µì˜ í•µì‹¬ì„ì„ ê°•ì¡° í•„ìš”

2. **í…ŒìŠ¤íŠ¸ ì½”ë“œ ë¶€ì¬**  
   - ëª¨ë“  íŒ€ì´ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ë¥¼ ì‘ì„±í•˜ì§€ ì•ŠìŒ
   - pytest ë„ì…ê³¼ ìµœì†Œ coverage 50% ëª©í‘œ ì„¤ì • ê¶Œì¥

3. **ì—ëŸ¬ í•¸ë“¤ë§ ë¯¸í¡**  
   - try-exceptë¥¼ ì“°ë”ë¼ë„ ë‹¨ìˆœ ë¡œê¹…ë§Œ í•˜ê³  ë³µêµ¬ ë¡œì§ì´ ì—†ìŒ
   - ì‚¬ìš©ì ì¹œí™”ì ì¸ ì—ëŸ¬ ë©”ì‹œì§€ì™€ fallback ì „ëµ í•„ìš”

4. **ë³´ì•ˆ ê³ ë ¤ì‚¬í•­ ë¶€ì¡±**  
   - API í‚¤ë‚˜ ë¯¼ê° ì •ë³´ë¥¼ ì½”ë“œì— í•˜ë“œì½”ë”©í•  ìœ„í—˜
   - .env íŒŒì¼ê³¼ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš© ê¶Œì¥

5. **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë¶€ì¬**  
   - ëª¨ë¸ ì¶”ë¡  ì‹œê°„, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë“±ì„ ì¸¡ì •í•˜ì§€ ì•ŠìŒ
   - í”„ë¡œë•ì…˜ ë°°í¬ ì „ í”„ë¡œíŒŒì¼ë§ í•„ìˆ˜

### íŒ€ë³„ ìµœìš°ì„  ê°œì„  ê³¼ì œ

| íŒ€ | ìµœìš°ì„  ê³¼ì œ | ì´ìœ  |
|----|------------|------|
| 1íŒ€ | requirements.txt ë²„ì „ ê³ ì • + Pipeline ë„ì… | ì¬í˜„ì„±ê³¼ ì¼ê´€ì„± í™•ë³´ |
| 2íŒ€ | requirements.txt ìƒì„± + ê²½ë¡œ ê´€ë¦¬ ê°œì„  | ì™„ì„±ë„ ë†’ì€ í”„ë¡œì íŠ¸ì¸ë° ë°°í¬ ì¤€ë¹„ ë¶€ì¡± |
| 3íŒ€ | ì½”ë“œ ëª¨ë“ˆí™” + ì˜ì¡´ì„± íŒŒì¼ ì‘ì„± | ë…¸íŠ¸ë¶ â†’ í”„ë¡œë•ì…˜ ì½”ë“œ ì „í™˜ |
| 4íŒ€ | ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ ì—…ê·¸ë ˆì´ë“œ | ìµœì‹  ê¸°ëŠ¥ê³¼ ì„±ëŠ¥ ê°œì„  í™œìš© |
| 5íŒ€ | íƒ€ì… íŒíŠ¸ + í…ŒìŠ¤íŠ¸ ì¶”ê°€ | ì¢‹ì€ êµ¬ì¡°ì— ê²¬ê³ í•¨ ì¶”ê°€ |

### í•™ìŠµ ê¶Œì¥ì‚¬í•­

ê° íŒ€ì´ ë‹¤ìŒ í”„ë¡œì íŠ¸ì—ì„œ ì‹œë„í•´ë³¼ ë§Œí•œ ê³ ê¸‰ ì£¼ì œ:

1. **MLOps íŒŒì´í”„ë¼ì¸**  
   - MLflow ë˜ëŠ” Weights & Biasesë¡œ ì‹¤í—˜ íŠ¸ë˜í‚¹
   - DVCë¡œ ë°ì´í„° ë²„ì „ ê´€ë¦¬
   - GitHub Actionsë¡œ CI/CD êµ¬ì¶•

2. **ëª¨ë¸ ë°°í¬**  
   - Docker ì»¨í…Œì´ë„ˆí™”
   - FastAPIë¡œ REST API êµ¬ì¶•
   - AWS SageMaker ë˜ëŠ” GCP Vertex AI ë°°í¬

3. **ê³ ê¸‰ ê¸°ë²•**  
   - AutoML (TPOT, Auto-sklearn)
   - ì‹ ê²½ë§ êµ¬ì¡° íƒìƒ‰ (Neural Architecture Search)
   - ì—°í•©í•™ìŠµ (Federated Learning)

4. **ëª¨ë‹ˆí„°ë§**  
   - Prometheus + Grafanaë¡œ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
   - Evidentlyë¡œ ë°ì´í„° ë“œë¦¬í”„íŠ¸ ê°ì§€
   - Alibi Detectë¡œ ëª¨ë¸ ì´ìƒ íƒì§€

### ë§ˆë¬´ë¦¬

5ê°œ íŒ€ ëª¨ë‘ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ê°œë°œì˜ ê¸°ë³¸ì€ ì˜ ìˆ˜í–‰í–ˆë‹¤. ë°ì´í„° ì „ì²˜ë¦¬, ëª¨ë¸ í•™ìŠµ, í‰ê°€ê¹Œì§€ì˜ í”„ë¡œì„¸ìŠ¤ëŠ” íƒ„íƒ„í•˜ë‹¤. í•˜ì§€ë§Œ **í”„ë¡œë•ì…˜ ì¤€ë¹„(Production-Ready) ìˆ˜ì¤€**ìœ¼ë¡œ ê°€ê¸° ìœ„í•´ì„œëŠ” ìœ„ì—ì„œ ì–¸ê¸‰í•œ ê°œì„ ì‚¬í•­ë“¤ì´ ë°˜ë“œì‹œ í•„ìš”í•˜ë‹¤.

íŠ¹íˆ 2íŒ€ê³¼ 4íŒ€, 5íŒ€ì€ ì¡°ê¸ˆë§Œ ë” ë³´ì™„í•˜ë©´ ì‹¤ë¬´ì— ë°”ë¡œ íˆ¬ì…í•´ë„ ë  ë§Œí¼ ì™„ì„±ë„ê°€ ë†’ë‹¤. 1íŒ€ê³¼ 3íŒ€ì€ ê¸°ì´ˆê°€ íŠ¼íŠ¼í•˜ë‹ˆ êµ¬ì¡°í™”ì™€ ëª¨ë“ˆí™”ì— ì§‘ì¤‘í•˜ë©´ ë¹ ë¥´ê²Œ ë”°ë¼ì¡ì„ ìˆ˜ ìˆì„ ê²ƒì´ë‹¤.

**í•µì‹¬ ë©”ì‹œì§€**: "ë™ì‘í•˜ëŠ” ëª¨ë¸"ì„ ë§Œë“œëŠ” ê²ƒê³¼ "ìœ ì§€ë³´ìˆ˜ ê°€ëŠ¥í•œ ì‹œìŠ¤í…œ"ì„ ë§Œë“œëŠ” ê²ƒì€ ë‹¤ë¥´ë‹¤. ì§€ê¸ˆë¶€í„°ë¼ë„ í…ŒìŠ¤íŠ¸, ë¡œê¹…, ë¬¸ì„œí™”, ë²„ì „ ê´€ë¦¬ë¥¼ ìŠµê´€í™”í•´ë¼. ê·¸ê²Œ ì‹œë‹ˆì–´ ì—”ì§€ë‹ˆì–´ë¡œ ê°€ëŠ” ê¸¸ì´ë‹¤.
