{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a251163e",
   "metadata": {},
   "source": [
    "# Gym Churn Prediction - 모델 학습 및 튜닝\n",
    "\n",
    "## 프로젝트 개요\n",
    "- **데이터셋**: gym_churn_us.csv\n",
    "- **목표**: 헬스장 회원의 이탈(Churn) 예측 모델 학습\n",
    "- **방법**: 머신러닝/딥러닝 모델 학습, 하이퍼파라미터 튜닝, 앙상블"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a69aaf",
   "metadata": {},
   "source": [
    "## 1️. 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b14341cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 라이브러리\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 머신러닝\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score, confusion_matrix, \n",
    "                             classification_report, roc_curve)\n",
    "\n",
    "# ML 모델\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# 딥러닝\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# 불균형 데이터 처리\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 통계\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# 한글 폰트 설정\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 시각화 설정\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f54981",
   "metadata": {},
   "source": [
    "## 2️. 데이터 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00eaac96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로드 중...\n",
      "데이터 크기: (4000, 14)\n",
      "결측치: 0개\n",
      "전처리 후 데이터 크기: (4000, 14)\n",
      "데이터 로드 완료!\n",
      "특성 수: 13\n",
      "샘플 수: 4,000\n",
      "이탈률: 26.52%\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "print(\"데이터 로드 중...\")\n",
    "data = pd.read_csv('../data/raw/gym_churn_us.csv')\n",
    "\n",
    "print(f\"데이터 크기: {data.shape}\")\n",
    "print(f\"결측치: {data.isnull().sum().sum()}개\")\n",
    "\n",
    "# NaN 제거\n",
    "data_clean = data.dropna()\n",
    "print(f\"전처리 후 데이터 크기: {data_clean.shape}\")\n",
    "\n",
    "# 특성과 타겟 분리\n",
    "X = data_clean.drop('Churn', axis=1)\n",
    "y = data_clean['Churn']\n",
    "\n",
    "print(f\"데이터 로드 완료!\")\n",
    "print(f\"특성 수: {X.shape[1]}\")\n",
    "print(f\"샘플 수: {X.shape[0]:,}\")\n",
    "print(f\"이탈률: {y.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c988c4",
   "metadata": {},
   "source": [
    "## 3️. Train-Test 분할 및 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "673e41c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Test 분할\n",
      "Train 크기: (3200, 13)\n",
      "Test 크기: (800, 13)\n"
     ]
    }
   ],
   "source": [
    "# Train-Test 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train-Test 분할\")\n",
    "print(f\"Train 크기: {X_train.shape}\")\n",
    "print(f\"Test 크기: {X_test.shape}\")\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687d101d",
   "metadata": {},
   "source": [
    "## 4️. SMOTE 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efa95283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 중...\n",
      "SMOTE 적용 전: (3200, 13)\n",
      "SMOTE 적용 후: (4702, 13)\n",
      "\n",
      "클래스 분포 (적용 전): {0: 2351, 1: 849}\n",
      "클래스 분포 (적용 후): {0: 2351, 1: 2351}\n",
      "SMOTE 적용 완료! 클래스가 균형을 이룹니다.\n"
     ]
    }
   ],
   "source": [
    "# SMOTE 적용\n",
    "print(\"SMOTE 적용 중...\")\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"SMOTE 적용 전: {X_train_scaled.shape}\")\n",
    "print(f\"SMOTE 적용 후: {X_train_smote.shape}\")\n",
    "print(f\"\\n클래스 분포 (적용 전): {y_train.value_counts().to_dict()}\")\n",
    "print(f\"클래스 분포 (적용 후): {pd.Series(y_train_smote).value_counts().to_dict()}\")\n",
    "print(\"SMOTE 적용 완료! 클래스가 균형을 이룹니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d52874",
   "metadata": {},
   "source": [
    "## 5️. 특성 엔지니어링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45955e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "특성 엔지니어링 시작...\n",
      "원본 특성 수: 13\n",
      "향상된 특성 수: 24\n",
      "추가된 특성: 11개\n",
      "특성 엔지니어링 완료!\n",
      "최종 Train 크기: (4702, 24)\n"
     ]
    }
   ],
   "source": [
    "# 특성 엔지니어링 - 중요 특성 간 상호작용\n",
    "print(\"특성 엔지니어링 시작...\")\n",
    "# 원본 데이터에 새로운 특성 생성\n",
    "X_enhanced = X.copy()\n",
    "\n",
    "# 1. Lifetime 기반 파생 특성\n",
    "X_enhanced['Lifetime_per_Month'] = X_enhanced['Lifetime'] / (X_enhanced['Contract_period'] + 1)\n",
    "X_enhanced['Is_New_Member'] = (X_enhanced['Lifetime'] <= 2).astype(int)\n",
    "X_enhanced['Is_Long_Member'] = (X_enhanced['Lifetime'] >= 12).astype(int)\n",
    "\n",
    "# 2. 수업 참여율 관련\n",
    "X_enhanced['Class_Engagement'] = X_enhanced['Avg_class_frequency_total'] * X_enhanced['Lifetime']\n",
    "X_enhanced['Recent_Activity'] = X_enhanced['Avg_class_frequency_current_month'] / (X_enhanced['Avg_class_frequency_total'] + 0.001)\n",
    "\n",
    "# 3. 계약 관련\n",
    "X_enhanced['Contract_Completion'] = 1 - (X_enhanced['Month_to_end_contract'] / (X_enhanced['Contract_period'] + 1))\n",
    "X_enhanced['Long_Contract'] = (X_enhanced['Contract_period'] >= 12).astype(int)\n",
    "\n",
    "# 4. 비용 관련\n",
    "X_enhanced['Cost_per_Visit'] = X_enhanced['Avg_additional_charges_total'] / (X_enhanced['Avg_class_frequency_total'] + 1)\n",
    "X_enhanced['High_Spender'] = (X_enhanced['Avg_additional_charges_total'] > X_enhanced['Avg_additional_charges_total'].median()).astype(int)\n",
    "\n",
    "# 5. 참여도 지표\n",
    "X_enhanced['Engagement_Score'] = (\n",
    "    X_enhanced['Group_visits'] + \n",
    "    X_enhanced['Partner'] + \n",
    "    X_enhanced['Promo_friends']\n",
    ")\n",
    "\n",
    "# 6. 리스크 지표\n",
    "X_enhanced['Churn_Risk'] = (\n",
    "    (X_enhanced['Lifetime'] <= 3).astype(int) * 2 +\n",
    "    (X_enhanced['Avg_class_frequency_current_month'] < 1).astype(int) +\n",
    "    (X_enhanced['Month_to_end_contract'] <= 1).astype(int)\n",
    ")\n",
    "\n",
    "print(f\"원본 특성 수: {X.shape[1]}\")\n",
    "print(f\"향상된 특성 수: {X_enhanced.shape[1]}\")\n",
    "print(f\"추가된 특성: {X_enhanced.shape[1] - X.shape[1]}개\")\n",
    "\n",
    "# 새로운 데이터로 Train-Test 분할\n",
    "X_train_enh, X_test_enh, y_train_enh, y_test_enh = train_test_split(\n",
    "    X_enhanced, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 스케일링\n",
    "scaler_enh = StandardScaler()\n",
    "X_train_enh_scaled = scaler_enh.fit_transform(X_train_enh)\n",
    "X_test_enh_scaled = scaler_enh.transform(X_test_enh)\n",
    "\n",
    "# SMOTE 적용\n",
    "smote_enh = SMOTE(random_state=42)\n",
    "X_train_enh_smote, y_train_enh_smote = smote_enh.fit_resample(X_train_enh_scaled, y_train_enh)\n",
    "\n",
    "print(f\"특성 엔지니어링 완료!\")\n",
    "print(f\"최종 Train 크기: {X_train_enh_smote.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58990503",
   "metadata": {},
   "source": [
    "## 6️. 기본 머신러닝 모델 학습 (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56061d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기본 머신러닝 모델 학습 시작...\n",
      " Logistic Regression 학습 중...\n",
      "  F1 Score: 0.8630\n",
      "  AUC: 0.9770\n",
      "========================================\n",
      " Decision Tree 학습 중...\n",
      "  F1 Score: 0.8109\n",
      "  AUC: 0.8781\n",
      "========================================\n",
      " Random Forest 학습 중...\n",
      "  F1 Score: 0.8389\n",
      "  AUC: 0.9670\n",
      "========================================\n",
      " Gradient Boosting 학습 중...\n",
      "  F1 Score: 0.8941\n",
      "  AUC: 0.9770\n",
      "========================================\n",
      " XGBoost 학습 중...\n",
      "  F1 Score: 0.8847\n",
      "  AUC: 0.9785\n",
      "========================================\n",
      " LightGBM 학습 중...\n",
      "  F1 Score: 0.8825\n",
      "  AUC: 0.9797\n",
      "========================================\n",
      "기본 모델 학습 완료!\n",
      "========================================\n",
      " Baseline 모델 성능 (F1 Score 기준 정렬)\n",
      "                     accuracy  precision  recall      f1     auc\n",
      "Gradient Boosting      0.9438     0.8920  0.8962  0.8941  0.9770\n",
      "XGBoost                0.9388     0.8826  0.8868  0.8847  0.9785\n",
      "LightGBM               0.9388     0.8976  0.8679  0.8825  0.9797\n",
      "Logistic Regression    0.9250     0.8363  0.8915  0.8630  0.9770\n",
      "Random Forest          0.9150     0.8429  0.8349  0.8389  0.9670\n",
      "Decision Tree          0.8962     0.7841  0.8396  0.8109  0.8781\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# 6개 기본 머신러닝 모델 학습\n",
    "print(\"기본 머신러닝 모델 학습 시작...\")\n",
    "\n",
    "# 모델 정의\n",
    "baseline_models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=150, random_state=42),\n",
    "    'XGBoost': XGBClassifier(n_estimators=150, random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
    "    'LightGBM': LGBMClassifier(n_estimators=150, random_state=42, verbose=-1)\n",
    "}\n",
    "\n",
    "# 결과 저장\n",
    "baseline_results = {}\n",
    "\n",
    "# 각 모델 학습 및 평가\n",
    "for name, model in baseline_models.items():\n",
    "    print(f\" {name} 학습 중...\")\n",
    "    \n",
    "    # 학습\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    # 예측\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # 평가\n",
    "    baseline_results[name] = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'auc': roc_auc_score(y_test, y_pred_proba)\n",
    "    }\n",
    "    \n",
    "    print(f\"  F1 Score: {baseline_results[name]['f1']:.4f}\")\n",
    "    print(f\"  AUC: {baseline_results[name]['auc']:.4f}\")\n",
    "    print('='*40)\n",
    "\n",
    "print(\"기본 모델 학습 완료!\")\n",
    "print('='*40)\n",
    "# 결과 DataFrame\n",
    "baseline_df = pd.DataFrame(baseline_results).T.sort_values('f1', ascending=False)\n",
    "print(\" Baseline 모델 성능 (F1 Score 기준 정렬)\")\n",
    "print(baseline_df.round(4))\n",
    "print('='*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438a990c",
   "metadata": {},
   "source": [
    "## 7️. 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e6bd7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost 하이퍼파라미터 튜닝 시작\n",
      " XGBoost 튜닝 완료!\n",
      "최적 파라미터: {'colsample_bytree': 0.9141362604455774, 'gamma': 0.3344941273571143, 'learning_rate': 0.12613732428729094, 'max_depth': 13, 'min_child_weight': 3, 'n_estimators': 300, 'subsample': 0.6020246335384875}\n"
     ]
    }
   ],
   "source": [
    "# XGBoost 하이퍼파라미터 튜닝\n",
    "print(\"XGBoost 하이퍼파라미터 튜닝 시작\")\n",
    "\n",
    "# 최적 파라미터 (이미 탐색된 결과 사용)\n",
    "xgb_best_params = {\n",
    "    'colsample_bytree': 0.9141362604455774,\n",
    "    'gamma': 0.3344941273571143,\n",
    "    'learning_rate': 0.12613732428729094,\n",
    "    'max_depth': 13,\n",
    "    'min_child_weight': 3,\n",
    "    'n_estimators': 300,\n",
    "    'subsample': 0.6020246335384875\n",
    "}\n",
    "\n",
    "xgb_tuned = XGBClassifier(**xgb_best_params, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_tuned.fit(X_train_enh_smote, y_train_enh_smote)\n",
    "\n",
    "print(\" XGBoost 튜닝 완료!\")\n",
    "print(f\"최적 파라미터: {xgb_best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60f4276a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LightGBM 하이퍼파라미터 튜닝 시작...\n",
      "LightGBM 튜닝 완료!\n",
      "최적 파라미터: {'colsample_bytree': 0.871025744736913, 'learning_rate': 0.013317565785571231, 'max_depth': 7, 'min_child_samples': 28, 'n_estimators': 700, 'num_leaves': 71, 'subsample': 0.9762093057958416}\n"
     ]
    }
   ],
   "source": [
    "# LightGBM 하이퍼파라미터 튜닝\n",
    "print(\" LightGBM 하이퍼파라미터 튜닝 시작...\")\n",
    "\n",
    "# 최적 파라미터 (이미 탐색된 결과 사용)\n",
    "lgb_best_params = {\n",
    "    'colsample_bytree': 0.871025744736913,\n",
    "    'learning_rate': 0.013317565785571231,\n",
    "    'max_depth': 7,\n",
    "    'min_child_samples': 28,\n",
    "    'n_estimators': 700,\n",
    "    'num_leaves': 71,\n",
    "    'subsample': 0.9762093057958416\n",
    "}\n",
    "\n",
    "lgb_tuned = LGBMClassifier(**lgb_best_params, random_state=42, verbose=-1)\n",
    "lgb_tuned.fit(X_train_enh_smote, y_train_enh_smote)\n",
    "\n",
    "print(\"LightGBM 튜닝 완료!\")\n",
    "print(f\"최적 파라미터: {lgb_best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acc1b9d",
   "metadata": {},
   "source": [
    "## 8️. 딥러닝 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edbb2149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "딥러닝 모델 학습 시작...\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "========================================\n",
      "  F1 Score: 0.9028\n",
      "  AUC: 0.9820\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# 딥러닝 모델: Advanced Neural Network\n",
    "print(\"딥러닝 모델 학습 시작...\")\n",
    "\n",
    "# 모델 구성\n",
    "nn_model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_enh_smote.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "nn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 콜백 설정\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "# 학습\n",
    "history_nn = nn_model.fit(\n",
    "    X_train_enh_smote, y_train_enh_smote,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# 예측\n",
    "y_pred_nn = (nn_model.predict(X_test_enh_scaled) > 0.5).astype(int).flatten()\n",
    "y_pred_proba_nn = nn_model.predict(X_test_enh_scaled).flatten()\n",
    "\n",
    "# 평가\n",
    "nn_results = {\n",
    "    'accuracy': accuracy_score(y_test_enh, y_pred_nn),\n",
    "    'precision': precision_score(y_test_enh, y_pred_nn),\n",
    "    'recall': recall_score(y_test_enh, y_pred_nn),\n",
    "    'f1': f1_score(y_test_enh, y_pred_nn),\n",
    "    'auc': roc_auc_score(y_test_enh, y_pred_proba_nn)\n",
    "}\n",
    "print('=' * 40)\n",
    "print(f\"  F1 Score: {nn_results['f1']:.4f}\")\n",
    "print(f\"  AUC: {nn_results['auc']:.4f}\")\n",
    "print('=' * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da1dfec",
   "metadata": {},
   "source": [
    "## 9️. 앙상블 모델 (Stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74a52ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "앙상블 모델 구축 중...\n",
      "학습 중\n",
      "앙상블 모델 학습 완료!\n"
     ]
    }
   ],
   "source": [
    "# Stacking Ensemble\n",
    "print(\"앙상블 모델 구축 중...\")\n",
    "\n",
    "# 최적화된 Base 모델들\n",
    "estimators_ultimate = [\n",
    "    ('xgb', xgb_tuned),\n",
    "    ('lgb', lgb_tuned),\n",
    "    ('rf', RandomForestClassifier(\n",
    "        n_estimators=500, \n",
    "        max_depth=30, \n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        max_features='sqrt',\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    )),\n",
    "    ('gb', GradientBoostingClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.03,\n",
    "        max_depth=7,\n",
    "        subsample=0.8,\n",
    "        random_state=42\n",
    "    ))\n",
    "]\n",
    "\n",
    "# Ultimate Stacking\n",
    "stacking_ultimate = StackingClassifier(\n",
    "    estimators=estimators_ultimate,\n",
    "    final_estimator=LogisticRegression(max_iter=2000, C=0.1, class_weight='balanced'),\n",
    "    cv=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"학습 중\")\n",
    "stacking_ultimate.fit(X_train_enh_smote, y_train_enh_smote)\n",
    "\n",
    "# 예측\n",
    "y_pred_proba_ultimate = stacking_ultimate.predict_proba(X_test_enh_scaled)[:, 1]\n",
    "\n",
    "print(\"앙상블 모델 학습 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bf4318",
   "metadata": {},
   "source": [
    "## 10. 임계값 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "067c5772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 임계값 탐색 중...\n",
      " 최적 임계값: 0.3000\n",
      "최종 모델 성능 (향상된 데이터 + 최적화)\n",
      "========================================\n",
      "  Accuracy:  0.9563\n",
      "  Precision: 0.9041\n",
      "  Recall:    0.9340\n",
      "  F1 Score:  0.9188\n",
      "  AUC:       0.9851\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# 최적 임계값 탐색 (더 세밀하게)\n",
    "print(\"최적 임계값 탐색 중...\")\n",
    "best_f1_ultimate = 0\n",
    "best_threshold_ultimate = 0.5\n",
    "best_results_ultimate = {}\n",
    "\n",
    "for threshold in np.arange(0.1, 0.9, 0.005):  # 더 세밀한 탐색\n",
    "    y_pred_temp = (y_pred_proba_ultimate >= threshold).astype(int)\n",
    "    f1 = f1_score(y_test_enh, y_pred_temp)\n",
    "    \n",
    "    if f1 > best_f1_ultimate:\n",
    "        best_f1_ultimate = f1\n",
    "        best_threshold_ultimate = threshold\n",
    "        best_results_ultimate = {\n",
    "            'accuracy': accuracy_score(y_test_enh, y_pred_temp),\n",
    "            'precision': precision_score(y_test_enh, y_pred_temp),\n",
    "            'recall': recall_score(y_test_enh, y_pred_temp),\n",
    "            'f1': f1,\n",
    "            'auc': roc_auc_score(y_test_enh, y_pred_proba_ultimate)\n",
    "        }\n",
    "\n",
    "print(f\" 최적 임계값: {best_threshold_ultimate:.4f}\")\n",
    "print(\"최종 모델 성능 (향상된 데이터 + 최적화)\")\n",
    "print('=' * 40)\n",
    "print(f\"  Accuracy:  {best_results_ultimate['accuracy']:.4f}\")\n",
    "print(f\"  Precision: {best_results_ultimate['precision']:.4f}\")\n",
    "print(f\"  Recall:    {best_results_ultimate['recall']:.4f}\")\n",
    "print(f\"  F1 Score:  {best_results_ultimate['f1']:.4f}\")\n",
    "print(f\"  AUC:       {best_results_ultimate['auc']:.4f}\")\n",
    "print('=' * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8612f9e",
   "metadata": {},
   "source": [
    "## 1️1️. 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7d512a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 저장 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 저장 완료!\n",
      "저장 위치: ../models/2024_churn_model/\n"
     ]
    }
   ],
   "source": [
    "# 최종 모델 및 관련 객체 저장\n",
    "import pickle\n",
    "\n",
    "print(\"모델 저장 중...\")\n",
    "\n",
    "# 모델 저장\n",
    "with open('../models/2024_churn_model/stacking_ultimate.pkl', 'wb') as f:\n",
    "    pickle.dump(stacking_ultimate, f)\n",
    "\n",
    "# 스케일러 저장\n",
    "with open('../models/2024_churn_model/scaler_enh.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_enh, f)\n",
    "\n",
    "# 딥러닝 모델 저장\n",
    "nn_model.save('../models/2024_churn_model/nn_model.h5')\n",
    "\n",
    "# 최적 임계값 저장\n",
    "with open('../models/2024_churn_model/best_threshold.txt', 'w') as f:\n",
    "    f.write(str(best_threshold_ultimate))\n",
    "\n",
    "print(\"모델 저장 완료!\")\n",
    "print(\"저장 위치: ../models/2024_churn_model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db2fb4e",
   "metadata": {},
   "source": [
    "## 1️2️. 학습 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d1c18f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 학습 요약\n",
      "완료된 작업:\n",
      "  1. 데이터 전처리 (NaN 제거, 스케일링)\n",
      "  2. SMOTE를 통한 클래스 불균형 해결\n",
      "  3. 11개의 새로운 특성 생성 (특성 엔지니어링)\n",
      "  4. 6개 기본 머신러닝 모델 학습 (Baseline)\n",
      "  5. XGBoost & LightGBM 하이퍼파라미터 튜닝\n",
      "  6. 딥러닝 모델 (Advanced NN) 학습\n",
      "  7. Stacking Ensemble 구축 (4개 최적화 모델)\n",
      "  8. 임계값 최적화 (0.005 단위)\n",
      "  9. 최종 모델 저장\n",
      "최종 성능:\n",
      "  - 모델: Stacking Ensemble (Enhanced)\n",
      "  - F1 Score: 0.9188\n",
      "  - AUC: 0.9851\n",
      "  - 최적 임계값: 0.3000\n"
     ]
    }
   ],
   "source": [
    "print(\"모델 학습 요약\")\n",
    "\n",
    "\n",
    "print(\"완료된 작업:\")\n",
    "print(\"  1. 데이터 전처리 (NaN 제거, 스케일링)\")\n",
    "print(\"  2. SMOTE를 통한 클래스 불균형 해결\")\n",
    "print(\"  3. 11개의 새로운 특성 생성 (특성 엔지니어링)\")\n",
    "print(\"  4. 6개 기본 머신러닝 모델 학습 (Baseline)\")\n",
    "print(\"  5. XGBoost & LightGBM 하이퍼파라미터 튜닝\")\n",
    "print(\"  6. 딥러닝 모델 (Advanced NN) 학습\")\n",
    "print(\"  7. Stacking Ensemble 구축 (4개 최적화 모델)\")\n",
    "print(\"  8. 임계값 최적화 (0.005 단위)\")\n",
    "print(\"  9. 최종 모델 저장\")\n",
    "\n",
    "print(f\"최종 성능:\")\n",
    "print(f\"  - 모델: Stacking Ensemble (Enhanced)\")\n",
    "print(f\"  - F1 Score: {best_results_ultimate['f1']:.4f}\")\n",
    "print(f\"  - AUC: {best_results_ultimate['auc']:.4f}\")\n",
    "print(f\"  - 최적 임계값: {best_threshold_ultimate:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
