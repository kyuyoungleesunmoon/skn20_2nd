{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "bCw1BmNGQf5s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "C2XtaQLbQkKA",
        "outputId": "abce9c7a-e6ce-4b5e-a452-9cc597235517"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>is_tv_subscriber</th>\n",
              "      <th>is_movie_package_subscriber</th>\n",
              "      <th>subscription_age</th>\n",
              "      <th>bill_avg</th>\n",
              "      <th>reamining_contract</th>\n",
              "      <th>service_failure_count</th>\n",
              "      <th>download_avg</th>\n",
              "      <th>upload_avg</th>\n",
              "      <th>download_over_limit</th>\n",
              "      <th>churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11.95</td>\n",
              "      <td>25</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0</td>\n",
              "      <td>8.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.22</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8.91</td>\n",
              "      <td>16</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>13.7</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.87</td>\n",
              "      <td>21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.39</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  is_tv_subscriber  is_movie_package_subscriber  subscription_age  \\\n",
              "0  15                 1                            0             11.95   \n",
              "1  18                 0                            0              8.22   \n",
              "2  23                 1                            0              8.91   \n",
              "3  27                 0                            0              6.87   \n",
              "4  34                 0                            0              6.39   \n",
              "\n",
              "   bill_avg  reamining_contract  service_failure_count  download_avg  \\\n",
              "0        25                0.14                      0           8.4   \n",
              "1         0                 NaN                      0           0.0   \n",
              "2        16                0.00                      0          13.7   \n",
              "3        21                 NaN                      1           0.0   \n",
              "4         0                 NaN                      0           0.0   \n",
              "\n",
              "   upload_avg  download_over_limit  churn  \n",
              "0         2.3                    0      0  \n",
              "1         0.0                    0      1  \n",
              "2         0.9                    0      1  \n",
              "3         0.0                    0      1  \n",
              "4         0.0                    0      1  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('../../ML_data/dataset/internet_service_churn.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Ch8uEfVgQkNb"
      },
      "outputs": [],
      "source": [
        "# reamining_contract ê²°ì¸¡ì¹˜ 0ìœ¼ë¡œ ëŒ€ì²´\n",
        "# subscription_age = -0.02 ì œê±°\n",
        "# download_avg, upload_avg ê²°ì¸¡ì¹˜ ì œê±°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "hwllbyE2VX4X",
        "outputId": "6153abe9-230a-4bdf-bb17-1c7fcb5cfad8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "id                                 0\n",
              "is_tv_subscriber                   0\n",
              "is_movie_package_subscriber        0\n",
              "subscription_age                   0\n",
              "bill_avg                           0\n",
              "reamining_contract             21572\n",
              "service_failure_count              0\n",
              "download_avg                     381\n",
              "upload_avg                       381\n",
              "download_over_limit                0\n",
              "churn                              0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "zqOkAL4VUGpk"
      },
      "outputs": [],
      "source": [
        "df['reamining_contract'] = df['reamining_contract'].fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "YCB9axiaUGrs"
      },
      "outputs": [],
      "source": [
        "df = df[df['subscription_age'] >= 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "NLO78pTtUGvQ"
      },
      "outputs": [],
      "source": [
        "df = df.dropna(subset=['download_avg'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "12ioyKJvUqFR",
        "outputId": "df29f9e7-e29e-4751-be85-6f5c69c07d08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "id                             0\n",
              "is_tv_subscriber               0\n",
              "is_movie_package_subscriber    0\n",
              "subscription_age               0\n",
              "bill_avg                       0\n",
              "reamining_contract             0\n",
              "service_failure_count          0\n",
              "download_avg                   0\n",
              "upload_avg                     0\n",
              "download_over_limit            0\n",
              "churn                          0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyj57WLCemRC"
      },
      "source": [
        "# Baseline ëª¨ë¸ ë¹„êµ\n",
        "- LogisticRegression\n",
        "- DecisionTreeClassifier\n",
        "- RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: catboost in /opt/miniconda3/envs/tf311/lib/python3.11/site-packages (1.2.8)\n",
            "Requirement already satisfied: graphviz in /opt/miniconda3/envs/tf311/lib/python3.11/site-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /opt/miniconda3/envs/tf311/lib/python3.11/site-packages (from catboost) (3.10.6)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /opt/miniconda3/envs/tf311/lib/python3.11/site-packages (from catboost) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.24 in /opt/miniconda3/envs/tf311/lib/python3.11/site-packages (from catboost) (2.3.3)\n",
            "Requirement already satisfied: scipy in /opt/miniconda3/envs/tf311/lib/python3.11/site-packages (from catboost) (1.16.2)\n",
            "Requirement already satisfied: plotly in /opt/miniconda3/envs/tf311/lib/python3.11/site-packages (from catboost) (6.4.0)\n",
            "Requirement already satisfied: six in /opt/miniconda3/envs/tf311/lib/python3.11/site-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/envs/tf311/lib/python3.11/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/tf311/lib/python3.11/site-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/envs/tf311/lib/python3.11/site-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /opt/miniconda3/envs/tf311/lib/python3.11/site-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/miniconda3/envs/tf311/lib/python3.11/site-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /opt/miniconda3/envs/tf311/lib/python3.11/site-packages (from matplotlib->catboost) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/miniconda3/envs/tf311/lib/python3.11/site-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/envs/tf311/lib/python3.11/site-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /opt/miniconda3/envs/tf311/lib/python3.11/site-packages (from matplotlib->catboost) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /opt/miniconda3/envs/tf311/lib/python3.11/site-packages (from matplotlib->catboost) (3.2.0)\n",
            "Requirement already satisfied: narwhals>=1.15.1 in /opt/miniconda3/envs/tf311/lib/python3.11/site-packages (from plotly->catboost) (2.10.2)\n",
            "Requirement already satisfied: xgboost in /opt/miniconda3/envs/tf311/lib/python3.11/site-packages (3.1.1)\n",
            "Requirement already satisfied: numpy in /opt/miniconda3/envs/tf311/lib/python3.11/site-packages (from xgboost) (1.23.5)\n",
            "Requirement already satisfied: scipy in /opt/miniconda3/envs/tf311/lib/python3.11/site-packages (from xgboost) (1.16.2)\n",
            "Requirement already satisfied: lightgbm in /opt/miniconda3/envs/tf311/lib/python3.11/site-packages (4.6.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /opt/miniconda3/envs/tf311/lib/python3.11/site-packages (from lightgbm) (1.23.5)\n",
            "Requirement already satisfied: scipy in /opt/miniconda3/envs/tf311/lib/python3.11/site-packages (from lightgbm) (1.16.2)\n"
          ]
        }
      ],
      "source": [
        "# !pip install catboost\n",
        "# !pip install xgboost\n",
        "# !pip install lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtEhswPAZqan",
        "outputId": "c2d4375b-7337-4896-f3ff-92581a980737"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Logistic Regression ===\n",
            "Accuracy: 0.9\n",
            "F1-score: 0.9087\n",
            "\n",
            "=== Decision Tree ===\n",
            "Accuracy: 0.9726\n",
            "F1-score: 0.9754\n",
            "\n",
            "=== Random Forest ===\n",
            "Accuracy: 0.9699\n",
            "F1-score: 0.9729\n",
            "\n",
            "=== XGBoost ===\n",
            "Accuracy: 0.9834\n",
            "F1-score: 0.985\n",
            "\n",
            "[LightGBM] [Info] Number of positive: 32039, number of negative: 25474\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000829 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1405\n",
            "[LightGBM] [Info] Number of data points in the train set: 57513, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.557074 -> initscore=0.229296\n",
            "[LightGBM] [Info] Start training from score 0.229296\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/miniconda3/envs/tf311/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [12:15:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== LightGBM ===\n",
            "Accuracy: 0.9716\n",
            "F1-score: 0.9745\n",
            "\n",
            "=== CatBoost ===\n",
            "Accuracy: 0.948\n",
            "F1-score: 0.9532\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "X = df.drop(columns=['churn'])\n",
        "y = df['churn']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# ìŠ¤ì¼€ì¼ë§ (ë¡œì§€ìŠ¤í‹± íšŒê·€ìš©)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
        "    \"LightGBM\": LGBMClassifier(n_estimators=100, learning_rate=0.05, random_state=42),\n",
        "    \"CatBoost\": CatBoostClassifier(iterations=100, learning_rate=0.05, depth=6,\n",
        "                                   loss_function='Logloss', verbose=0, random_seed=42)\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    if name == \"Logistic Regression\":\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        preds = model.predict(X_test_scaled)\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        preds = model.predict(X_test)\n",
        "\n",
        "    print(f\"=== {name} ===\")\n",
        "    print(\"Accuracy:\", round(accuracy_score(y_test, preds), 4))\n",
        "    print(\"F1-score:\", round(f1_score(y_test, preds), 4))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 32039, number of negative: 25474\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000747 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1407\n",
            "[LightGBM] [Info] Number of data points in the train set: 57513, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.557074 -> initscore=0.229296\n",
            "[LightGBM] [Info] Start training from score 0.229296\n",
            "[LightGBM] [Info] Number of positive: 32039, number of negative: 25474\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000751 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1407\n",
            "[LightGBM] [Info] Number of data points in the train set: 57513, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.557074 -> initscore=0.229296\n",
            "[LightGBM] [Info] Start training from score 0.229296\n",
            "[LightGBM] [Info] Number of positive: 32040, number of negative: 25474\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001025 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1407\n",
            "[LightGBM] [Info] Number of data points in the train set: 57514, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.557082 -> initscore=0.229327\n",
            "[LightGBM] [Info] Start training from score 0.229327\n",
            "[LightGBM] [Info] Number of positive: 32039, number of negative: 25475\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000808 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1403\n",
            "[LightGBM] [Info] Number of data points in the train set: 57514, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.557064 -> initscore=0.229256\n",
            "[LightGBM] [Info] Start training from score 0.229256\n",
            "[LightGBM] [Info] Number of positive: 32039, number of negative: 25475\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000720 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1379\n",
            "[LightGBM] [Info] Number of data points in the train set: 57514, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.557064 -> initscore=0.229256\n",
            "[LightGBM] [Info] Start training from score 0.229256\n",
            "=== LightGBM ===\n",
            "Foldë³„ F1-score: [0.71607366 0.69318756 0.66180117 0.55569678 0.00249377]\n",
            "í‰ê·  F1-score: 0.5259\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/miniconda3/envs/tf311/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [12:15:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/opt/miniconda3/envs/tf311/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [12:15:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/opt/miniconda3/envs/tf311/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [12:15:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/opt/miniconda3/envs/tf311/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [12:15:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/opt/miniconda3/envs/tf311/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [12:15:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== XGBoost ===\n",
            "Foldë³„ F1-score: [0.71607366 0.6934678  0.65405457 0.57477414 0.02075612]\n",
            "í‰ê·  F1-score: 0.5318\n",
            "\n",
            "=== RandomForest ===\n",
            "Foldë³„ F1-score: [7.15753731e-01 6.91271183e-01 6.69875503e-01 5.70219124e-01\n",
            " 2.49656722e-04]\n",
            "í‰ê·  F1-score: 0.5295\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# êµì°¨ê²€ì¦\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# ëª¨ë¸ ëª©ë¡ ì •ì˜\n",
        "models = {\n",
        "    \"LightGBM\": LGBMClassifier(random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
        "    \"RandomForest\": RandomForestClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "# 5-Fold êµì°¨ê²€ì¦ ìˆ˜í–‰ (F1-score ê¸°ì¤€)\n",
        "for name, model in models.items():\n",
        "    scores = cross_val_score(model, X, y, cv=5, scoring='f1')\n",
        "    print(f\"=== {name} ===\")\n",
        "    print(f\"Foldë³„ F1-score: {scores}\")\n",
        "    print(f\"í‰ê·  F1-score: {scores.mean():.4f}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfnBPhWIdohH"
      },
      "source": [
        "F1-scoreê°€ 0.97ì—ì„œ 0.53ê¹Œì§€ ë–¨ì–´ì§ -> Overfitting !!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YpUAy1PfUjZ"
      },
      "source": [
        " ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½\n",
        "\n",
        "- **Logistic Regression**: ì •í™•ë„ 0.90, F1-score 0.91ë¡œ ë¹„êµì  ì•ˆì •ì ì¸ ì„±ëŠ¥ì„ ë³´ì„  \n",
        "- **Decision Tree**: ì •í™•ë„ 0.97, F1-score 0.98ë¡œ ë§¤ìš° ë†’ì€ ìˆ˜ì¹˜ë¥¼ ê¸°ë¡  \n",
        "- **Random Forest**: ì •í™•ë„ 0.97, F1-score 0.97ë¡œ Decision Treeì™€ ìœ ì‚¬í•œ ì„±ëŠ¥ì„ ë³´ì„  \n",
        "- **XGBoost**: ì •í™•ë„ 0.98, F1-score 0.99ë¡œ ê°€ì¥ ìš°ìˆ˜í•œ ê²°ê³¼ë¥¼ ë‚˜íƒ€ëƒ„  \n",
        "- **LightGBM**: ì •í™•ë„ 0.97, F1-score 0.97ë¡œ ë†’ì€ ì„±ëŠ¥ì„ ê¸°ë¡  \n",
        "\n",
        "---\n",
        "\n",
        "ğŸ” êµì°¨ê²€ì¦ ê²°ê³¼ ë¶„ì„ (5-Fold Cross Validation)\n",
        "\n",
        "- ì¼ë°˜í™” ì„±ëŠ¥ì„ ê²€ì¦í•˜ê¸° ìœ„í•´ **Random Forest**, **XGBoost**, **LightGBM** ëª¨ë¸ì„ ëŒ€ìƒìœ¼ë¡œ êµì°¨ê²€ì¦ì„ ìˆ˜í–‰í•¨  \n",
        "- ê·¸ ê²°ê³¼, ì„¸ ëª¨ë¸ ëª¨ë‘ **í‰ê·  F1-scoreê°€ ì•½ 0.52~0.53 ìˆ˜ì¤€ìœ¼ë¡œ ê¸‰ê²©íˆ í•˜ë½**  \n",
        "\n",
        "â¡ï¸ ì´ëŠ” í•™ìŠµ ë°ì´í„°ì— ëŒ€í•œ **ê³¼ì í•©(overfitting)** ì´ ë°œìƒí–ˆìŒì„ ì˜ë¯¸í•¨  \n",
        "â¡ï¸ í›ˆë ¨ ì„¸íŠ¸ì—ì„œëŠ” ë†’ì€ ì„±ëŠ¥ì„ ë³´ì˜€ì§€ë§Œ, **ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•œ ì¼ë°˜í™” ì„±ëŠ¥ì´ ì¶©ë¶„í•˜ì§€ ì•Šì•˜ìŒ**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Decision Tree ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.89      0.89      6327\n",
            "           1       0.92      0.92      0.92      8052\n",
            "\n",
            "    accuracy                           0.91     14379\n",
            "   macro avg       0.91      0.90      0.91     14379\n",
            "weighted avg       0.91      0.91      0.91     14379\n",
            "\n",
            "\n",
            "=== Random Forest ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.94      0.93      6327\n",
            "           1       0.96      0.93      0.94      8052\n",
            "\n",
            "    accuracy                           0.94     14379\n",
            "   macro avg       0.94      0.94      0.94     14379\n",
            "weighted avg       0.94      0.94      0.94     14379\n",
            "\n",
            "\n",
            "=== Logistic Regression ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.94      0.91      6327\n",
            "           1       0.95      0.91      0.93      8052\n",
            "\n",
            "    accuracy                           0.92     14379\n",
            "   macro avg       0.92      0.92      0.92     14379\n",
            "weighted avg       0.92      0.92      0.92     14379\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#### ë¨¸ì‹ ëŸ¬ë‹ ë² ì´ìŠ¤ ë¼ì¸ ëª¨ë¸ ì„ ì • : Random Forest\n",
        "# - Decision Tree\n",
        "# - Random Forest\n",
        "# - Logistic Regression\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# 1. ë°ì´í„° ë¶„ë¦¬ (X: feature, y: target)\n",
        "df_reg = pd.read_csv('../../ML_data/dataset/reg_model_preprocessed.csv')\n",
        "X = df_reg.drop('churn', axis=1)\n",
        "y = df_reg['churn']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 2. ëª¨ë¸ ì •ì˜\n",
        "models = {\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42)\n",
        "}\n",
        "\n",
        "# 3. ëª¨ë¸ í•™ìŠµ\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "# 4. ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(classification_report(y_test, y_pred))\n",
        "# í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì„¸ë¶€ì ìœ¼ë¡œ ì¡°ì •í•˜ì§€ ì•Šì€ ê¸°ë³¸ ì„¤ì • ê¸°ì¤€ìœ¼ë¡œ ë¹„êµí–ˆì„ ë•Œ, RandomForestì˜ ì„±ëŠ¥ì´ ê°€ì¥ ë†’ê²Œ ë‚˜íƒ€ë‚¬ë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.94      0.93      6327\n",
            "           1       0.96      0.93      0.94      8052\n",
            "\n",
            "    accuracy                           0.94     14379\n",
            "   macro avg       0.94      0.94      0.94     14379\n",
            "weighted avg       0.94      0.94      0.94     14379\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ë¨¸ì‹ ëŸ¬ë‹ ë² ì´ìŠ¤ ë¼ì¸ ëª¨ë¸ : RandomForest\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# 1. ë°ì´í„° ë¶„ë¦¬ (X: feature, y: target)\n",
        "X = df_reg.drop('churn', axis=1)\n",
        "y = df_reg['churn']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 2. ëª¨ë¸ ìƒì„±\n",
        "model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "\n",
        "# 3. ëª¨ë¸ í•™ìŠµ\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 4. ì„±ëŠ¥ ì¡°íšŒ\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
