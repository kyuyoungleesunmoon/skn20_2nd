import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import seaborn as sns
import matplotlib.pyplot as plt
import joblib
from sklearn.preprocessing import StandardScaler, LabelEncoder
from scipy import stats
import os
from pathlib import Path

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ê³ ê° ì´íƒˆ ì˜ˆì¸¡ ë¶„ì„",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì‚¬ì´ë“œë°” ë„¤ë¹„ê²Œì´ì…˜
st.sidebar.title("ğŸ“‹ ëª©ì°¨")
menu = st.sidebar.radio(
    "ë¶„ì„ ë‹¨ê³„ ì„ íƒ",
    ["0. í”„ë¡œì íŠ¸ ê°œìš”", "1. ë°ì´í„° íƒìƒ‰", "2. ë°ì´í„° ì „ì²˜ë¦¬", 
     "3. ëª¨ë¸ ì„ ì • ë‹¨ê³„", "4. ìƒìœ„ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€", "5. ìµœì¢… ê²°ê³¼"]
)

# ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
@st.cache_data
def load_data(filepath):
    """CSV íŒŒì¼ ë¡œë“œ"""
    try:
        df = pd.read_csv(filepath)
        return df
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# ì´ìƒì¹˜ íƒì§€ í•¨ìˆ˜
def detect_outliers_iqr(df, column):
    """IQR ë°©ì‹ìœ¼ë¡œ ì´ìƒì¹˜ íƒì§€"""
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]
    return outliers, lower_bound, upper_bound

# ë²”ì£¼í˜• ë³€ìˆ˜ í¬ê·€ ì¹´í…Œê³ ë¦¬ íƒì§€
def detect_rare_categories(df, column, threshold=0.01):
    """1% ë¯¸ë§Œ ë¹„ìœ¨ì˜ í¬ê·€ ì¹´í…Œê³ ë¦¬ íƒì§€"""
    value_counts = df[column].value_counts(normalize=True)
    rare_categories = value_counts[value_counts < threshold]
    return rare_categories

# ====================
# 0. í”„ë¡œì íŠ¸ ê°œìš”
# ====================
if menu == "0. í”„ë¡œì íŠ¸ ê°œìš”":
    st.title("ğŸ¦ ê³ ê° ì´íƒˆ ì˜ˆì¸¡ í”„ë¡œì íŠ¸")
    st.markdown("---")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("ğŸ“Œ í”„ë¡œì íŠ¸ ì†Œê°œ")
        st.markdown("""
        ### Bank Customer Churn Prediction
        
        ë³¸ í”„ë¡œì íŠ¸ëŠ” **ì€í–‰ ê³ ê°ì˜ ì´íƒˆì„ ì˜ˆì¸¡**í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ë¶„ë¥˜ ëª¨ë¸ì„ êµ¬ì¶•í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.
        
        #### ğŸ¯ í”„ë¡œì íŠ¸ ëª©í‘œ
        - ê³ ê° ì´íƒˆ ê°€ëŠ¥ì„±ì„ ì‚¬ì „ì— ì˜ˆì¸¡í•˜ì—¬ ì„ ì œì  ëŒ€ì‘
        - ì´íƒˆ ê³ ê° íŠ¹ì„± íŒŒì•…ì„ í†µí•œ ê³ ê° ìœ ì§€ ì „ëµ ìˆ˜ë¦½
        - ë†’ì€ Recallê³¼ F1-scoreë¥¼ í†µí•œ ê· í˜•ì¡íŒ ì˜ˆì¸¡ ëª¨ë¸ ê°œë°œ
        
        #### ğŸ“Š ë°ì´í„°ì…‹ ì •ë³´
        - **ì¶œì²˜**: Kaggle - Bank Customer Churn Dataset
        - **ê·œëª¨**: 10,000ê°œ í–‰, 12ê°œ ì—´
        - **íƒ€ê²Ÿ ë³€ìˆ˜**: churn (0: ìœ ì§€, 1: ì´íƒˆ)
        """)
        
        st.markdown("---")
        
        st.subheader("ğŸ” ì£¼ìš” ë³€ìˆ˜ ì„¤ëª…")
        variable_info = pd.DataFrame({
            'ë³€ìˆ˜ëª…': ['credit_score', 'country', 'gender', 'age', 'tenure', 
                     'balance', 'products_number', 'credit_card', 'active_member', 
                     'estimated_salary', 'churn'],
            'ì„¤ëª…': ['ì‹ ìš© ì ìˆ˜', 'êµ­ê°€', 'ì„±ë³„', 'ë‚˜ì´', 'ê±°ë˜ ê¸°ê°„ (ë…„)',
                   'ê³„ì¢Œ ì”ì•¡', 'ë³´ìœ  ìƒí’ˆ ìˆ˜', 'ì‹ ìš©ì¹´ë“œ ë³´ìœ  ì—¬ë¶€', 'í™œë™ íšŒì› ì—¬ë¶€',
                   'ì˜ˆìƒ ì—°ë´‰', 'ì´íƒˆ ì—¬ë¶€ (íƒ€ê²Ÿ)'],
            'íƒ€ì…': ['ì—°ì†í˜•', 'ë²”ì£¼í˜•', 'ë²”ì£¼í˜•', 'ì—°ì†í˜•', 'ì—°ì†í˜•',
                   'ì—°ì†í˜•', 'ë²”ì£¼í˜•', 'ë²”ì£¼í˜•', 'ë²”ì£¼í˜•', 'ì—°ì†í˜•', 'ë²”ì£¼í˜•']
        })
        st.dataframe(variable_info, use_container_width=True)
    
    with col2:
        st.header("ğŸ‘¥ íŒ€ ì •ë³´")
        st.info("""
        **íŒ€ëª…**: 1ì¡°
        
        **íŒ€ì›**:
        - ê¹€ë‚˜í˜„
        - ë¬¸ì°½êµ
        - ì´ê²½í˜„
        - ì´ìŠ¹ê·œ
        - ì •ë˜ì›
        """)
        
        st.markdown("---")
        
        st.header("ğŸ“ˆ ë¶„ì„ í”„ë¡œì„¸ìŠ¤")
        st.markdown("""
        1ï¸âƒ£ **ë°ì´í„° íƒìƒ‰**
        - ê²°ì¸¡ì¹˜ ë° ì´ìƒì¹˜ í™•ì¸
        
        2ï¸âƒ£ **ë°ì´í„° ì „ì²˜ë¦¬**
        - ë‹¨ë³€ìˆ˜/ì´ë³€ìˆ˜/ë‹¤ë³€ìˆ˜ ë¶„ì„
        - ìŠ¤ì¼€ì¼ë§ ë° ì¸ì½”ë”©
        
        3ï¸âƒ£ **ëª¨ë¸ ì„ ì •**
        - 8ê°œ ëª¨ë¸ ë¹„êµ í‰ê°€
        
        4ï¸âƒ£ **ëª¨ë¸ ìµœì í™”**
        - í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
        
        5ï¸âƒ£ **ìµœì¢… ê²°ê³¼**
        - ëª¨ë¸ í•´ì„ ë° ì˜ˆì¸¡
        """)

# ====================
# 1. ë°ì´í„° íƒìƒ‰
# ====================
elif menu == "1. ë°ì´í„° íƒìƒ‰":
    st.title("ğŸ” ë°ì´í„° íƒìƒ‰ (EDA)")
    st.markdown("---")
    
    # íŒŒì¼ ì§ì ‘ ë¡œë“œ
    st.subheader("ğŸ“‚ ë°ì´í„° íŒŒì¼ ë¡œë“œ")
    
    # íŒŒì¼ ê²½ë¡œ ì„¤ì •
    current_dir = Path(__file__).parent
    data_path = current_dir / "Bank Customer Churn Prediction.csv"
    
    try:
        df_raw = pd.read_csv(data_path)
        st.success(f"âœ… ë°ì´í„° ë¡œë“œ ì„±ê³µ: `{data_path}`")
    except FileNotFoundError:
        st.error(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: `{data_path}`")
        st.info("íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()
    except Exception as e:
        st.error(f"âŒ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.stop()
    
    if df_raw is not None:
        
        # ê¸°ë³¸ ì •ë³´ í‘œì‹œ
        st.success(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {df_raw.shape[0]}í–‰ Ã— {df_raw.shape[1]}ì—´")
    
        # st.markdown("---")
        
        # ê²°ì¸¡ì¹˜ í™•ì¸
        st.subheader("ğŸ” ê²°ì¸¡ì¹˜ íƒìƒ‰")
        missing_data = df_raw.isnull().sum()
        
        col1, col2 = st.columns([1, 2])
        
        with col1:
            if missing_data.sum() == 0:
                st.success("âœ… ê²°ì¸¡ì¹˜ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")
            else:
                st.warning(f"âš ï¸ ì´ {missing_data.sum()}ê°œì˜ ê²°ì¸¡ì¹˜ ë°œê²¬")
            
            missing_df = pd.DataFrame({
                'ë³€ìˆ˜': missing_data.index,
                'ê²°ì¸¡ì¹˜ ìˆ˜': missing_data.values,
                'ë¹„ìœ¨(%)': (missing_data.values / len(df_raw) * 100).round(2)
            })
            st.dataframe(missing_df, use_container_width=True)
        
        with col2:
            fig = px.bar(
                missing_df,
                x='ë³€ìˆ˜',
                y='ê²°ì¸¡ì¹˜ ìˆ˜',
                title='ë³€ìˆ˜ë³„ ê²°ì¸¡ì¹˜ ë¶„í¬',
                color='ê²°ì¸¡ì¹˜ ìˆ˜',
                color_continuous_scale='Reds'
            )
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
        
        st.markdown("---")
        
        # ì´ìƒì¹˜ íƒìƒ‰
        st.subheader("ğŸ¯ ì´ìƒì¹˜ íƒìƒ‰")
        
        st.info("""
        **ì´ìƒì¹˜ íƒìƒ‰ ê¸°ì¤€**:
        - **ì—°ì†í˜• ë³€ìˆ˜**: IQR ê¸°ë°˜ (Q1 - 1.5Ã—IQR ë¯¸ë§Œ ë˜ëŠ” Q3 + 1.5Ã—IQR ì´ˆê³¼)
        - **ë²”ì£¼í˜• ë³€ìˆ˜**: ë¹„ìœ¨ 1% ë¯¸ë§Œì˜ í¬ê·€ ì¹´í…Œê³ ë¦¬
        """)
        
        # ì´ìƒì¹˜ ì²˜ë¦¬ ë°©ë²• ìš”ì•½
        st.subheader("ğŸ› ï¸ ì´ìƒì¹˜ ì²˜ë¦¬ ë°©ë²•")
        
        treatment_df = pd.DataFrame({
            'ë³€ìˆ˜': ['age', 'credit_score', 'products_number (ì¹´í…Œê³ ë¦¬ 4)'],
            'ì´ìƒì¹˜ ìˆ˜': ['359', '15', '60'],
            'ë¹„ìœ¨': ['3.59%', '0.15%', '0.006%'],
            'ì²˜ë¦¬ ë°©ë²•': ['í–‰ ì‚­ì œ', 'í–‰ ì‚­ì œ', 'ì¹´í…Œê³ ë¦¬ 3ê³¼ í†µí•©']
        })
        
        st.dataframe(treatment_df, use_container_width=True)
        
        st.info("""
        ğŸ“Œ **ì²˜ë¦¬ ê²°ê³¼**:
        - ageì™€ credit_scoreì˜ ì´ìƒì¹˜ëŠ” ê²¹ì¹˜ì§€ ì•Šì•„ ì´ **374ê°œ í–‰(3.74%)** ì‚­ì œ
        - products_numberì—ì„œ 4ê°œ ìƒí’ˆ ë³´ìœ  ê³ ê°(60ëª…)ì€ 3ê°œ ìƒí’ˆ ë³´ìœ  ê·¸ë£¹(266ëª…)ê³¼ í†µí•©
        """)
    
    # df_raw ë³€ìˆ˜ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥ (ë‹¤ë¥¸ í˜ì´ì§€ì—ì„œ ì‚¬ìš©)
    st.session_state['df_raw'] = df_raw

# ====================
# 2. ë°ì´í„° ì „ì²˜ë¦¬
# ====================
elif menu == "2. ë°ì´í„° ì „ì²˜ë¦¬":
    st.title("âš™ï¸ ë°ì´í„° ì „ì²˜ë¦¬ ë° EDA")
    st.markdown("---")
    
    # íŒŒì¼ ì§ì ‘ ë¡œë“œ
    current_dir = Path(__file__).parent
    data_path = current_dir / "Bank Customer Churn Prediction.csv"
    
    try:
        df = pd.read_csv(data_path)
        st.success(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {df.shape[0]}í–‰ Ã— {df.shape[1]}ì—´")
    except FileNotFoundError:
        st.error(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: `{data_path}`")
        st.stop()
    except Exception as e:
        st.error(f"âŒ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.stop()
    
    if df is not None:
        
        # ê¸°ë³¸ ì „ì²˜ë¦¬ (customer_id ì œê±°, ì¸ì½”ë”©)
        if 'customer_id' in df.columns:
            df = df.drop('customer_id', axis=1)
        
        # LabelEncoder ì ìš© (ì‹œê°í™”ìš©)
        df_encoded = df.copy()
        le = LabelEncoder()
        
        if 'gender' in df.columns and df['gender'].dtype == 'object':
            df_encoded['gender'] = le.fit_transform(df['gender'])
        if 'country' in df.columns and df['country'].dtype == 'object':
            df_encoded['country'] = le.fit_transform(df['country'])
        
        st.success(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {df.shape[0]}í–‰ Ã— {df.shape[1]}ì—´")
        
        # Expanderë¡œ í•˜ìœ„ ëª©ì°¨ êµ¬ì„±
        with st.expander("ğŸ“Š ë‹¨ë³€ìˆ˜ ë¶„ì„", expanded=False):
            st.markdown("### ë‹¨ë³€ìˆ˜ ë¶„ì„ (Univariate Analysis)")
            st.markdown("""
            ê° ë³€ìˆ˜ì˜ ê°œë³„ ë¶„í¬ë¥¼ íŒŒì•…í•˜ì—¬ ë°ì´í„°ì˜ íŠ¹ì„±ì„ ì´í•´í•©ë‹ˆë‹¤.
            - ì—°ì†í˜• ë³€ìˆ˜: ë¶„í¬ í˜•íƒœ, ì¤‘ì‹¬ ê²½í–¥, ì‚°í¬ë„
            - ë²”ì£¼í˜• ë³€ìˆ˜: ê° ë²”ì£¼ì˜ ë¹ˆë„ì™€ ë¹„ìœ¨
            """)
            
            # ë³€ìˆ˜ ì„ íƒ
            all_columns = df_encoded.columns.tolist()
            if 'churn' in all_columns:
                all_columns.remove('churn')
            
            selected_col = st.selectbox("ë¶„ì„í•  ë³€ìˆ˜ ì„ íƒ", all_columns, key="univariate")
            
            col1, col2 = st.columns([2, 1])
            
            with col1:
                # ì‹œê°í™”
                if df_encoded[selected_col].dtype in [np.float64, np.int64]:
                    # ì—°ì†í˜• ë³€ìˆ˜ - íˆìŠ¤í† ê·¸ë¨ê³¼ ë°•ìŠ¤í”Œë¡¯
                    fig = make_subplots(
                        rows=2, cols=1,
                        subplot_titles=(f'{selected_col} íˆìŠ¤í† ê·¸ë¨', f'{selected_col} ë°•ìŠ¤í”Œë¡¯'),
                        row_heights=[0.6, 0.4]
                    )
                    
                    # íˆìŠ¤í† ê·¸ë¨
                    fig.add_trace(
                        go.Histogram(x=df_encoded[selected_col], name='ë¶„í¬', 
                                   marker_color='skyblue'),
                        row=1, col=1
                    )
                    
                    # ë°•ìŠ¤í”Œë¡¯
                    fig.add_trace(
                        go.Box(x=df_encoded[selected_col], name='ë°•ìŠ¤í”Œë¡¯',
                              marker_color='lightcoral'),
                        row=2, col=1
                    )
                    
                    fig.update_layout(height=600, showlegend=False)
                    st.plotly_chart(fig, use_container_width=True)
                    
                else:
                    # ë²”ì£¼í˜• ë³€ìˆ˜ - ë§‰ëŒ€ ê·¸ë˜í”„
                    value_counts = df_encoded[selected_col].value_counts()
                    
                    fig = px.bar(
                        x=value_counts.index,
                        y=value_counts.values,
                        labels={'x': selected_col, 'y': 'ë¹ˆë„'},
                        title=f'{selected_col} ë¶„í¬',
                        color=value_counts.values,
                        color_continuous_scale='Blues'
                    )
                    fig.update_layout(height=400)
                    st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                # ê¸°ì´ˆ í†µê³„ëŸ‰
                st.markdown("#### ğŸ“ˆ ê¸°ì´ˆ í†µê³„")
                if df_encoded[selected_col].dtype in [np.float64, np.int64]:
                    stats_df = pd.DataFrame({
                        'í†µê³„ëŸ‰': ['í‰ê· ', 'ì¤‘ì•™ê°’', 'í‘œì¤€í¸ì°¨', 'ìµœì†Œê°’', 'ìµœëŒ€ê°’', 'ì™œë„', 'ì²¨ë„'],
                        'ê°’': [
                            f"{df_encoded[selected_col].mean():.2f}",
                            f"{df_encoded[selected_col].median():.2f}",
                            f"{df_encoded[selected_col].std():.2f}",
                            f"{df_encoded[selected_col].min():.2f}",
                            f"{df_encoded[selected_col].max():.2f}",
                            f"{df_encoded[selected_col].skew():.2f}",
                            f"{df_encoded[selected_col].kurtosis():.2f}"
                        ]
                    })
                    st.dataframe(stats_df, use_container_width=True)
                else:
                    value_counts = df_encoded[selected_col].value_counts()
                    pct = (value_counts / len(df_encoded) * 100).round(2)
                    stats_df = pd.DataFrame({
                        'ì¹´í…Œê³ ë¦¬': value_counts.index,
                        'ë¹ˆë„': value_counts.values,
                        'ë¹„ìœ¨(%)': pct.values
                    })
                    st.dataframe(stats_df, use_container_width=True)
            
            # ì¸ì‚¬ì´íŠ¸
            st.markdown("---")
            st.markdown("#### ğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸")
            
            insights = {
                'credit_score': "- ì‹ ìš© ì ìˆ˜ëŠ” ëŒ€ì²´ë¡œ ì •ê·œë¶„í¬ë¥¼ ë”°ë¥´ë©°, 400ì´ í•˜í•œì´ê³  ì´ë¥¼ ë„˜ëŠ” ì´ìƒì¹˜ê°€ ì¡´ì¬\n- ì‹ ìš© ì ìˆ˜ê°€ ë‚®ì•„ì§ˆìˆ˜ë¡ ì‚¬ëŒ ìˆ˜ê°€ ì ì–´ì§€ë©°, ê°ìê¸° ì¦ê°€í•˜ëŠ” êµ¬ê°„ì´ ì¡´ì¬(600~850)",
                'age': "- 50%ì˜ ë°ì´í„°ê°€ 32~44ì„¸ì— ë°€ì§‘\n- ê³ ë ¹ì¸µì˜ ìˆ˜ëŠ” ì ìŒ\n- ì´ìƒì¹˜ê°€ ë§ìŒ(387ê°œ) â‡’ boxplotì—ì„œ 62ì„¸ ì´ìƒì€ ì „ë¶€ ì´ìƒì¹˜ë¡œ íŒë‹¨ë¨",
                'balance': "- histplotì„ ë³´ë‹ˆ, ì”ê³ ê°€ 0ì¸ ê³ ê°ì´ ë§¤ìš° ë§ìŒ\n- ì”ê³ ê°€ 0ì¸ ê³ ê°ì´ ì „ì²´ ê³ ê°ì˜ 36.5%",
                'estimated_salary': "- Q2ê°€ ìƒìì˜ ì •ì¤‘ì•™ì— ì˜¤ê³ , ìœ„ ì•„ë˜ ìˆ˜ì—¼ ê¸¸ì´ë„ ë¹„ìŠ·í•¨\n- ì—°ë´‰ ë¶„í¬ëŠ” ë°ì´í„°ê°€ ëŒ€ì¹­/ê³ ë¥´ê²Œ ë¶„í¬ë˜ì—ˆìŒ",
                'products_number': "- 1ê°œ(50.84%)ë‚˜ 2ê°œ(45.9%)ì˜ ìƒí’ˆì„ ì´ìš©í•˜ëŠ” ê³ ê°ì´ ë§ìŒ\n- 4ê°œ ìƒí’ˆ ì´ìš© ê³ ê°ì€ ë§¤ìš° ì ìŒ",
                'country': "- í”„ë‘ìŠ¤ 50.1%, ìŠ¤í˜ì¸ 24.8%, ë…ì¼ 25.1%\n- ê³ ê°ì¸µì´ 50%ê°€ í”„ë‘ìŠ¤",
                'gender': "- ë‚¨ì 54.6%, ì—¬ì 45.4%ë¡œ ì„±ë¹„ ë¹„ìŠ·",
                'credit_card': "- ë³´ìœ  70.5%, ë¯¸ë³´ìœ  29.5%",
                'active_member': "- í™œë™ì¤‘ì¸ íšŒì› 51.5%, ë¹„í™œë™ì¤‘ì¸ íšŒì› 48.5%ë¡œ ë¹„ìŠ·í•¨",
                'tenure': "- 0ë…„(ê±°ë˜ ê°€ì…í•œ ê³ ê°)ì´ 10ë…„ì€ 400ëª…ëŒ€\n- ë‚˜ë¨¸ì§€ ê¸°ê°„(1ë…„~6ë…„)ì€ ëŒ€ì²´ë¡œ ë¹„ìŠ·í•œ ìˆ˜ì¤€ì„(800~1000ëª…ëŒ€)"
            }
            
            if selected_col in insights:
                st.info(insights[selected_col])
            else:
                st.info("í•´ë‹¹ ë³€ìˆ˜ì— ëŒ€í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤.")
        
        with st.expander("ğŸ”— ì´ë³€ìˆ˜ ë¶„ì„", expanded=False):
            st.markdown("### ì´ë³€ìˆ˜ ë¶„ì„ (Bivariate Analysis)")
            st.markdown("""
            ê° ë³€ìˆ˜ì™€ íƒ€ê²Ÿ ë³€ìˆ˜(churn) ê°„ì˜ ê´€ê³„ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.
            ì´ë¥¼ í†µí•´ ì´íƒˆì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ìš”ì¸ì„ ì‹ë³„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            """)
            
            # ë³€ìˆ˜ ì„ íƒ (churn ì œì™¸)
            feature_cols = [col for col in df_encoded.columns if col != 'churn']
            selected_feature = st.selectbox("ë¹„êµí•  ë³€ìˆ˜ ì„ íƒ", feature_cols, key="bivariate")
            
            col1, col2 = st.columns([2, 1])
            
            with col1:
                if df_encoded[selected_feature].dtype in [np.float64, np.int64]:
                    # ì—°ì†í˜• ë³€ìˆ˜ - ë°•ìŠ¤í”Œë¡¯
                    fig = px.box(
                        df_encoded,
                        x='churn',
                        y=selected_feature,
                        color='churn',
                        title=f'{selected_feature} vs Churn',
                        labels={'churn': 'ì´íƒˆ ì—¬ë¶€', selected_feature: selected_feature},
                        color_discrete_map={0: 'lightblue', 1: 'lightcoral'}
                    )
                    fig.update_layout(height=500)
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    # ë²”ì£¼í˜• ë³€ìˆ˜ - ìŠ¤íƒ ë°” ì°¨íŠ¸
                    cross_tab = pd.crosstab(df_encoded[selected_feature], df_encoded['churn'])
                    
                    fig = go.Figure()
                    
                    fig.add_trace(go.Bar(
                        x=cross_tab.index,
                        y=cross_tab[0],
                        name='ìœ ì§€ (0)',
                        marker_color='lightblue'
                    ))
                    
                    fig.add_trace(go.Bar(
                        x=cross_tab.index,
                        y=cross_tab[1],
                        name='ì´íƒˆ (1)',
                        marker_color='lightcoral'
                    ))
                    
                    fig.update_layout(
                        title=f'{selected_feature} vs Churn',
                        xaxis_title=selected_feature,
                        yaxis_title='ê³ ê° ìˆ˜',
                        barmode='stack',
                        height=500
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                st.markdown("#### ğŸ“Š ì´íƒˆë¥  ë¹„êµ")
                
                if 'churn' in df_encoded.columns:
                    if df_encoded[selected_feature].dtype in [np.float64, np.int64]:
                        # ì—°ì†í˜• ë³€ìˆ˜ - ì´íƒˆ/ìœ ì§€ ê·¸ë£¹ë³„ í†µê³„
                        churn_stats = df_encoded.groupby('churn')[selected_feature].agg([
                            ('í‰ê· ', 'mean'),
                            ('ì¤‘ì•™ê°’', 'median'),
                            ('í‘œì¤€í¸ì°¨', 'std')
                        ]).round(2)
                        churn_stats.index = ['ìœ ì§€ (0)', 'ì´íƒˆ (1)']
                        st.dataframe(churn_stats, use_container_width=True)
                    else:
                        # ë²”ì£¼í˜• ë³€ìˆ˜ - ê° ì¹´í…Œê³ ë¦¬ë³„ ì´íƒˆë¥ 
                        churn_rate = df_encoded.groupby(selected_feature)['churn'].agg([
                            ('ì „ì²´', 'count'),
                            ('ì´íƒˆ', 'sum'),
                            ('ì´íƒˆë¥ (%)', lambda x: (x.sum()/len(x)*100).round(2))
                        ])
                        st.dataframe(churn_rate, use_container_width=True)
            
            # ì¸ì‚¬ì´íŠ¸
            st.markdown("---")
            st.markdown("#### ğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸")
            
            bivariate_insights = {
                'credit_score': "- ì „ë°˜ì  ì‹ ìš©ì ìˆ˜ ë¶„í¬ ì°¨ì´ëŠ” ì—†ì–´ë³´ì„ (ì´íƒˆì¸ê³¼ ìœ ì§€ì¸ì˜ IQR ë²”ìœ„ê°€ ìœ ì‚¬)\n- ë‹¤ë§Œ, ì´íƒˆ ì§‘ë‹¨ì—ì„œ ì‹ ìš©ì ìˆ˜ê°€ 4000ì´í•˜ì˜ ì´ìƒì¹˜ê°€ ë‹¤ìˆ˜ ë°œê²¬ë¨ (íŠ¹ì´ì : ì´íƒˆì§‘ë‹¨ì˜ credit_score < 4000 ê·¹ë‹¨ì  ì €ì‹ ìš© ê³ ê°ë“¤ì´ ì¡´ì¬í•˜ì—¬ ì¡°ê¸° ì´íƒˆ)",
                'age': "- ì´íƒˆ ì§‘ë‹¨ì´ ë³´ì ì „ë°˜ë³´ë‹¤ ì—°ë ¹ëŒ€ê°€ ë†’ìŒ(40ì¤‘ë°˜~50ì´ˆë°˜)\n- ìœ ì§€ ì§‘ë‹¨ì€ ì—°ë ¹ëŒ€ë³´ë‹¤ ì ŠìŒ(30ì´ˆ~40ì´ˆ)",
                'balance': "- ì´íƒˆ ì§‘ë‹¨ì˜ ì”ê³  í‰ê· ì´ ì¡°ê¸ˆ ë” ë†’ìŒ\n- ìœ ì§€ ì§‘ë‹¨ì´ ì´íƒˆ ì§‘ë‹¨ë³´ë‹¤ IQR ë¶„í¬ê°€ ì•„ë˜ìª½ìœ¼ë¡œ ë” ë„“ìŒ\n- ìœ ì§€ ê³ ê°ì„ ì”ê³ í•˜ê°€ ì ì€ ì‚¬ëŒì´ ë§ìŒ\n- ìœ ì§€ ì§‘ë‹¨ì€ ì”ì•¡ì´ 0ì¸ ê³ ê°ì´ ë§ìŒ â‡’ ì”ì•¡ì´ ì—†ìœ¼ë©´ ì´íƒˆ ê°€ëŠ¥ì„± ë‚®ìŒ",
                'estimated_salary': "- ì „ë°˜ì  ì—°ë´‰ ë¶„í¬ëŠ” ë¹„ìŠ·í•¨",
                'products_number': "- ì´íƒˆì§‘ë‹¨ì˜ ì´ìš©ìƒí’ˆìˆ˜ 1ê°œ >>> 2ê°œ > 3ê°œ > 4ê°œ\n- ìœ ì§€ì§‘ë‹¨ì˜ ì´ìš©ìƒí’ˆìˆ˜ 2ê°œ > 1ê°œ\n- ìœ ì§€ì§‘ë‹¨ ê³ ê°ì—ì„œëŠ” 0ì¸ êµ­ê°€ë¡œí‘œì‹œì˜ ë¹„ìœ¨ì´ ê°€ì¥ ë†’ìŒ\n- ì´íƒˆ ì§‘ë‹¨ì€ 2ë²ˆ(ë…ì¼)>0ë²ˆ(í”„ë‘ìŠ¤)>1ë²ˆ(ìŠ¤í˜ì¸) ìˆœìœ¼ë¡œ ë§ìŒ",
                'country': "- ìœ ì§€ ì§‘ë‹¨ ì¤‘ì—ì„œëŠ” 0ì¸ êµ­ê°€í‘œì‹œì˜ ë¹„ìœ¨ì´ ê°€ì¥ ë†’ìŒ\n- ì´íƒˆ ì§‘ë‹¨ì€ 2ë²ˆ êµ­ê°€(ë…ì¼)ì˜ ì´íƒˆë¥ ì´ ì ˆë°˜ ì •ë„ë¡œ ë†’ìŒ",
                'gender': "- ìœ ì§€ ì§‘ë‹¨ì—ì„œ ë‚¨ì„±ê³¼ ë¹„ìœ¨ì´ ë†’ìŒ\n- ì´íƒˆ ì§‘ë‹¨ì—ì„œ ì—¬ì ë¹„ìœ¨ì´ ë†’ìŒ",
                'credit_card': "- ìœ ì§€ì§‘ë‹¨/ì´íƒˆì§‘ë‹¨ ê°„ ì‹ ìš©ì¹´ë“œ ë³´ìœ  ì—¬ë¶€ëŠ” ë¹„ìŠ·í•¨\n- ì‹ ìš©ì¹´ë“œë¥¼ ë³´ìœ í•˜ë©´ ë”°ë¥¸ ì´íƒˆ ì°¨ì´ëŠ” ì—†ìŒ",
                'active_member': "- ì´íƒˆ ì§‘ë‹¨ì¼ìˆ˜ë¡ ë¹„í™œë™íšŒì›ì˜ ë§ìŒ\n- ìœ ì§€ ì§‘ë‹¨ì¼ìˆ˜ë¡ í™œë™íšŒì›ì´ ë†’ìŒ\n- ë¹„í™œë™ì§‘ë‹¨ì¼ìˆ˜ë¡ ì´íƒˆë¥ ì´ ë†’ìŒ",
                'tenure': "- ì¹´í…Œê³ ë¦¬ë¡œ 10ê°œë¡œ ë§ì•„ì„œ ê·¸ë˜í”„ìƒ ëˆˆì— ë„ëŠ” íŒ¨í„´ì€ ì—†ìŒ"
            }
            
            if selected_feature in bivariate_insights:
                st.info(bivariate_insights[selected_feature])
            else:
                st.info("í•´ë‹¹ ë³€ìˆ˜ì— ëŒ€í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤.")
        
        with st.expander("ğŸ”¢ ë‹¤ë³€ìˆ˜ ë¶„ì„", expanded=False):
            st.markdown("### ë‹¤ë³€ìˆ˜ ë¶„ì„ (Multivariate Analysis)")
            st.markdown("""
            3ê°œ ì´ìƒì˜ ë³€ìˆ˜ ê°„ ê´€ê³„ë¥¼ ë¶„ì„í•˜ì—¬ ë³µì¡í•œ íŒ¨í„´ì„ íŒŒì•…í•©ë‹ˆë‹¤.
            - ìƒê´€ê´€ê³„ ë¶„ì„ (Correlation Analysis)
            - ë‹¤ì¤‘ê³µì„ ì„± ê²€í†  (VIF)
            """)
            
            st.markdown("---")
            st.markdown("#### ğŸ”„ ë°ì´í„° ì „ì²˜ë¦¬")
            st.info("""
            **Scaling (í‘œì¤€í™”)**:
            - ì—°ì†í˜• ë³€ìˆ˜ì˜ í‰ê· ì„ 0, ë¶„ì‚°ì„ 1ë¡œ ë³€í™˜
            - StandardScaler ì ìš©
            
            **Encoding (ì¸ì½”ë”©)**:
            - ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ One-Hot Encodingìœ¼ë¡œ ë³€í™˜
            - ê° ì¹´í…Œê³ ë¦¬ë¥¼ ë³„ë„ì˜ ì´ì§„ ë³€ìˆ˜ë¡œ ë¶„ë¦¬
            """)
            
            # ìŠ¤ì¼€ì¼ë§ ë° ì¸ì½”ë”© ìˆ˜í–‰
            from sklearn.preprocessing import StandardScaler
            
            # ì—°ì†í˜• ë³€ìˆ˜ ìŠ¤ì¼€ì¼ë§
            continuous_features = df_encoded.select_dtypes(include=[np.number]).columns.tolist()
            if 'churn' in continuous_features:
                continuous_features.remove('churn')
            
            df_scaled = df_encoded.copy()
            scaler = StandardScaler()
            df_scaled[continuous_features] = scaler.fit_transform(df_encoded[continuous_features])
            
            # One-Hot Encoding (ì´ë¯¸ ì¸ì½”ë”©ëœ ê²½ìš° ë”ë¯¸ ë³€ìˆ˜ ìƒì„±)
            categorical_features = []
            for col in ['gender', 'country', 'credit_card', 'active_member', 'products_number']:
                if col in df_scaled.columns:
                    categorical_features.append(col)
            
            if len(categorical_features) > 0:
                df_encoded_full = pd.get_dummies(df_scaled, columns=categorical_features, drop_first=False)
            else:
                df_encoded_full = df_scaled.copy()
            
            st.markdown("---")
            st.markdown("#### ğŸ“Š ìƒê´€ê´€ê³„ ë¶„ì„ (Pearson Correlation)")
            
            # ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ
            corr_matrix = df_encoded_full.corr()
            
            fig = px.imshow(
                corr_matrix,
                labels=dict(color="ìƒê´€ê³„ìˆ˜"),
                x=corr_matrix.columns,
                y=corr_matrix.columns,
                color_continuous_scale='RdBu_r',
                zmin=-1, zmax=1,
                title="ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ"
            )
            fig.update_layout(height=700)
            st.plotly_chart(fig, use_container_width=True)
            
            # # Churnê³¼ì˜ ìƒê´€ê´€ê³„
            # st.markdown("#### ğŸ¯ Churnê³¼ì˜ ìƒê´€ê´€ê³„")
            
            if 'churn' in corr_matrix.columns:
                churn_corr = corr_matrix['churn'].drop('churn').sort_values(ascending=False)
            
            st.markdown("---")
            st.markdown("#### ğŸ” ë‹¤ì¤‘ê³µì„ ì„± ê²€í†  (VIF)")
            
            st.info("""
            **ë‹¤ì¤‘ê³µì„ ì„±: íŠ¹ì • ë³€ìˆ˜ê°€ ë‹¤ë¥¸ ë³€ìˆ˜ë“¤ê³¼ ê°•í•œ ì„ í˜•ê´€ê³„ë¥¼ ê°€ì§€ëŠ” í˜„ìƒ. ë‹¤ì¤‘ê³µì„ ì„±ì´ ì¡´ì¬í•  ê²½ìš° ëª¨ë¸ í•´ì„ë ¥ ì €í•˜ë¥¼ ì´ˆë˜í•  ìˆ˜ ìˆìŒ.
                           
            ë‹¤ì¤‘ê³µì„ ì„± ì¸¡ì • ì§€í‘œ VIF (Variance Inflation Factor)**:
            - VIF = 1: ë‹¤ë¥¸ ë³€ìˆ˜ë“¤ê³¼ ì „í˜€ ìƒê´€ê´€ê³„ê°€ ì—†ìŒ
            - 1 < VIF < 5: ì•½í•œ~ì¤‘ê°„ ì •ë„ì˜ ìƒê´€ê´€ê³„
            - 5 < VIF < 10: ë†’ì€ ìƒê´€ê´€ê³„, ì£¼ì˜ í•„ìš”
            - VIF > 10: ì‹¬ê°í•œ ë‹¤ì¤‘ê³µì„ ì„±, ë³€ìˆ˜ ì œê±° ê³ ë ¤
            """)
            
            # VIF ê³„ì‚°ì€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ë¯€ë¡œ ê²°ê³¼ë§Œ í‘œì‹œ
            st.markdown("##### ğŸ“Š ë³¸ ë°ì´í„°ì…‹ì˜ VIF ì¸¡ì • ê²°ê³¼")
            
            vif_data = pd.DataFrame({
                'feature': ['credit_score', 'age', 'tenure', 'balance', 'estimated_salary', 
                          'churn', 'country_1', 'country_2', 'gender_1', 'credit_card_1',
                          'active_member_1', 'products_number_2', 'products_number_3', 'products_number_4'],
                'VIF': [1.001658, 1.110699, 1.002220, 1.401081, 1.001055,
                       1.352674, 1.125197, 1.371610, 1.013243, 1.001673,
                       1.047173, 1.290294, 1.087827, 1.029537]
            })
            
            st.dataframe(vif_data, use_container_width=True)
            
            st.success("""
            âœ… **ê²°ê³¼ í•´ì„**:
            - ëª¨ë“  ë³€ìˆ˜ì˜ VIF ê°’ì´ 1ì ëŒ€ë¡œ í™•ì¸ë¨
            - ê° ë…ë¦½ë³€ìˆ˜ ê°„ì˜ ìƒê´€ì„±ì´ ë‚®ê³ , ìƒí˜¸ ë…ë¦½ì„±ì´ í™•ë³´ë¨
            - **ë³€ìˆ˜ ì œê±°ë‚˜ ì°¨ì› ì¶•ì†Œ(PCA) ë“±ì˜ ì¶”ê°€ ì¡°ì¹˜ëŠ” ë¶ˆí•„ìš”**
            """)
        
        with st.expander("ğŸ”§ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸", expanded=False):
            st.markdown("### ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸")
            st.markdown("""
            ëª¨ë¸ë§ ë‹¨ê³„ì—ì„œ ì‚¬ìš©í•  ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.
            - **ColumnTransformer**: ì—°ì†í˜•/ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ ë¶„ë¦¬í•˜ì—¬ ì²˜ë¦¬
            - **Pipeline**: ì „ì²˜ë¦¬ì™€ ëª¨ë¸ì„ í•˜ë‚˜ì˜ íë¦„ìœ¼ë¡œ í†µí•©
            """)
            
            st.markdown("---")
            st.markdown("#### ğŸ“‹ ì „ì²˜ë¦¬ ì„¤ì •")
            
            pipeline_info = pd.DataFrame({
                'êµ¬ë¶„': ['ì—°ì†í˜• ë³€ìˆ˜', 'ë²”ì£¼í˜• ë³€ìˆ˜', 'ë°ì´í„° ë¶„í• ', 'í´ë˜ìŠ¤ ë¶ˆê· í˜•', 'ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€'],
                'ì²˜ë¦¬ ë‚´ìš©': [
                    'StandardScaler / MinMaxScaler (ëª¨ë¸ ìœ í˜•ë³„ ì„ íƒ)',
                    "OneHotEncoder(drop='first', handle_unknown='ignore')",
                    "train_test_split(test_size=0.2, stratify=y, random_state=42)",
                    "Churn=1 ë¹„ìœ¨ ì•½ 20.3% â†’ Stratified Split ì ìš©ìœ¼ë¡œ ìœ ì§€",
                    "Pipeline ë‚´ë¶€ì—ì„œ fitì€ train ë°ì´í„°ì—ë§Œ ìˆ˜í–‰ í›„ testì—ëŠ” transform ì ìš©"
                ]
            })
            
            st.dataframe(pipeline_info, use_container_width=True)
            
            st.markdown("---")
            st.markdown("#### ğŸ”„ íŒŒì´í”„ë¼ì¸ êµ¬ì¡°")
            
            st.code("""
# ColumnTransformer êµ¬ì„±
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), continuous_features),
        ('cat', OneHotEncoder(drop='first'), categorical_features)
    ])

# Pipeline êµ¬ì„±
pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('model', model)
])

# í•™ìŠµ ë° ì˜ˆì¸¡
pipeline.fit(X_train, y_train)
y_pred = pipeline.predict(X_test)
            """, language='python')
            
            st.info("""
            ğŸ’¡ **ì¥ì **:
            - ë°ì´í„° ëˆ„ìˆ˜(Data Leakage) ë°©ì§€
            - ì½”ë“œ ì¬ì‚¬ìš©ì„± ë° ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ
            - ëª¨ë¸ ë³€ê²½ ì‹œì—ë„ ë™ì¼í•œ ì „ì²˜ë¦¬ ì ìš© ë³´ì¥
            """)
        
        # dfë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
        st.session_state['df_processed'] = df_encoded

# ====================
# 3. ëª¨ë¸ ì„ ì • ë‹¨ê³„
# ====================
elif menu == "3. ëª¨ë¸ ì„ ì • ë‹¨ê³„":
    st.title("ğŸ¤– ëª¨ë¸ ì„ ì • ë‹¨ê³„")
    st.markdown("---")
    
    st.markdown("""
    ### ğŸ“Œ ëª¨ë¸ ì„ ì • ëª©ì 
    
    ë³¸ í”„ë¡œì íŠ¸ì˜ ëª©í‘œëŠ” **ì€í–‰ ê³ ê°ì˜ ì´íƒˆì„ ì˜ˆì¸¡**í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
    ì´ë¥¼ ìœ„í•´ ë‹¤ì–‘í•œ ë¶„ë¥˜ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ì„±ëŠ¥ì„ ë¹„êµí•˜ì—¬ ìµœì ì˜ ëª¨ë¸ì„ ì„ ì •í•©ë‹ˆë‹¤.
    
    #### ğŸ¯ í‰ê°€ ê¸°ì¤€
    - **Recall (ì¬í˜„ìœ¨)**: ì‹¤ì œ ì´íƒˆ ê³ ê°ì„ ì–¼ë§ˆë‚˜ ì˜ ì°¾ì•„ë‚´ëŠ”ê°€?
    - **F1-score**: Precisionê³¼ Recallì˜ ì¡°í™” í‰ê·  (ê· í˜•ì¡íŒ ì„±ëŠ¥)
    - **ì¼ë°˜í™” ì„±ëŠ¥**: Train/Test ì ìˆ˜ ì°¨ì´ê°€ ì ì€ ëª¨ë¸
    """)
    
    st.markdown("---")
    
    st.subheader("ğŸ”¬ í•™ìŠµ ë° í‰ê°€ ëª¨ë¸ (ì´ 8ê°œ)")
    
    models_info = pd.DataFrame({
        'ëª¨ë¸ëª…': [
            'Logistic Regression',
            'K-Nearest Neighbors (KNN)',
            'Support Vector Machine (SVM)',
            'Decision Tree',
            'Random Forest',
            'Bagging',
            'AdaBoost',
            'Neural Network (MLP)'
        ],
        'ëª¨ë¸ ìœ í˜•': [
            'ì„ í˜• ëª¨ë¸',
            'ê±°ë¦¬ ê¸°ë°˜',
            'ì„œí¬íŠ¸ ë²¡í„°',
            'íŠ¸ë¦¬ ê¸°ë°˜',
            'ì•™ìƒë¸” (íŠ¸ë¦¬)',
            'ì•™ìƒë¸” (ë°°ê¹…)',
            'ì•™ìƒë¸” (ë¶€ìŠ¤íŒ…)',
            'ì‹ ê²½ë§'
        ],
        'íŠ¹ì§•': [
            'í•´ì„ ê°€ëŠ¥, ë¹ ë¥¸ í•™ìŠµ',
            'ê±°ë¦¬ ê¸°ë°˜ ë¶„ë¥˜, ë‹¨ìˆœ',
            'ë¹„ì„ í˜• ê²½ê³„, ê³ ì°¨ì› ì í•©',
            'í•´ì„ ê°€ëŠ¥, ê³¼ì í•© ìœ„í—˜',
            'ê°•ë ¥í•œ ì„±ëŠ¥, ê³¼ì í•© ë°©ì§€',
            'ë¶„ì‚° ê°ì†Œ, ì•ˆì •ì„±',
            'ì•½í•œ í•™ìŠµê¸° ê²°í•©',
            'ë³µì¡í•œ íŒ¨í„´ í•™ìŠµ'
        ]
    })
    
    st.dataframe(models_info, use_container_width=True)
    
    st.markdown("---")
    
    st.subheader("ğŸ“Š Baseline ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")
    
    st.info("""
    **Baseline ì„¤ì •**:
    - ëª¨ë“  ëª¨ë¸ì€ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ê¸°ë³¸ê°’(default)ìœ¼ë¡œ ì„¤ì •
    - ë™ì¼í•œ ë°ì´í„° ë¶„í•  ì ìš© (train 80% / test 20%)
    - Stratified Splitìœ¼ë¡œ í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€
    """)
    
    # ì„±ëŠ¥ ë°ì´í„°
    baseline_results = pd.DataFrame({
        'Model': ['AdaBoost', 'NN', 'Bagging', 'LogisticRegression', 
                  'RandomForest', 'SVM', 'KNN', 'DecisionTree'],
        'ROC_AUC': [0.8464, 0.8547, 0.8186, 0.8487, 0.8501, np.nan, 0.7995, 0.6919],
        'Accuracy': [0.8634, 0.8609, 0.8505, 0.8598, 0.8577, 0.8634, 0.8406, 0.7970],
        'F1': [0.6021, 0.5864, 0.5727, 0.5714, 0.5595, 0.5504, 0.5165, 0.5069],
        'Recall': [0.5103, 0.4872, 0.4949, 0.4615, 0.4462, 0.4128, 0.4205, 0.5154]
    })
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.markdown("#### ğŸ“‹ ì„±ëŠ¥ ì§€í‘œ (Test ë°ì´í„°)")
        st.dataframe(baseline_results.style.highlight_max(subset=['F1', 'Recall'], color='lightgreen'), 
                    use_container_width=True)
    
    with col2:
        st.markdown("#### ğŸ“ˆ ëª¨ë¸ë³„ F1-Score ë° Recall ë¹„êµ")
        
        fig = go.Figure()
        
        fig.add_trace(go.Bar(
            x=baseline_results['Model'],
            y=baseline_results['F1'],
            name='F1-Score',
            marker_color='skyblue'
        ))
        
        fig.add_trace(go.Bar(
            x=baseline_results['Model'],
            y=baseline_results['Recall'],
            name='Recall',
            marker_color='lightcoral'
        ))
        
        fig.update_layout(
            barmode='group',
            xaxis_title='ëª¨ë¸',
            yaxis_title='ì ìˆ˜',
            height=400,
            legend=dict(x=0.7, y=1)
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    st.markdown("---")
    
    st.subheader("ğŸ† ìƒìœ„ 3ê°œ ëª¨ë¸ ì„ ì •")
    
    st.success("""
    **ì„ ì • ê¸°ì¤€**:
    - F1-Scoreì™€ Recallì´ ëª¨ë‘ ì–‘í˜¸
    - Trainê³¼ Test ì ìˆ˜ ì°¨ì´ê°€ ì ìŒ (ê³¼ì í•© ë°©ì§€)
    
    **ì„ ì •ëœ ëª¨ë¸**:
    1. â­ **Logistic Regression** (F1: 0.5714, Recall: 0.4615)
    2. â­ **AdaBoost** (F1: 0.6021, Recall: 0.5103)
    3. â­ **Random Forest** (F1: 0.5595, Recall: 0.4462)
    """)
    
    # ì„ ì • ëª¨ë¸ ë¹„êµ
    top3_models = baseline_results[baseline_results['Model'].isin(['LogisticRegression', 'AdaBoost', 'RandomForest'])]
    
    fig = go.Figure()
    
    metrics = ['Accuracy', 'F1', 'Recall']
    colors = ['lightblue', 'lightgreen', 'lightcoral']
    
    for i, metric in enumerate(metrics):
        fig.add_trace(go.Bar(
            x=top3_models['Model'],
            y=top3_models[metric],
            name=metric,
            marker_color=colors[i]
        ))
    
    fig.update_layout(
        title='ìƒìœ„ 3ê°œ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ',
        xaxis_title='ëª¨ë¸',
        yaxis_title='ì ìˆ˜',
        barmode='group',
        height=400
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    st.info("""
    ğŸ’¡ **ë‹¤ìŒ ë‹¨ê³„**:
    ì„ ì •ëœ 3ê°œ ëª¨ë¸ì— ëŒ€í•´ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ ì§„í–‰í•˜ì—¬ ì„±ëŠ¥ì„ ìµœì í™”í•©ë‹ˆë‹¤.
    """)

# ====================
# 4. ìƒìœ„ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
# ====================
elif menu == "4. ìƒìœ„ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€":
    st.title("ğŸ¯ ìƒìœ„ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€")
    st.markdown("---")
    
    st.header("ğŸ“¦ í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ")
    
    # ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ì„¤ì •
    current_dir = Path(__file__).parent
    model_files = {
        'RandomForest': f'{current_dir}\\randomforest_model.pkl',
        'AdaBoost': f'{current_dir}\\adaboost_model.pkl',
        'LogisticRegression': f'{current_dir}\\logisticregression_model.pkl'
    }
    
    loaded_models = {}
    missing_models = []
    
    # ëª¨ë¸ ë¡œë“œ ë¡œê·¸
    st.info("ğŸ”„ ëª¨ë¸ ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    # í”„ë¡œê·¸ë ˆìŠ¤ ë°”
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # ëª¨ë¸ ë¡œë“œ
    for idx, (name, filepath) in enumerate(model_files.items()):
        status_text.text(f"ë¡œë”© ì¤‘: {name}...")
        try:
            loaded_models[name] = joblib.load(filepath)
            st.success(f"âœ… {name} ëª¨ë¸ ë¡œë“œ ì„±ê³µ - `{filepath}`")
        except FileNotFoundError:
            missing_models.append(name)
            st.error(f"âŒ {name} ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: `{filepath}`")
        except Exception as e:
            missing_models.append(name)
            st.error(f"âŒ {name} ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        # í”„ë¡œê·¸ë ˆìŠ¤ ë°” ì—…ë°ì´íŠ¸
        progress_bar.progress((idx + 1) / len(model_files))
    
    status_text.text("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
    
    if missing_models:
        st.warning(f"""
        âš ï¸ ì¼ë¶€ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {', '.join(missing_models)}
        
        ë…¸íŠ¸ë¶ì—ì„œ ëª¨ë¸ì„ ë¨¼ì € í•™ìŠµí•˜ê³  ì €ì¥í•´ì£¼ì„¸ìš”.
        """)
        st.stop()
    else:
        st.success(f"ğŸ‰ ì´ {len(loaded_models)}ê°œì˜ ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
    st.session_state['loaded_models'] = loaded_models
    
    st.markdown("---")
    
    st.subheader("âš™ï¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹")
    
    st.markdown("""
    ### ğŸ”§ íŠœë‹ ë°©ë²•: RandomizedSearchCV
    
    - **íƒìƒ‰ ë°©ë²•**: ëœë¤ ì„œì¹˜ (íš¨ìœ¨ì ì¸ íƒìƒ‰)
    - **êµì°¨ ê²€ì¦**: 5-Fold Cross Validation
    - **í‰ê°€ ì§€í‘œ**: F1-Score (ì´íƒˆ ê³ ê° íƒì§€ ì¤‘ì‹œ)
    - **íƒìƒ‰ íšŸìˆ˜**: n_iter=30
    """)
    
    st.markdown("---")
    
    # íŠœë‹ ê²°ê³¼
    st.subheader("ğŸ“Š í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ê²°ê³¼")
    
    tuning_params = pd.DataFrame({
        'ëª¨ë¸': ['Logistic Regression', 'Random Forest', 'AdaBoost'],
        'ì£¼ìš” í•˜ì´í¼íŒŒë¼ë¯¸í„°': [
            "C=77.97, penalty='l1', solver='saga', max_iter=1544",
            "n_estimators=104, max_depth=17, max_features='log2', min_samples_split=13, min_samples_leaf=3",
            "n_estimators=285, learning_rate=1.23"
        ]
    })
    
    st.dataframe(tuning_params, use_container_width=True)
    
    st.markdown("---")
    
    st.subheader("ğŸ“ˆ íŠœë‹ í›„ ëª¨ë¸ ì„±ëŠ¥")
    
    tuned_results = pd.DataFrame({
        'Model': ['RandomForest', 'AdaBoost', 'LogisticRegression'],
        'ROC_AUC': [0.856, 0.846, 0.847],
        'Accuracy': [0.858, 0.864, 0.784],
        'F1': [0.649, 0.593, 0.585],
        'Recall': [0.649, 0.487, 0.751]
    })
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.markdown("#### ğŸ“‹ íŠœë‹ í›„ ì„±ëŠ¥ ì§€í‘œ")
        st.dataframe(tuned_results.style.highlight_max(subset=['F1', 'Recall'], color='lightgreen'),
                    use_container_width=True)
        
        st.markdown("#### ğŸ“Š ì„±ëŠ¥ ê°œì„  ë¹„êµ")
        
        # Baseline vs Tuned ë¹„êµ
        comparison = pd.DataFrame({
            'ëª¨ë¸': ['Random Forest', 'AdaBoost', 'Logistic Regression'],
            'Baseline F1': [0.560, 0.602, 0.571],
            'Tuned F1': [0.649, 0.593, 0.585],
            'ê°œì„ ': ['+0.089', '-0.009', '+0.014']
        })
        st.dataframe(comparison, use_container_width=True)
    
    with col2:
        st.markdown("#### ğŸ“Š íŠœë‹ ì „í›„ ì„±ëŠ¥ ë¹„êµ")
        
        # Baseline ë°ì´í„°
        baseline_compare = pd.DataFrame({
            'Model': ['RandomForest', 'AdaBoost', 'LogisticRegression'],
            'Baseline_F1': [0.5595, 0.6021, 0.5714],
            'Tuned_F1': [0.649, 0.593, 0.585],
            'Baseline_Recall': [0.4462, 0.5103, 0.4615],
            'Tuned_Recall': [0.649, 0.487, 0.751]
        })
        
        fig = go.Figure()
        
        # F1 Score
        fig.add_trace(go.Bar(
            name='Baseline F1',
            x=baseline_compare['Model'],
            y=baseline_compare['Baseline_F1'],
            marker_color='lightblue'
        ))
        
        fig.add_trace(go.Bar(
            name='Tuned F1',
            x=baseline_compare['Model'],
            y=baseline_compare['Tuned_F1'],
            marker_color='skyblue'
        ))
        
        fig.update_layout(
            title='íŠœë‹ ì „í›„ F1-Score ë¹„êµ',
            xaxis_title='ëª¨ë¸',
            yaxis_title='F1-Score',
            barmode='group',
            height=350
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Recall
        fig2 = go.Figure()
        
        fig2.add_trace(go.Bar(
            name='Baseline Recall',
            x=baseline_compare['Model'],
            y=baseline_compare['Baseline_Recall'],
            marker_color='lightcoral'
        ))
        
        fig2.add_trace(go.Bar(
            name='Tuned Recall',
            x=baseline_compare['Model'],
            y=baseline_compare['Tuned_Recall'],
            marker_color='coral'
        ))
        
        fig2.update_layout(
            title='íŠœë‹ ì „í›„ Recall ë¹„êµ',
            xaxis_title='ëª¨ë¸',
            yaxis_title='Recall',
            barmode='group',
            height=350
        )
        
        st.plotly_chart(fig2, use_container_width=True)
    
    st.markdown("---")
    
    st.subheader("ğŸ† ìµœì¢… ëª¨ë¸ ì„ ì •")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ìµœì¢… ì„ ì • ëª¨ë¸", "Random Forest", "")
    with col2:
        st.metric("F1-Score", "0.649", "+0.089")
    with col3:
        st.metric("Recall", "0.649", "+0.203")
    
    st.success("""
    ### âœ… Random Forest ëª¨ë¸ ì„ ì • ì´ìœ 
    
    1. **ìµœê³ ì˜ ì„±ëŠ¥**: F1-Score 0.649 ìµœìƒìœ„
    2. **ëŒ€í­ ê°œì„ **: Baseline ëŒ€ë¹„ F1-Score +0.089, Recall +0.203 í–¥ìƒ
    3. **ì´íƒˆ íƒì§€ ê°•í™”**: Recall 0.649ë¡œ ì´íƒˆ ê³ ê°ì˜ 64.9%ë¥¼ ì •í™•íˆ íƒì§€
    4. **ì¼ë°˜í™” ì„±ëŠ¥**: Test ë°ì´í„°ì—ì„œë„ ì•ˆì •ì ì¸ ì„±ëŠ¥ ìœ ì§€
    5. **ê³¼ì í•© ë°©ì§€**: max_depth, min_samples_split ë“±ì˜ íŒŒë¼ë¯¸í„° ì¡°ì •ìœ¼ë¡œ ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ
    
    **í•µì‹¬ ì„±ê³¼**:
    - ì´íƒˆ ê³ ê°ì„ ë†“ì¹˜ì§€ ì•Šìœ¼ë©´ì„œ(ë†’ì€ Recall)
    - ë¶ˆí•„ìš”í•œ ì˜¤íƒì„ ì¤„ì´ëŠ”(ê· í˜•ì¡íŒ F1) ë°©í–¥ìœ¼ë¡œ ìµœì í™”
    """)
    
    st.markdown("---")

# ====================
# 5. ìµœì¢… ê²°ê³¼
# ====================
elif menu == "5. ìµœì¢… ê²°ê³¼":
    st.title("ğŸ‰ ìµœì¢… ê²°ê³¼ ë° ëª¨ë¸ ì˜ˆì¸¡")
    st.markdown("---")
    
    # í”„ë¡œì íŠ¸ ìš”ì•½
    st.header("ğŸ“Š í”„ë¡œì íŠ¸ ìš”ì•½")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ë°ì´í„° ê·œëª¨", "10,000ê±´", "")
    with col2:
        st.metric("ìµœì¢… ëª¨ë¸", "Random Forest", "")
    with col3:
        st.metric("F1-Score", "0.649", "")
    with col4:
        st.metric("Recall", "0.649", "")
    
    st.markdown("---")
    
    # í”„ë¡œì„¸ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨
    st.subheader("ğŸ”„ ë¶„ì„ í”„ë¡œì„¸ìŠ¤")
    
    st.markdown("""
    ```
    ğŸ“Š ë°ì´í„° ìˆ˜ì§‘
        â†“
    ğŸ” ë°ì´í„° íƒìƒ‰ (EDA)
        â”œâ”€ ê²°ì¸¡ì¹˜ í™•ì¸ âœ… (ì—†ìŒ)
        â”œâ”€ ì´ìƒì¹˜ ì²˜ë¦¬ (374ê±´ ì œê±°)
        â””â”€ ê¸°ë³¸ í†µê³„ ë¶„ì„
        â†“
    âš™ï¸ ë°ì´í„° ì „ì²˜ë¦¬
        â”œâ”€ ë‹¨ë³€ìˆ˜ ë¶„ì„ (ê° ë³€ìˆ˜ ë¶„í¬ íŒŒì•…)
        â”œâ”€ ì´ë³€ìˆ˜ ë¶„ì„ (Churnê³¼ì˜ ê´€ê³„)
        â”œâ”€ ë‹¤ë³€ìˆ˜ ë¶„ì„ (ìƒê´€ê´€ê³„, VIF)
        â””â”€ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
        â†“
    ğŸ¤– ëª¨ë¸ í•™ìŠµ
        â”œâ”€ 8ê°œ ëª¨ë¸ ë¹„êµ
        â”œâ”€ ìƒìœ„ 3ê°œ ì„ ì •
        â””â”€ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
        â†“
    ğŸ† ìµœì¢… ëª¨ë¸: Random Forest
        â”œâ”€ F1-Score: 0.649
        â”œâ”€ Recall: 0.649
        â””â”€ Accuracy: 0.858
    ```
    """)
    
    st.markdown("---")
    
    # í•µì‹¬ í¬ì¸íŠ¸
    st.subheader("ğŸ’¡ ë‹¨ê³„ë³„ í•µì‹¬ í¬ì¸íŠ¸")
    
    with st.expander("1ï¸âƒ£ ë°ì´í„° íƒìƒ‰", expanded=False):
        st.markdown("""
        **ì£¼ìš” ë°œê²¬ì‚¬í•­**:
        - âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ (ë°ì´í„° í’ˆì§ˆ ì–‘í˜¸)
        - âš ï¸ age, credit_scoreì—ì„œ ì´ìƒì¹˜ ë°œê²¬ (374ê±´, 3.74%)
        - ğŸ“Š í´ë˜ìŠ¤ ë¶ˆê· í˜•: Churn=1ì´ ì•½ 20.3%
        
        **ì²˜ë¦¬ ë°©ë²•**:
        - IQR ê¸°ë°˜ ì´ìƒì¹˜ ì œê±°
        - products_numberì˜ í¬ê·€ ì¹´í…Œê³ ë¦¬(4ê°œ ìƒí’ˆ) í†µí•©
        - Stratified Splitìœ¼ë¡œ í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€
        """)
    
    with st.expander("2ï¸âƒ£ ë°ì´í„° ì „ì²˜ë¦¬", expanded=False):
        st.markdown("""
        **ë‹¨ë³€ìˆ˜ ë¶„ì„**:
        - ê° ë³€ìˆ˜ì˜ ë¶„í¬ íŠ¹ì„± íŒŒì•…
        - ì™œë„, ì²¨ë„ ë“± í†µê³„ëŸ‰ í™•ì¸
        
        **ì´ë³€ìˆ˜ ë¶„ì„**:
        - ì´íƒˆì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì£¼ìš” ë³€ìˆ˜ ì‹ë³„
        - age, products_number, active_memberê°€ ê°•í•œ ì˜í–¥
        
        **ë‹¤ë³€ìˆ˜ ë¶„ì„**:
        - ìƒê´€ê´€ê³„ ë¶„ì„: ê°•í•œ ìƒê´€ê´€ê³„ ë³€ìˆ˜ ì—†ìŒ
        - VIF < 2: ë‹¤ì¤‘ê³µì„ ì„± ë¬¸ì œ ì—†ìŒ
        
        **ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸**:
        - StandardScaler: ì—°ì†í˜• ë³€ìˆ˜
        - OneHotEncoder: ë²”ì£¼í˜• ë³€ìˆ˜
        - ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€
        """)
    
    with st.expander("3ï¸âƒ£ ëª¨ë¸ ì„ ì • ë° ìµœì í™”", expanded=False):
        st.markdown("""
        **Baseline ë¹„êµ (8ê°œ ëª¨ë¸)**:
        - Logistic Regression, KNN, SVM, Decision Tree
        - Random Forest, Bagging, AdaBoost, Neural Network
        
        **ìƒìœ„ 3ê°œ ì„ ì •**:
        1. AdaBoost (F1: 0.602)
        2. Logistic Regression (F1: 0.571)
        3. Random Forest (F1: 0.560)
        
        **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**:
        - RandomizedSearchCV (n_iter=30, cv=5)
        - í‰ê°€ ì§€í‘œ: F1-Score
        
        **ìµœì¢… ì„ ì •: Random Forest**
        - íŠœë‹ í›„ F1: 0.649 (+0.089)
        - íŠœë‹ í›„ Recall: 0.649 (+0.203)
        """)
    
    with st.expander("4ï¸âƒ£ ìµœì¢… ê²°ê³¼ ë° ì¸ì‚¬ì´íŠ¸", expanded=False):
        st.markdown("""
        **ëª¨ë¸ ì„±ëŠ¥**:
        - âœ… F1-Score: 0.649 (ì´íƒˆ/ìœ ì§€ ê· í˜•)
        - âœ… Recall: 0.649 (ì´íƒˆ ê³ ê° 64.9% íƒì§€)
        - âœ… Accuracy: 0.858 (ì „ì²´ ì •í™•ë„)
        
        **ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸**:
        1. **ë‚˜ì´**: 40ëŒ€ ì¤‘í›„ë°˜~50ëŒ€ ì´ˆë°˜ ê³ ê°ì´ ì´íƒˆ ìœ„í—˜ ë†’ìŒ
        2. **ìƒí’ˆ ìˆ˜**: 1ê°œ ìƒí’ˆë§Œ ì´ìš©í•˜ëŠ” ê³ ê°ì´ ì´íƒˆ í™•ë¥  ë†’ìŒ
        3. **í™œë™ì„±**: ë¹„í™œë™ íšŒì›ì˜ ì´íƒˆë¥ ì´ í˜„ì €íˆ ë†’ìŒ
        4. **ì”ì•¡**: ì”ì•¡ì´ 0ì¸ ê³ ê°ì€ ì˜¤íˆë ¤ ì´íƒˆ í™•ë¥  ë‚®ìŒ
        5. **êµ­ê°€**: ë…ì¼ ê³ ê°ì˜ ì´íƒˆë¥ ì´ ë‹¤ë¥¸ êµ­ê°€ ëŒ€ë¹„ ë†’ìŒ
        
        **ì‹¤ë¬´ í™œìš©**:
        - ê³ ìœ„í—˜ ê³ ê° ì¡°ê¸° ì‹ë³„ ë° ë§ì¶¤í˜• ë¦¬í…ì…˜ ì „ëµ
        - 40ëŒ€ ì´ìƒ + 1ê°œ ìƒí’ˆ + ë¹„í™œë™ íšŒì› â†’ ì§‘ì¤‘ ê´€ë¦¬
        - ì¶”ê°€ ìƒí’ˆ ê°€ì… ìœ ë„ ë° í™œë™ì„± ì¦ì§„ ìº í˜ì¸
        """)
    
    st.markdown("---")
    
    # ëª¨ë¸ ì˜ˆì¸¡ ì„¹ì…˜
    st.header("ğŸ”® ê³ ê° ì´íƒˆ ì˜ˆì¸¡")
    st.markdown("í•™ìŠµëœ Random Forest ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê³ ê°ì˜ ì´íƒˆ ì—¬ë¶€ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")
    
    # ëª¨ë¸ ë¡œë“œ
    current_dir = Path(__file__).parent
    model_path = current_dir / 'randomforest_model.pkl'
    
    try:
        # ì„¸ì…˜ì—ì„œ ëª¨ë¸ í™•ì¸
        if 'loaded_models' in st.session_state and 'RandomForest' in st.session_state['loaded_models']:
            model = st.session_state['loaded_models']['RandomForest']
            st.success("âœ… Random Forest ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ì„¸ì…˜ì—ì„œ ê°€ì ¸ì˜´)")
        else:
            # ì§ì ‘ ë¡œë“œ
            model = joblib.load(model_path)
            st.success(f"âœ… Random Forest ëª¨ë¸ ë¡œë“œ ì™„ë£Œ - `{model_path}`")
    except FileNotFoundError:
        st.error(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: `{model_path}`")
        st.info("ë¨¼ì € '4. ìƒìœ„ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€' ë©”ë‰´ì—ì„œ ëª¨ë¸ì„ ë¡œë“œí•˜ê±°ë‚˜, ë…¸íŠ¸ë¶ì—ì„œ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ì €ì¥í•´ì£¼ì„¸ìš”.")
        st.stop()
    except Exception as e:
        st.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.stop()
    
    st.markdown("---")
    
    # ì…ë ¥ í¼
    st.subheader("ğŸ“ ê³ ê° ì •ë³´ ì…ë ¥")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        credit_score = st.number_input("ì‹ ìš© ì ìˆ˜", min_value=300, max_value=850, value=650, step=10)
        age = st.number_input("ë‚˜ì´", min_value=18, max_value=100, value=40, step=1)
        tenure = st.number_input("ê±°ë˜ ê¸°ê°„ (ë…„)", min_value=0, max_value=10, value=5, step=1)
        balance = st.number_input("ê³„ì¢Œ ì”ì•¡ ($)", min_value=0.0, max_value=250000.0, value=50000.0, step=1000.0)
    
    with col2:
        estimated_salary = st.number_input("ì˜ˆìƒ ì—°ë´‰ ($)", min_value=0.0, max_value=200000.0, value=80000.0, step=1000.0)
        products_number = st.selectbox("ë³´ìœ  ìƒí’ˆ ìˆ˜", [1, 2, 3, 4], index=0)
        country = st.selectbox("êµ­ê°€", ["í”„ë‘ìŠ¤", "ìŠ¤í˜ì¸", "ë…ì¼"], index=0)
        gender = st.selectbox("ì„±ë³„", ["ë‚¨ì„±", "ì—¬ì„±"], index=0)
    
    with col3:
        credit_card = st.selectbox("ì‹ ìš©ì¹´ë“œ ë³´ìœ ", ["ì˜ˆ", "ì•„ë‹ˆì˜¤"], index=0)
        active_member = st.selectbox("í™œë™ íšŒì›", ["ì˜ˆ", "ì•„ë‹ˆì˜¤"], index=0)
    
    # ì˜ˆì¸¡ ë²„íŠ¼
    if st.button("ğŸ”® ì´íƒˆ ì—¬ë¶€ ì˜ˆì¸¡í•˜ê¸°", use_container_width=True):
        # ì…ë ¥ ë°ì´í„° ì „ì²˜ë¦¬
        country_encoded = {"í”„ë‘ìŠ¤": 0, "ìŠ¤í˜ì¸": 1, "ë…ì¼": 2}[country]
        gender_encoded = 1 if gender == "ë‚¨ì„±" else 0
        credit_card_encoded = 1 if credit_card == "ì˜ˆ" else 0
        active_member_encoded = 1 if active_member == "ì˜ˆ" else 0
        
        # ì…ë ¥ ë°ì´í„° ìƒì„±
        input_data = pd.DataFrame({
            'credit_score': [credit_score],
            'country': [country_encoded],
            'gender': [gender_encoded],
            'age': [age],
            'tenure': [tenure],
            'balance': [balance],
            'products_number': [products_number],
            'credit_card': [credit_card_encoded],
            'active_member': [active_member_encoded],
            'estimated_salary': [estimated_salary]
        })
        
        # ì˜ˆì¸¡
        try:
            prediction = model.predict(input_data)[0]
            prediction_proba = model.predict_proba(input_data)[0]
            
            st.markdown("---")
            
            # ê²°ê³¼ í‘œì‹œ
            if prediction == 1:
                st.error("âš ï¸ **ì´íƒˆ ìœ„í—˜ ê³ ê°ì…ë‹ˆë‹¤!**")
                churn_prob = prediction_proba[1] * 100
                st.metric("ì´íƒˆ í™•ë¥ ", f"{churn_prob:.1f}%", "ìœ„í—˜")
                
                st.warning("""
                ### ğŸš¨ ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­
                1. ê³ ê° ë§ì¶¤í˜• ë¦¬í…ì…˜ ìº í˜ì¸ ì‹¤ì‹œ
                2. ì¶”ê°€ ìƒí’ˆ ê°€ì… í˜œíƒ ì œê³µ
                3. ì „ë‹´ ìƒë‹´ì‚¬ ë°°ì •
                4. VIP ì„œë¹„ìŠ¤ ì œê³µ
                """)
            else:
                st.success("âœ… **ì•ˆì •ì ì¸ ê³ ê°ì…ë‹ˆë‹¤.**")
                stay_prob = prediction_proba[0] * 100
                st.metric("ìœ ì§€ í™•ë¥ ", f"{stay_prob:.1f}%", "ì•ˆì •")
                
                st.info("""
                ### ğŸ’š ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­
                1. ìš°ìˆ˜ ê³ ê° í˜œíƒ ì œê³µ
                2. ì •ê¸°ì ì¸ ë§Œì¡±ë„ ì¡°ì‚¬
                3. ì‹ ê·œ ì„œë¹„ìŠ¤ ìš°ì„  ì•ˆë‚´
                """)
            
            # í™•ë¥  ì‹œê°í™”
            fig = go.Figure(go.Bar(
                x=['ìœ ì§€', 'ì´íƒˆ'],
                y=[prediction_proba[0]*100, prediction_proba[1]*100],
                marker_color=['lightgreen', 'lightcoral'],
                text=[f"{prediction_proba[0]*100:.1f}%", f"{prediction_proba[1]*100:.1f}%"],
                textposition='auto'
            ))
            
            fig.update_layout(
                title='ì´íƒˆ í™•ë¥  ë¶„ì„',
                xaxis_title='ì˜ˆì¸¡ ê²°ê³¼',
                yaxis_title='í™•ë¥  (%)',
                height=400
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
        except Exception as e:
            st.error(f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            st.info("ì…ë ¥ ë°ì´í„°ì™€ ëª¨ë¸ì˜ í˜•ì‹ì´ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    
    st.markdown("---")
    
    # í”„ë¡œì íŠ¸ ë§ˆë¬´ë¦¬
    st.subheader("ğŸ“ í”„ë¡œì íŠ¸ ê²°ë¡ ")
    
    st.success("""
    ### âœ… í”„ë¡œì íŠ¸ ì„±ê³¼
    
    1. **ë°ì´í„° í’ˆì§ˆ**: ì²´ê³„ì ì¸ ì „ì²˜ë¦¬ë¡œ ê³ í’ˆì§ˆ ë°ì´í„°ì…‹ êµ¬ì¶•
    2. **ëª¨ë¸ ì„±ëŠ¥**: F1-Score 0.649ë¡œ ê· í˜•ì¡íŒ ì˜ˆì¸¡ ì„±ëŠ¥ ë‹¬ì„±
    3. **ì‹¤ë¬´ ì ìš©**: 64.9%ì˜ ì´íƒˆ ê³ ê°ì„ ì‚¬ì „ì— íƒì§€ ê°€ëŠ¥
    4. **ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜**: ì„ ì œì  ë¦¬í…ì…˜ ì „ëµ ìˆ˜ë¦½ ê¸°ë°˜ ë§ˆë ¨
    """)
    
    st.balloons()

# Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center'>
    <p>ğŸ¦ Bank Customer Churn Prediction Project</p>
    <p>Team 1 | 2024</p>
</div>
""", unsafe_allow_html=True)
