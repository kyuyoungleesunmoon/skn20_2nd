{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "CgoqHQAvtDpx"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wo0vi1NZt4-_"
      },
      "outputs": [],
      "source": [
        "class Dataset:\n",
        "    def __init__(self, file_name):\n",
        "        super().__init__()\n",
        "        self.file_name = file_name\n",
        "\n",
        "        df = pd.read_csv(f'../../DL_data/dataset/{self.file_name}')\n",
        "        X = df.drop('churn', axis=1)\n",
        "        y = df['churn']\n",
        "\n",
        "        self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(X, y, random_state=42, test_size=0.2,\n",
        "                                                                              stratify=y)\n",
        "\n",
        "    def get_train_dataset(self):\n",
        "        train_dataset = Train_Dataset(self.X_train, self.y_train)\n",
        "        val_dataset = Train_Dataset(self.X_val, self.y_val)\n",
        "\n",
        "        return train_dataset, val_dataset\n",
        "\n",
        "\n",
        "# Dataset\n",
        "class Train_Dataset(Dataset):\n",
        "    def __init__(self, data, label):\n",
        "        self.data = data\n",
        "        self.label = label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    # getter\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.data.iloc[idx].to_numpy()\n",
        "        label = self.label.iloc[idx]\n",
        "\n",
        "        return data, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "gqMzIyHovNc6"
      },
      "outputs": [],
      "source": [
        "class MLP_model(nn.Module):\n",
        "    def __init__(self, Cin):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(Cin, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            nn.Linear(128, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            nn.Linear(64, 32),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "AVtt_eXJG153"
      },
      "outputs": [],
      "source": [
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, min_delta=0.0, path='best_model.pt'):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.path = path\n",
        "        self.best = None\n",
        "        self.count = 0\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        if self.best is None or (self.best - val_loss) > self.min_delta:\n",
        "            self.best = val_loss\n",
        "            self.count = 0\n",
        "            torch.save(model.state_dict(), self.path)  # 베스트 갱신 시 저장\n",
        "        else:\n",
        "            self.count += 1\n",
        "            if self.count >= self.patience:\n",
        "                self.early_stop = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Olom_-XSEh2",
        "outputId": "c412a1fc-65de-4b91-dcf6-e0c8247b2b75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "num Feature : (13,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 1/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 226.64it/s]\n",
            "[Epoch 1/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 356.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2333 || Valid Loss : 0.2074 | Valid Accuracy : 93.41%\n",
            "Epoch 1 - F1 : 0.9400, Precision : 0.9542, Recall : 0.9262\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 2/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 228.47it/s]\n",
            "[Epoch 2/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 362.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2140 || Valid Loss : 0.2065 | Valid Accuracy : 93.52%\n",
            "Epoch 2 - F1 : 0.9410, Precision : 0.9545, Recall : 0.9278\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 3/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 229.38it/s]\n",
            "[Epoch 3/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 361.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2133 || Valid Loss : 0.2047 | Valid Accuracy : 93.56%\n",
            "Epoch 3 - F1 : 0.9413, Precision : 0.9556, Recall : 0.9275\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 4/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 231.18it/s]\n",
            "[Epoch 4/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 342.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2119 || Valid Loss : 0.2025 | Valid Accuracy : 93.52%\n",
            "Epoch 4 - F1 : 0.9411, Precision : 0.9535, Recall : 0.9290\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 5/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 230.58it/s]\n",
            "[Epoch 5/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 357.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2102 || Valid Loss : 0.2078 | Valid Accuracy : 93.48%\n",
            "Epoch 5 - F1 : 0.9406, Precision : 0.9561, Recall : 0.9255\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 6/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 226.86it/s]\n",
            "[Epoch 6/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 363.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2089 || Valid Loss : 0.2062 | Valid Accuracy : 93.50%\n",
            "Epoch 6 - F1 : 0.9408, Precision : 0.9557, Recall : 0.9263\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 7/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 228.18it/s]\n",
            "[Epoch 7/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 364.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2084 || Valid Loss : 0.2019 | Valid Accuracy : 93.56%\n",
            "Epoch 7 - F1 : 0.9413, Precision : 0.9559, Recall : 0.9272\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 8/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 232.16it/s]\n",
            "[Epoch 8/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 365.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2080 || Valid Loss : 0.2019 | Valid Accuracy : 93.55%\n",
            "Epoch 8 - F1 : 0.9413, Precision : 0.9537, Recall : 0.9292\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 9/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 231.09it/s]\n",
            "[Epoch 9/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 358.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2071 || Valid Loss : 0.2010 | Valid Accuracy : 93.57%\n",
            "Epoch 9 - F1 : 0.9415, Precision : 0.9542, Recall : 0.9291\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 10/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 228.55it/s]\n",
            "[Epoch 10/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 360.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2069 || Valid Loss : 0.2014 | Valid Accuracy : 93.59%\n",
            "Epoch 10 - F1 : 0.9416, Precision : 0.9565, Recall : 0.9272\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 11/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 228.93it/s]\n",
            "[Epoch 11/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 360.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2067 || Valid Loss : 0.2005 | Valid Accuracy : 93.57%\n",
            "Epoch 11 - F1 : 0.9414, Precision : 0.9554, Recall : 0.9278\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 12/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 229.98it/s]\n",
            "[Epoch 12/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 358.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2058 || Valid Loss : 0.2001 | Valid Accuracy : 93.60%\n",
            "Epoch 12 - F1 : 0.9418, Precision : 0.9547, Recall : 0.9292\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 13/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 231.47it/s]\n",
            "[Epoch 13/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 351.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2054 || Valid Loss : 0.1992 | Valid Accuracy : 93.68%\n",
            "Epoch 13 - F1 : 0.9425, Precision : 0.9553, Recall : 0.9301\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 14/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 228.45it/s]\n",
            "[Epoch 14/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 359.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2062 || Valid Loss : 0.2010 | Valid Accuracy : 93.61%\n",
            "Epoch 14 - F1 : 0.9418, Precision : 0.9552, Recall : 0.9288\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 15/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 226.49it/s]\n",
            "[Epoch 15/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 360.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2055 || Valid Loss : 0.1996 | Valid Accuracy : 93.62%\n",
            "Epoch 15 - F1 : 0.9420, Precision : 0.9542, Recall : 0.9302\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 16/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 229.89it/s]\n",
            "[Epoch 16/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 362.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2034 || Valid Loss : 0.1998 | Valid Accuracy : 93.67%\n",
            "Epoch 16 - F1 : 0.9424, Precision : 0.9551, Recall : 0.9301\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 17/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 230.35it/s]\n",
            "[Epoch 17/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 361.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2057 || Valid Loss : 0.1997 | Valid Accuracy : 93.60%\n",
            "Epoch 17 - F1 : 0.9416, Precision : 0.9572, Recall : 0.9266\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 18/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 231.55it/s]\n",
            "[Epoch 18/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 363.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2043 || Valid Loss : 0.2026 | Valid Accuracy : 93.59%\n",
            "Epoch 18 - F1 : 0.9415, Precision : 0.9566, Recall : 0.9270\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 19/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 231.85it/s]\n",
            "[Epoch 19/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 362.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2042 || Valid Loss : 0.1994 | Valid Accuracy : 93.64%\n",
            "Epoch 19 - F1 : 0.9420, Precision : 0.9571, Recall : 0.9273\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 20/100] Training: 100%|██████████| 1798/1798 [00:08<00:00, 222.37it/s]\n",
            "[Epoch 20/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 353.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2036 || Valid Loss : 0.1995 | Valid Accuracy : 93.59%\n",
            "Epoch 20 - F1 : 0.9415, Precision : 0.9567, Recall : 0.9268\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 21/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 228.70it/s]\n",
            "[Epoch 21/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 361.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2034 || Valid Loss : 0.1981 | Valid Accuracy : 93.66%\n",
            "Epoch 21 - F1 : 0.9422, Precision : 0.9584, Recall : 0.9265\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 22/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 229.33it/s]\n",
            "[Epoch 22/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 362.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2030 || Valid Loss : 0.1989 | Valid Accuracy : 93.66%\n",
            "Epoch 22 - F1 : 0.9422, Precision : 0.9575, Recall : 0.9273\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 23/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 229.23it/s]\n",
            "[Epoch 23/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 355.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2028 || Valid Loss : 0.1987 | Valid Accuracy : 93.65%\n",
            "Epoch 23 - F1 : 0.9422, Precision : 0.9555, Recall : 0.9293\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 24/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 225.81it/s]\n",
            "[Epoch 24/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 348.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2029 || Valid Loss : 0.1990 | Valid Accuracy : 93.71%\n",
            "Epoch 24 - F1 : 0.9428, Precision : 0.9557, Recall : 0.9302\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 25/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 226.70it/s]\n",
            "[Epoch 25/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 355.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2026 || Valid Loss : 0.1991 | Valid Accuracy : 93.67%\n",
            "Epoch 25 - F1 : 0.9424, Precision : 0.9550, Recall : 0.9302\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 26/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 226.47it/s]\n",
            "[Epoch 26/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 360.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2031 || Valid Loss : 0.1983 | Valid Accuracy : 93.66%\n",
            "Epoch 26 - F1 : 0.9423, Precision : 0.9557, Recall : 0.9293\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 27/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 226.07it/s]\n",
            "[Epoch 27/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 358.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2038 || Valid Loss : 0.1988 | Valid Accuracy : 93.68%\n",
            "Epoch 27 - F1 : 0.9425, Precision : 0.9549, Recall : 0.9305\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 28/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 227.67it/s]\n",
            "[Epoch 28/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 353.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2023 || Valid Loss : 0.1992 | Valid Accuracy : 93.62%\n",
            "Epoch 28 - F1 : 0.9418, Precision : 0.9585, Recall : 0.9256\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 29/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 229.40it/s]\n",
            "[Epoch 29/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 361.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2036 || Valid Loss : 0.1973 | Valid Accuracy : 93.73%\n",
            "Epoch 29 - F1 : 0.9429, Precision : 0.9570, Recall : 0.9291\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 30/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 226.88it/s]\n",
            "[Epoch 30/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 356.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2023 || Valid Loss : 0.1975 | Valid Accuracy : 93.66%\n",
            "Epoch 30 - F1 : 0.9423, Precision : 0.9559, Recall : 0.9290\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 31/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 227.88it/s]\n",
            "[Epoch 31/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 360.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2023 || Valid Loss : 0.1989 | Valid Accuracy : 93.66%\n",
            "Epoch 31 - F1 : 0.9422, Precision : 0.9584, Recall : 0.9265\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 32/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 228.44it/s]\n",
            "[Epoch 32/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 361.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2030 || Valid Loss : 0.1989 | Valid Accuracy : 93.66%\n",
            "Epoch 32 - F1 : 0.9423, Precision : 0.9557, Recall : 0.9293\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 33/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 227.85it/s]\n",
            "[Epoch 33/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 360.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2016 || Valid Loss : 0.1979 | Valid Accuracy : 93.71%\n",
            "Epoch 33 - F1 : 0.9428, Precision : 0.9561, Recall : 0.9298\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 34/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 229.26it/s]\n",
            "[Epoch 34/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 363.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2020 || Valid Loss : 0.1983 | Valid Accuracy : 93.69%\n",
            "Epoch 34 - F1 : 0.9425, Precision : 0.9573, Recall : 0.9282\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 35/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 231.89it/s]\n",
            "[Epoch 35/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 361.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2018 || Valid Loss : 0.1969 | Valid Accuracy : 93.69%\n",
            "Epoch 35 - F1 : 0.9425, Precision : 0.9570, Recall : 0.9285\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 36/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 228.30it/s]\n",
            "[Epoch 36/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 360.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2025 || Valid Loss : 0.1970 | Valid Accuracy : 93.68%\n",
            "Epoch 36 - F1 : 0.9424, Precision : 0.9563, Recall : 0.9290\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 37/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 231.39it/s]\n",
            "[Epoch 37/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 360.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2007 || Valid Loss : 0.1971 | Valid Accuracy : 93.68%\n",
            "Epoch 37 - F1 : 0.9425, Precision : 0.9561, Recall : 0.9292\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 38/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 231.14it/s]\n",
            "[Epoch 38/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 355.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2020 || Valid Loss : 0.1973 | Valid Accuracy : 93.65%\n",
            "Epoch 38 - F1 : 0.9422, Precision : 0.9559, Recall : 0.9288\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 39/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 231.32it/s]\n",
            "[Epoch 39/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 350.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2018 || Valid Loss : 0.1966 | Valid Accuracy : 93.68%\n",
            "Epoch 39 - F1 : 0.9424, Precision : 0.9562, Recall : 0.9291\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 40/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 228.84it/s]\n",
            "[Epoch 40/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 358.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2005 || Valid Loss : 0.1969 | Valid Accuracy : 93.69%\n",
            "Epoch 40 - F1 : 0.9425, Precision : 0.9562, Recall : 0.9292\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 41/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 230.62it/s]\n",
            "[Epoch 41/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 360.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2004 || Valid Loss : 0.1986 | Valid Accuracy : 93.69%\n",
            "Epoch 41 - F1 : 0.9424, Precision : 0.9572, Recall : 0.9281\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 42/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 230.57it/s]\n",
            "[Epoch 42/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 363.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2017 || Valid Loss : 0.1973 | Valid Accuracy : 93.70%\n",
            "Epoch 42 - F1 : 0.9427, Precision : 0.9561, Recall : 0.9296\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 43/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 230.79it/s]\n",
            "[Epoch 43/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 357.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2012 || Valid Loss : 0.1964 | Valid Accuracy : 93.69%\n",
            "Epoch 43 - F1 : 0.9425, Precision : 0.9562, Recall : 0.9292\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 44/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 230.87it/s]\n",
            "[Epoch 44/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 360.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2005 || Valid Loss : 0.1964 | Valid Accuracy : 93.72%\n",
            "Epoch 44 - F1 : 0.9428, Precision : 0.9566, Recall : 0.9295\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 45/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 230.16it/s]\n",
            "[Epoch 45/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 359.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2009 || Valid Loss : 0.1968 | Valid Accuracy : 93.70%\n",
            "Epoch 45 - F1 : 0.9426, Precision : 0.9566, Recall : 0.9291\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 46/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 228.93it/s]\n",
            "[Epoch 46/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 362.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2008 || Valid Loss : 0.1974 | Valid Accuracy : 93.62%\n",
            "Epoch 46 - F1 : 0.9419, Precision : 0.9547, Recall : 0.9295\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 47/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 231.63it/s]\n",
            "[Epoch 47/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 360.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2011 || Valid Loss : 0.1966 | Valid Accuracy : 93.64%\n",
            "Epoch 47 - F1 : 0.9422, Precision : 0.9548, Recall : 0.9300\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 48/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 225.04it/s]\n",
            "[Epoch 48/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 353.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2016 || Valid Loss : 0.1977 | Valid Accuracy : 93.73%\n",
            "Epoch 48 - F1 : 0.9429, Precision : 0.9563, Recall : 0.9298\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 49/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 225.25it/s]\n",
            "[Epoch 49/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 361.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2002 || Valid Loss : 0.1970 | Valid Accuracy : 93.69%\n",
            "Epoch 49 - F1 : 0.9426, Precision : 0.9560, Recall : 0.9296\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 50/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 229.38it/s]\n",
            "[Epoch 50/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 361.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.1997 || Valid Loss : 0.1969 | Valid Accuracy : 93.67%\n",
            "Epoch 50 - F1 : 0.9423, Precision : 0.9569, Recall : 0.9282\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 51/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 228.82it/s]\n",
            "[Epoch 51/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 360.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.2015 || Valid Loss : 0.1969 | Valid Accuracy : 93.68%\n",
            "Epoch 51 - F1 : 0.9423, Precision : 0.9581, Recall : 0.9271\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 52/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 230.06it/s]\n",
            "[Epoch 52/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 358.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.1997 || Valid Loss : 0.1980 | Valid Accuracy : 93.67%\n",
            "Epoch 52 - F1 : 0.9424, Precision : 0.9552, Recall : 0.9300\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 53/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 229.71it/s]\n",
            "[Epoch 53/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 361.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.1998 || Valid Loss : 0.1981 | Valid Accuracy : 93.73%\n",
            "Epoch 53 - F1 : 0.9428, Precision : 0.9586, Recall : 0.9275\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 54/100] Training: 100%|██████████| 1798/1798 [00:07<00:00, 229.54it/s]\n",
            "[Epoch 54/100] Validation: 100%|██████████| 450/450 [00:01<00:00, 352.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.1999 || Valid Loss : 0.1964 | Valid Accuracy : 93.71%\n",
            "Epoch 54 - F1 : 0.9427, Precision : 0.9581, Recall : 0.9277\n",
            "* Early stopping triggered.\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9126    0.9490    0.9304      6369\n",
            "         1.0     0.9581    0.9277    0.9427      8010\n",
            "\n",
            "    accuracy                         0.9371     14379\n",
            "   macro avg     0.9353    0.9383    0.9365     14379\n",
            "weighted avg     0.9379    0.9371    0.9372     14379\n",
            "\n",
            "\n",
            "최종 평가 결과\n",
            "Precision    : 0.9570\n",
            "Recall       : 0.9291\n",
            "F1 Score     : 0.9429\n",
            "Accuracy (%) : 93.73%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Using device:\", device)\n",
        "\n",
        "    dataset = Dataset(file_name='re_log_model_preprocessed.csv')\n",
        "    train_dataset, val_dataset = dataset.get_train_dataset()\n",
        "\n",
        "    Cin = train_dataset.__getitem__(0)[0].shape\n",
        "    print(f\"num Feature : {Cin}\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    val_loader   = DataLoader(val_dataset,   batch_size=32)\n",
        "\n",
        "    model = MLP_model(Cin[0]).to(device)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    train_epoch = 100\n",
        "    train_losses, val_losses, val_accuracies = [], [], []\n",
        "    best_metrics = {'f1': 0, 'precision': 0, 'recall': 0, 'accuracy': 0}\n",
        "\n",
        "    # Early Stopping\n",
        "    es = EarlyStopping(patience=10, min_delta=0.0, path='../best_model.pt')\n",
        "\n",
        "    for epoch in range(train_epoch):\n",
        "        # 학습\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for batch_data, batch_label in tqdm(train_loader, desc=f\"[Epoch {epoch+1}/{train_epoch}] Training\"):\n",
        "            batch_data = batch_data.to(device).float()\n",
        "            batch_label = batch_label.to(device).float().unsqueeze(-1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_data)                 # logits\n",
        "            loss = criterion(outputs, batch_label)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        # 검증\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct, total = 0, 0\n",
        "        all_preds, all_labels = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_data, batch_label in tqdm(val_loader, desc=f\"[Epoch {epoch+1}/{train_epoch}] Validation\"):\n",
        "                batch_data = batch_data.to(device).float()\n",
        "                batch_label = batch_label.to(device).float().unsqueeze(-1)\n",
        "\n",
        "                logits = model(batch_data)\n",
        "                loss = criterion(logits, batch_label)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                probs = torch.sigmoid(logits)\n",
        "                preds = (probs > 0.5).float()\n",
        "\n",
        "                correct += (preds == batch_label).sum().item()\n",
        "                total += batch_label.size(0)\n",
        "\n",
        "                all_preds.extend(preds.cpu().numpy().ravel())\n",
        "                all_labels.extend(batch_label.cpu().numpy().ravel())\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        val_losses.append(avg_val_loss)\n",
        "        val_accuracy = 100 * correct / total\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "        val_f1       = f1_score(all_labels, all_preds, zero_division=0)\n",
        "        val_precision= precision_score(all_labels, all_preds, zero_division=0)\n",
        "        val_recall   = recall_score(all_labels, all_preds, zero_division=0)\n",
        "\n",
        "        print(f\"Train Loss : {avg_train_loss:.4f} || Valid Loss : {avg_val_loss:.4f} | Valid Accuracy : {val_accuracy:.2f}%\")\n",
        "        print(f\"Epoch {epoch+1} - F1 : {val_f1:.4f}, Precision : {val_precision:.4f}, Recall : {val_recall:.4f}\")\n",
        "\n",
        "        # 베스트 메트릭 갱신\n",
        "        if val_accuracy > best_metrics['accuracy']:\n",
        "            best_metrics.update({'f1': val_f1, 'precision': val_precision, 'recall': val_recall, 'accuracy': val_accuracy})\n",
        "\n",
        "        # Early Stopping 체크: 검증 손실 계산 '직후'\n",
        "        es(avg_val_loss, model)\n",
        "        if es.early_stop:\n",
        "            print(\"* Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    # 학습 종료 후: 베스트 가중치 로드\n",
        "    model.load_state_dict(torch.load('../best_model.pt', map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, digits=4))\n",
        "\n",
        "    print(\"\\n최종 평가 결과\")\n",
        "    print(f\"Precision    : {best_metrics['precision']:.4f}\")\n",
        "    print(f\"Recall       : {best_metrics['recall']:.4f}\")\n",
        "    print(f\"F1 Score     : {best_metrics['f1']:.4f}\")\n",
        "    print(f\"Accuracy (%) : {best_metrics['accuracy']:.2f}%\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# learning_rate  = 0.1, 0.001, 0.0001 비교"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuI9tK0DMV8g",
        "outputId": "70758730-1e34-40de-aeab-18c401487d4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "num Feature : (13,)\n",
            "\n",
            "==============================\n",
            "학습률 0.001 실험 시작\n",
            "==============================\n",
            "[LR 0.001] Epoch 001 | Train Loss: 0.2322 | Val Loss: 0.2074 | Val Acc: 93.46%\n",
            "[LR 0.001] Epoch 002 | Train Loss: 0.2163 | Val Loss: 0.2049 | Val Acc: 93.50%\n",
            "[LR 0.001] Epoch 003 | Train Loss: 0.2130 | Val Loss: 0.2041 | Val Acc: 93.54%\n",
            "[LR 0.001] Epoch 004 | Train Loss: 0.2110 | Val Loss: 0.2057 | Val Acc: 93.53%\n",
            "[LR 0.001] Epoch 005 | Train Loss: 0.2109 | Val Loss: 0.2044 | Val Acc: 93.50%\n",
            "[LR 0.001] Epoch 006 | Train Loss: 0.2085 | Val Loss: 0.2027 | Val Acc: 93.46%\n",
            "[LR 0.001] Epoch 007 | Train Loss: 0.2094 | Val Loss: 0.2008 | Val Acc: 93.62%\n",
            "[LR 0.001] Epoch 008 | Train Loss: 0.2083 | Val Loss: 0.2017 | Val Acc: 93.62%\n",
            "[LR 0.001] Epoch 009 | Train Loss: 0.2087 | Val Loss: 0.2010 | Val Acc: 93.57%\n",
            "[LR 0.001] Epoch 010 | Train Loss: 0.2070 | Val Loss: 0.2009 | Val Acc: 93.53%\n",
            "[LR 0.001] Epoch 011 | Train Loss: 0.2069 | Val Loss: 0.1997 | Val Acc: 93.58%\n",
            "[LR 0.001] Epoch 012 | Train Loss: 0.2073 | Val Loss: 0.2008 | Val Acc: 93.59%\n",
            "[LR 0.001] Epoch 013 | Train Loss: 0.2053 | Val Loss: 0.2005 | Val Acc: 93.64%\n",
            "[LR 0.001] Epoch 014 | Train Loss: 0.2060 | Val Loss: 0.2002 | Val Acc: 93.65%\n",
            "[LR 0.001] Epoch 015 | Train Loss: 0.2052 | Val Loss: 0.1994 | Val Acc: 93.62%\n",
            "[LR 0.001] Epoch 016 | Train Loss: 0.2048 | Val Loss: 0.1987 | Val Acc: 93.61%\n",
            "[LR 0.001] Epoch 017 | Train Loss: 0.2039 | Val Loss: 0.2003 | Val Acc: 93.64%\n",
            "[LR 0.001] Epoch 018 | Train Loss: 0.2043 | Val Loss: 0.2000 | Val Acc: 93.71%\n",
            "[LR 0.001] Epoch 019 | Train Loss: 0.2049 | Val Loss: 0.2007 | Val Acc: 93.61%\n",
            "[LR 0.001] Epoch 020 | Train Loss: 0.2039 | Val Loss: 0.1989 | Val Acc: 93.61%\n",
            "[LR 0.001] Epoch 021 | Train Loss: 0.2032 | Val Loss: 0.1975 | Val Acc: 93.68%\n",
            "[LR 0.001] Epoch 022 | Train Loss: 0.2032 | Val Loss: 0.1988 | Val Acc: 93.67%\n",
            "[LR 0.001] Epoch 023 | Train Loss: 0.2024 | Val Loss: 0.1984 | Val Acc: 93.62%\n",
            "[LR 0.001] Epoch 024 | Train Loss: 0.2044 | Val Loss: 0.1974 | Val Acc: 93.68%\n",
            "[LR 0.001] Epoch 025 | Train Loss: 0.2033 | Val Loss: 0.1980 | Val Acc: 93.68%\n",
            "[LR 0.001] Epoch 026 | Train Loss: 0.2032 | Val Loss: 0.1985 | Val Acc: 93.65%\n",
            "[LR 0.001] Epoch 027 | Train Loss: 0.2020 | Val Loss: 0.1973 | Val Acc: 93.69%\n",
            "[LR 0.001] Epoch 028 | Train Loss: 0.2025 | Val Loss: 0.1976 | Val Acc: 93.69%\n",
            "[LR 0.001] Epoch 029 | Train Loss: 0.2026 | Val Loss: 0.1980 | Val Acc: 93.70%\n",
            "[LR 0.001] Epoch 030 | Train Loss: 0.2032 | Val Loss: 0.1976 | Val Acc: 93.68%\n",
            "[LR 0.001] Epoch 031 | Train Loss: 0.2031 | Val Loss: 0.1974 | Val Acc: 93.64%\n",
            "[LR 0.001] Epoch 032 | Train Loss: 0.2033 | Val Loss: 0.1974 | Val Acc: 93.76%\n",
            "[LR 0.001] Epoch 033 | Train Loss: 0.2036 | Val Loss: 0.1977 | Val Acc: 93.70%\n",
            "[LR 0.001] Epoch 034 | Train Loss: 0.2014 | Val Loss: 0.1990 | Val Acc: 93.73%\n",
            "[LR 0.001] Epoch 035 | Train Loss: 0.2007 | Val Loss: 0.2001 | Val Acc: 93.72%\n",
            "[LR 0.001] Epoch 036 | Train Loss: 0.2017 | Val Loss: 0.1965 | Val Acc: 93.69%\n",
            "[LR 0.001] Epoch 037 | Train Loss: 0.2021 | Val Loss: 0.1977 | Val Acc: 93.70%\n",
            "[LR 0.001] Epoch 038 | Train Loss: 0.2018 | Val Loss: 0.1968 | Val Acc: 93.71%\n",
            "[LR 0.001] Epoch 039 | Train Loss: 0.2009 | Val Loss: 0.1982 | Val Acc: 93.73%\n",
            "[LR 0.001] Epoch 040 | Train Loss: 0.1997 | Val Loss: 0.1972 | Val Acc: 93.69%\n",
            "[LR 0.001] Epoch 041 | Train Loss: 0.2005 | Val Loss: 0.1980 | Val Acc: 93.68%\n",
            "[LR 0.001] Epoch 042 | Train Loss: 0.2021 | Val Loss: 0.1973 | Val Acc: 93.71%\n",
            "[LR 0.001] Epoch 043 | Train Loss: 0.2015 | Val Loss: 0.1969 | Val Acc: 93.73%\n",
            "[LR 0.001] Epoch 044 | Train Loss: 0.1999 | Val Loss: 0.1983 | Val Acc: 93.62%\n",
            "[LR 0.001] Epoch 045 | Train Loss: 0.2009 | Val Loss: 0.1974 | Val Acc: 93.73%\n",
            "[LR 0.001] Epoch 046 | Train Loss: 0.2006 | Val Loss: 0.1980 | Val Acc: 93.71%\n",
            "* Early Stopping triggered for lr=0.001\n",
            "\n",
            "==============================\n",
            "학습률 0.01 실험 시작\n",
            "==============================\n",
            "[LR 0.01] Epoch 001 | Train Loss: 0.2270 | Val Loss: 0.2133 | Val Acc: 93.47%\n",
            "[LR 0.01] Epoch 002 | Train Loss: 0.2193 | Val Loss: 0.2083 | Val Acc: 93.43%\n",
            "[LR 0.01] Epoch 003 | Train Loss: 0.2152 | Val Loss: 0.2049 | Val Acc: 93.48%\n",
            "[LR 0.01] Epoch 004 | Train Loss: 0.2153 | Val Loss: 0.2074 | Val Acc: 93.46%\n",
            "[LR 0.01] Epoch 005 | Train Loss: 0.2121 | Val Loss: 0.2068 | Val Acc: 93.49%\n",
            "[LR 0.01] Epoch 006 | Train Loss: 0.2118 | Val Loss: 0.2088 | Val Acc: 93.42%\n",
            "[LR 0.01] Epoch 007 | Train Loss: 0.2103 | Val Loss: 0.2031 | Val Acc: 93.58%\n",
            "[LR 0.01] Epoch 008 | Train Loss: 0.2094 | Val Loss: 0.2022 | Val Acc: 93.55%\n",
            "[LR 0.01] Epoch 009 | Train Loss: 0.2096 | Val Loss: 0.2007 | Val Acc: 93.63%\n",
            "[LR 0.01] Epoch 010 | Train Loss: 0.2086 | Val Loss: 0.2016 | Val Acc: 93.59%\n",
            "[LR 0.01] Epoch 011 | Train Loss: 0.2092 | Val Loss: 0.2057 | Val Acc: 93.54%\n",
            "[LR 0.01] Epoch 012 | Train Loss: 0.2070 | Val Loss: 0.2011 | Val Acc: 93.55%\n",
            "[LR 0.01] Epoch 013 | Train Loss: 0.2073 | Val Loss: 0.2014 | Val Acc: 93.59%\n",
            "[LR 0.01] Epoch 014 | Train Loss: 0.2066 | Val Loss: 0.2008 | Val Acc: 93.60%\n",
            "[LR 0.01] Epoch 015 | Train Loss: 0.2083 | Val Loss: 0.2001 | Val Acc: 93.63%\n",
            "[LR 0.01] Epoch 016 | Train Loss: 0.2067 | Val Loss: 0.2002 | Val Acc: 93.59%\n",
            "[LR 0.01] Epoch 017 | Train Loss: 0.2075 | Val Loss: 0.2018 | Val Acc: 93.64%\n",
            "[LR 0.01] Epoch 018 | Train Loss: 0.2052 | Val Loss: 0.2002 | Val Acc: 93.59%\n",
            "[LR 0.01] Epoch 019 | Train Loss: 0.2062 | Val Loss: 0.1993 | Val Acc: 93.66%\n",
            "[LR 0.01] Epoch 020 | Train Loss: 0.2056 | Val Loss: 0.1994 | Val Acc: 93.67%\n",
            "[LR 0.01] Epoch 021 | Train Loss: 0.2062 | Val Loss: 0.2010 | Val Acc: 93.61%\n",
            "[LR 0.01] Epoch 022 | Train Loss: 0.2063 | Val Loss: 0.1997 | Val Acc: 93.55%\n",
            "[LR 0.01] Epoch 023 | Train Loss: 0.2065 | Val Loss: 0.2002 | Val Acc: 93.66%\n",
            "[LR 0.01] Epoch 024 | Train Loss: 0.2055 | Val Loss: 0.1992 | Val Acc: 93.67%\n",
            "[LR 0.01] Epoch 025 | Train Loss: 0.2054 | Val Loss: 0.2016 | Val Acc: 93.66%\n",
            "[LR 0.01] Epoch 026 | Train Loss: 0.2055 | Val Loss: 0.2041 | Val Acc: 93.68%\n",
            "[LR 0.01] Epoch 027 | Train Loss: 0.2047 | Val Loss: 0.2085 | Val Acc: 93.59%\n",
            "[LR 0.01] Epoch 028 | Train Loss: 0.2054 | Val Loss: 0.2012 | Val Acc: 93.62%\n",
            "[LR 0.01] Epoch 029 | Train Loss: 0.2054 | Val Loss: 0.2001 | Val Acc: 93.59%\n",
            "[LR 0.01] Epoch 030 | Train Loss: 0.2048 | Val Loss: 0.1994 | Val Acc: 93.63%\n",
            "[LR 0.01] Epoch 031 | Train Loss: 0.2052 | Val Loss: 0.2002 | Val Acc: 93.58%\n",
            "[LR 0.01] Epoch 032 | Train Loss: 0.2050 | Val Loss: 0.1993 | Val Acc: 93.60%\n",
            "[LR 0.01] Epoch 033 | Train Loss: 0.2040 | Val Loss: 0.1972 | Val Acc: 93.69%\n",
            "[LR 0.01] Epoch 034 | Train Loss: 0.2052 | Val Loss: 0.1982 | Val Acc: 93.69%\n",
            "[LR 0.01] Epoch 035 | Train Loss: 0.2047 | Val Loss: 0.2061 | Val Acc: 93.69%\n",
            "[LR 0.01] Epoch 036 | Train Loss: 0.2036 | Val Loss: 0.1999 | Val Acc: 93.69%\n",
            "[LR 0.01] Epoch 037 | Train Loss: 0.2042 | Val Loss: 0.1971 | Val Acc: 93.75%\n",
            "[LR 0.01] Epoch 038 | Train Loss: 0.2041 | Val Loss: 0.1985 | Val Acc: 93.69%\n",
            "[LR 0.01] Epoch 039 | Train Loss: 0.2041 | Val Loss: 0.1988 | Val Acc: 93.71%\n",
            "[LR 0.01] Epoch 040 | Train Loss: 0.2044 | Val Loss: 0.2045 | Val Acc: 93.55%\n",
            "[LR 0.01] Epoch 041 | Train Loss: 0.2039 | Val Loss: 0.1992 | Val Acc: 93.62%\n",
            "[LR 0.01] Epoch 042 | Train Loss: 0.2032 | Val Loss: 0.1982 | Val Acc: 93.73%\n",
            "[LR 0.01] Epoch 043 | Train Loss: 0.2042 | Val Loss: 0.1979 | Val Acc: 93.73%\n",
            "[LR 0.01] Epoch 044 | Train Loss: 0.2036 | Val Loss: 0.2000 | Val Acc: 93.67%\n",
            "[LR 0.01] Epoch 045 | Train Loss: 0.2043 | Val Loss: 0.1988 | Val Acc: 93.64%\n",
            "[LR 0.01] Epoch 046 | Train Loss: 0.2041 | Val Loss: 0.1988 | Val Acc: 93.65%\n",
            "[LR 0.01] Epoch 047 | Train Loss: 0.2031 | Val Loss: 0.1974 | Val Acc: 93.68%\n",
            "* Early Stopping triggered for lr=0.01\n",
            "\n",
            "==============================\n",
            "학습률 0.1 실험 시작\n",
            "==============================\n",
            "[LR 0.1] Epoch 001 | Train Loss: 0.2518 | Val Loss: 0.2176 | Val Acc: 93.11%\n",
            "[LR 0.1] Epoch 002 | Train Loss: 0.2417 | Val Loss: 0.2181 | Val Acc: 93.29%\n",
            "[LR 0.1] Epoch 003 | Train Loss: 0.2387 | Val Loss: 0.2117 | Val Acc: 93.08%\n",
            "[LR 0.1] Epoch 004 | Train Loss: 0.2330 | Val Loss: 0.2702 | Val Acc: 88.25%\n",
            "[LR 0.1] Epoch 005 | Train Loss: 0.2353 | Val Loss: 0.2187 | Val Acc: 92.98%\n",
            "[LR 0.1] Epoch 006 | Train Loss: 0.2315 | Val Loss: 0.2092 | Val Acc: 93.39%\n",
            "[LR 0.1] Epoch 007 | Train Loss: 0.2338 | Val Loss: 0.2452 | Val Acc: 93.39%\n",
            "[LR 0.1] Epoch 008 | Train Loss: 0.2298 | Val Loss: 0.2106 | Val Acc: 93.53%\n",
            "[LR 0.1] Epoch 009 | Train Loss: 0.2298 | Val Loss: 0.2200 | Val Acc: 93.50%\n",
            "[LR 0.1] Epoch 010 | Train Loss: 0.2301 | Val Loss: 0.2096 | Val Acc: 93.55%\n",
            "[LR 0.1] Epoch 011 | Train Loss: 0.2331 | Val Loss: 0.2060 | Val Acc: 93.57%\n",
            "[LR 0.1] Epoch 012 | Train Loss: 0.2287 | Val Loss: 0.2065 | Val Acc: 93.53%\n",
            "[LR 0.1] Epoch 013 | Train Loss: 0.2299 | Val Loss: 0.2083 | Val Acc: 93.44%\n",
            "[LR 0.1] Epoch 014 | Train Loss: 0.2290 | Val Loss: 0.2038 | Val Acc: 93.63%\n",
            "[LR 0.1] Epoch 015 | Train Loss: 0.2296 | Val Loss: 0.2059 | Val Acc: 93.30%\n",
            "[LR 0.1] Epoch 016 | Train Loss: 0.2277 | Val Loss: 0.2076 | Val Acc: 93.53%\n",
            "[LR 0.1] Epoch 017 | Train Loss: 0.2266 | Val Loss: 0.2057 | Val Acc: 93.57%\n",
            "[LR 0.1] Epoch 018 | Train Loss: 0.2257 | Val Loss: 0.2037 | Val Acc: 93.54%\n",
            "[LR 0.1] Epoch 019 | Train Loss: 0.2276 | Val Loss: 0.2056 | Val Acc: 93.45%\n",
            "[LR 0.1] Epoch 020 | Train Loss: 0.2278 | Val Loss: 0.2284 | Val Acc: 93.46%\n",
            "[LR 0.1] Epoch 021 | Train Loss: 0.2245 | Val Loss: 0.2080 | Val Acc: 93.55%\n",
            "[LR 0.1] Epoch 022 | Train Loss: 0.2274 | Val Loss: 0.2034 | Val Acc: 93.53%\n",
            "[LR 0.1] Epoch 023 | Train Loss: 0.2264 | Val Loss: 0.2044 | Val Acc: 93.49%\n",
            "[LR 0.1] Epoch 024 | Train Loss: 0.2281 | Val Loss: 0.2059 | Val Acc: 93.59%\n",
            "[LR 0.1] Epoch 025 | Train Loss: 0.2258 | Val Loss: 0.2032 | Val Acc: 93.63%\n",
            "[LR 0.1] Epoch 026 | Train Loss: 0.2257 | Val Loss: 0.2234 | Val Acc: 93.52%\n",
            "[LR 0.1] Epoch 027 | Train Loss: 0.2255 | Val Loss: 0.2061 | Val Acc: 93.60%\n",
            "[LR 0.1] Epoch 028 | Train Loss: 0.2266 | Val Loss: 0.2362 | Val Acc: 91.91%\n",
            "[LR 0.1] Epoch 029 | Train Loss: 0.2263 | Val Loss: 0.2044 | Val Acc: 93.61%\n",
            "[LR 0.1] Epoch 030 | Train Loss: 0.2260 | Val Loss: 0.2119 | Val Acc: 93.17%\n",
            "[LR 0.1] Epoch 031 | Train Loss: 0.2281 | Val Loss: 0.2264 | Val Acc: 91.88%\n",
            "[LR 0.1] Epoch 032 | Train Loss: 0.2238 | Val Loss: 0.2213 | Val Acc: 93.58%\n",
            "[LR 0.1] Epoch 033 | Train Loss: 0.2247 | Val Loss: 0.2051 | Val Acc: 93.55%\n",
            "[LR 0.1] Epoch 034 | Train Loss: 0.2270 | Val Loss: 0.2074 | Val Acc: 93.56%\n",
            "[LR 0.1] Epoch 035 | Train Loss: 0.2263 | Val Loss: 0.2097 | Val Acc: 93.16%\n",
            "* Early Stopping triggered for lr=0.1\n",
            "\n",
            "< 학습률별 최종 성능 비교 >\n",
            "LR        Accuracy  F1        Precision Recall    \n",
            "0.001     93.76     0.9432    0.9570    0.9298    \n",
            "0.01      93.75     0.9431    0.9572    0.9293    \n",
            "0.1       93.63     0.9419    0.9577    0.9266    \n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Using device:\", device)\n",
        "\n",
        "    dataset = Dataset(file_name='re_log_model_preprocessed.csv')\n",
        "    train_dataset, val_dataset = dataset.get_train_dataset()\n",
        "\n",
        "    Cin = train_dataset.__getitem__(0)[0].shape\n",
        "    print(f\"num Feature : {Cin}\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    val_loader   = DataLoader(val_dataset,   batch_size=32)\n",
        "\n",
        "    # 🔹 테스트할 학습률 리스트\n",
        "    learning_rates = [0.001, 0.01, 0.1]\n",
        "    results = []  # 각 학습률별 성능 저장 리스트\n",
        "\n",
        "    for lr in learning_rates:\n",
        "        print(f\"\\n==============================\")\n",
        "        print(f\"학습률 {lr} 실험 시작\")\n",
        "        print(f\"==============================\")\n",
        "\n",
        "        model = MLP_model(Cin[0]).to(device)\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "        train_epoch = 100\n",
        "        best_metrics = {'f1': 0, 'precision': 0, 'recall': 0, 'accuracy': 0}\n",
        "\n",
        "        es = EarlyStopping(patience=10, min_delta=0.0, path=f'../best_model_lr{lr}.pt')\n",
        "\n",
        "        for epoch in range(train_epoch):\n",
        "            # 학습\n",
        "            model.train()\n",
        "            train_loss = 0.0\n",
        "            for batch_data, batch_label in train_loader:\n",
        "                batch_data = batch_data.to(device).float()\n",
        "                batch_label = batch_label.to(device).float().unsqueeze(-1)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(batch_data)\n",
        "                loss = criterion(outputs, batch_label)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                train_loss += loss.item()\n",
        "\n",
        "            avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "            # 검증\n",
        "            model.eval()\n",
        "            val_loss = 0.0\n",
        "            correct, total = 0, 0\n",
        "            all_preds, all_labels = [], []\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch_data, batch_label in val_loader:\n",
        "                    batch_data = batch_data.to(device).float()\n",
        "                    batch_label = batch_label.to(device).float().unsqueeze(-1)\n",
        "\n",
        "                    outputs = model(batch_data)\n",
        "                    loss = criterion(outputs, batch_label)\n",
        "                    val_loss += loss.item()\n",
        "                    probs = torch.sigmoid(outputs)\n",
        "                    preds = (probs > 0.5).float()\n",
        "\n",
        "                    correct += (preds == batch_label).sum().item()\n",
        "                    total += batch_label.size(0)\n",
        "                    all_preds.extend(preds.cpu().numpy().ravel())\n",
        "                    all_labels.extend(batch_label.cpu().numpy().ravel())\n",
        "\n",
        "            avg_val_loss = val_loss / len(val_loader)\n",
        "            val_accuracy = 100 * correct / total\n",
        "            val_f1 = f1_score(all_labels, all_preds)\n",
        "            val_precision = precision_score(all_labels, all_preds)\n",
        "            val_recall = recall_score(all_labels, all_preds)\n",
        "\n",
        "            print(f\"[LR {lr}] Epoch {epoch+1:03d} | \"\n",
        "                  f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val Acc: {val_accuracy:.2f}%\")\n",
        "\n",
        "            # EarlyStopping\n",
        "            es(avg_val_loss, model)\n",
        "            if es.early_stop:\n",
        "                print(f\"* Early Stopping triggered for lr={lr}\")\n",
        "                break\n",
        "\n",
        "            # Best metrics 갱신\n",
        "            if val_accuracy > best_metrics['accuracy']:\n",
        "                best_metrics.update({\n",
        "                    'f1': val_f1, 'precision': val_precision,\n",
        "                    'recall': val_recall, 'accuracy': val_accuracy\n",
        "                })\n",
        "\n",
        "        # 학습 완료 후 결과 저장\n",
        "        results.append({\n",
        "            'lr': lr,\n",
        "            'f1': best_metrics['f1'],\n",
        "            'precision': best_metrics['precision'],\n",
        "            'recall': best_metrics['recall'],\n",
        "            'accuracy': best_metrics['accuracy']\n",
        "        })\n",
        "\n",
        "    # ---------------- 결과 비교 출력 ----------------\n",
        "    print(\"\\n< 학습률별 최종 성능 비교 >\")\n",
        "    print(\"{:<10}{:<10}{:<10}{:<10}{:<10}\".format(\"LR\", \"Accuracy\", \"F1\", \"Precision\", \"Recall\"))\n",
        "    for r in results:\n",
        "        print(\"{:<10}{:<10.2f}{:<10.4f}{:<10.4f}{:<10.4f}\".format(\n",
        "            r['lr'], r['accuracy'], r['f1'], r['precision'], r['recall']\n",
        "        ))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ROC-AUC , PR-AUC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeWCmlxFxyXo",
        "outputId": "55db9777-d1ba-4d9c-9827-48723ad37aba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Model loaded successfully\n",
            "\n",
            "ROC-AUC : 0.9658\n",
            "PR-AUC  : 0.9791\n"
          ]
        }
      ],
      "source": [
        "#ROC-AUC, PR-AUC  계산\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# 데이터셋 불러오기\n",
        "dataset = Dataset(file_name='re_log_model_preprocessed.csv')\n",
        "train_dataset, val_dataset = dataset.get_train_dataset()\n",
        "\n",
        "# DataLoader\n",
        "from torch.utils.data import DataLoader\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "\n",
        "Cin = train_dataset.__getitem__(0)[0].shape[0]\n",
        "\n",
        "# 모델 구조 정의 동일해야함\n",
        "import torch.nn as nn\n",
        "\n",
        "class MLP_model(nn.Module):\n",
        "    def __init__(self, Cin):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(Cin, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            nn.Linear(128, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            nn.Linear(64, 32),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "# 모델 불러오기\n",
        "model = MLP_model(Cin).to(device)\n",
        "state_dict = torch.load(\"/best_model.pt\", map_location=device)\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval()\n",
        "print(\"Model loaded successfully\")\n",
        "\n",
        "# 예측, AUC 계산\n",
        "y_probs, y_trues = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for xb, yb in val_loader:\n",
        "        xb = xb.to(device).float()\n",
        "        yb = yb.to(device).float()\n",
        "\n",
        "        out = model(xb)\n",
        "        prob = torch.sigmoid(out)\n",
        "        y_probs.append(prob.detach().cpu().numpy().ravel())\n",
        "        y_trues.append(yb.detach().cpu().numpy().ravel())\n",
        "\n",
        "\n",
        "y_prob = np.concatenate(y_probs)\n",
        "y_true = np.concatenate(y_trues)\n",
        "\n",
        "roc_auc = roc_auc_score(y_true, y_prob)\n",
        "pr_auc = average_precision_score(y_true, y_prob)\n",
        "\n",
        "print(f\"\\nROC-AUC : {roc_auc:.4f}\")\n",
        "print(f\"PR-AUC  : {pr_auc:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
