{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28221c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow 설치\n",
    "%pip install tensorflow\n",
    "\n",
    "# PyTorch 설치 (기본 CPU 버전)\n",
    "%pip install torch torchvision torchaudio\n",
    "\n",
    "# PyTorch로 만든 모델을 scikit-learn처럼 편하게 학습/평가/튜닝할 때 사용\n",
    "%pip install skorch\n",
    "# TensorFlow 설치\n",
    "%pip install tensorflow\n",
    "\n",
    "# PyTorch 설치 (기본 CPU 버전)\n",
    "# %pip install torch torchvision torchaudio\n",
    "\n",
    "# NumPy, Pandas, scikit-learn 설치\n",
    "%pip install numpy pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569a44ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92795c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip uninstall torch torchvision torchaudio -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5695216e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu130\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc82a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)          # CUDA 버전 확인\n",
    "print(torch.cuda.is_available())   # True = GPU 사용 가능\n",
    "print(torch.cuda.get_device_name(0)) # GPU 이름 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a7cd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f388aa2",
   "metadata": {},
   "source": [
    "#### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3029de31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 데이터 불러오기 1 : 기존 수치형 데이터\n",
    "# import pandas as pd\n",
    "# url = \"C:\\\\Users\\\\Playdata2\\\\Downloads\\\\tree_model_preprocessed.csv\"\n",
    "# df = pd.read_csv(url)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e6b1d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subscription_age</th>\n",
       "      <th>service_failure_count</th>\n",
       "      <th>download_over_limit</th>\n",
       "      <th>churn</th>\n",
       "      <th>contract_type_active</th>\n",
       "      <th>contract_type_expired</th>\n",
       "      <th>contract_type_no_contract</th>\n",
       "      <th>sub_both</th>\n",
       "      <th>sub_movie</th>\n",
       "      <th>sub_none</th>\n",
       "      <th>sub_tv</th>\n",
       "      <th>bill_avg_log</th>\n",
       "      <th>download_avg_log</th>\n",
       "      <th>upload_avg_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>2.240710</td>\n",
       "      <td>1.193922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>2.687847</td>\n",
       "      <td>0.641854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subscription_age  service_failure_count  download_over_limit  churn  \\\n",
       "0             11.95                      0                    0      0   \n",
       "1              8.22                      0                    0      1   \n",
       "2              8.91                      0                    0      1   \n",
       "3              6.87                      1                    0      1   \n",
       "4              6.39                      0                    0      1   \n",
       "\n",
       "   contract_type_active  contract_type_expired  contract_type_no_contract  \\\n",
       "0                     1                      0                          0   \n",
       "1                     0                      0                          1   \n",
       "2                     0                      1                          0   \n",
       "3                     0                      0                          1   \n",
       "4                     0                      0                          1   \n",
       "\n",
       "   sub_both  sub_movie  sub_none  sub_tv  bill_avg_log  download_avg_log  \\\n",
       "0         0          0         0       1      3.258097          2.240710   \n",
       "1         0          0         1       0      0.000000          0.000000   \n",
       "2         0          0         0       1      2.833213          2.687847   \n",
       "3         0          0         1       0      3.091042          0.000000   \n",
       "4         0          0         1       0      0.000000          0.000000   \n",
       "\n",
       "   upload_avg_log  \n",
       "0        1.193922  \n",
       "1        0.000000  \n",
       "2        0.641854  \n",
       "3        0.000000  \n",
       "4        0.000000  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기 2 : 로그변환 수치형 데이터\n",
    "import pandas as pd\n",
    "url = \"../../DL_data/dataset/re_log_model_preprocessed.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fa1061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Fitting 3 folds for each of 150 candidates, totalling 450 fits\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.9312\u001b[0m        \u001b[32m0.2247\u001b[0m       \u001b[35m0.9350\u001b[0m        \u001b[31m0.2045\u001b[0m  1.6397\n",
      "      2       0.9339        \u001b[32m0.2086\u001b[0m       \u001b[35m0.9345\u001b[0m        \u001b[31m0.2027\u001b[0m  1.5303\n",
      "      3       0.9339        \u001b[32m0.2055\u001b[0m       0.9352        \u001b[31m0.1994\u001b[0m  1.6467\n",
      "      4       0.9348        \u001b[32m0.2036\u001b[0m       0.9363        \u001b[31m0.1971\u001b[0m  1.7901\n",
      "      5       0.9349        \u001b[32m0.2023\u001b[0m       0.9365        \u001b[31m0.1950\u001b[0m  1.8105\n",
      "      6       0.9353        \u001b[32m0.2014\u001b[0m       0.9365        0.1952  1.8300\n",
      "      7       0.9360        \u001b[32m0.2004\u001b[0m       0.9377        \u001b[31m0.1941\u001b[0m  1.8279\n",
      "      8       0.9362        \u001b[32m0.1992\u001b[0m       0.9382        0.1949  1.8041\n",
      "      9       0.9367        \u001b[32m0.1988\u001b[0m       0.9384        \u001b[31m0.1931\u001b[0m  1.8049\n",
      "     10       0.9367        \u001b[32m0.1979\u001b[0m       0.9382        \u001b[31m0.1912\u001b[0m  1.8173\n",
      "     11       0.9369        \u001b[32m0.1971\u001b[0m       0.9374        \u001b[31m0.1910\u001b[0m  1.8163\n",
      "     12       0.9366        \u001b[32m0.1957\u001b[0m       0.9390        \u001b[31m0.1905\u001b[0m  1.9061\n",
      "     13       0.9372        \u001b[32m0.1950\u001b[0m       0.9389        \u001b[31m0.1896\u001b[0m  2.0514\n",
      "     14       0.9372        \u001b[32m0.1942\u001b[0m       0.9391        \u001b[31m0.1892\u001b[0m  1.9386\n",
      "     15       0.9374        \u001b[32m0.1937\u001b[0m       0.9393        0.1902  1.9920\n",
      "     16       0.9374        \u001b[32m0.1930\u001b[0m       0.9385        0.1901  1.8746\n",
      "     17       0.9376        \u001b[32m0.1926\u001b[0m       0.9391        \u001b[31m0.1884\u001b[0m  1.8848\n",
      "     18       0.9375        \u001b[32m0.1920\u001b[0m       0.9388        0.1901  1.8531\n",
      "     19       0.9379        \u001b[32m0.1913\u001b[0m       0.9393        0.1890  1.9043\n",
      "     20       0.9380        \u001b[32m0.1909\u001b[0m       0.9386        0.1888  1.8680\n",
      "     21       0.9377        \u001b[32m0.1900\u001b[0m       0.9398        0.1897  1.8777\n",
      "     22       0.9382        \u001b[32m0.1897\u001b[0m       0.9386        \u001b[31m0.1872\u001b[0m  1.8528\n",
      "     23       0.9381        \u001b[32m0.1891\u001b[0m       0.9388        0.1891  1.8797\n",
      "     24       0.9384        \u001b[32m0.1880\u001b[0m       0.9391        \u001b[31m0.1869\u001b[0m  1.8941\n",
      "     25       0.9386        \u001b[32m0.1879\u001b[0m       0.9387        0.1881  1.8853\n",
      "     26       0.9387        \u001b[32m0.1871\u001b[0m       0.9388        \u001b[31m0.1857\u001b[0m  1.8854\n",
      "     27       0.9387        \u001b[32m0.1862\u001b[0m       0.9398        0.1865  1.9063\n",
      "     28       0.9384        \u001b[32m0.1858\u001b[0m       0.9391        0.1866  1.8738\n",
      "     29       0.9389        \u001b[32m0.1850\u001b[0m       0.9395        0.1864  1.8639\n",
      "     30       0.9391        \u001b[32m0.1840\u001b[0m       0.9389        \u001b[31m0.1854\u001b[0m  1.8648\n",
      "Accuracy: 0.9357\n",
      "Precision: 0.9540\n",
      "Recall: 0.9300\n",
      "F1 Score: 0.9418\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9136    0.9429    0.9281      6327\n",
      "         1.0     0.9540    0.9300    0.9418      8052\n",
      "\n",
      "    accuracy                         0.9357     14379\n",
      "   macro avg     0.9338    0.9364    0.9349     14379\n",
      "weighted avg     0.9362    0.9357    0.9358     14379\n",
      "\n",
      "Best Parameters Found:\n",
      "{'net__optimizer__weight_decay': 0.0, 'net__optimizer': <class 'torch.optim.adam.Adam'>, 'net__module__layers': [128, 64, 32], 'net__module__activation': <class 'torch.nn.modules.activation.Tanh'>, 'net__max_epochs': 30, 'net__lr': 0.001, 'net__batch_size': 64}\n"
     ]
    }
   ],
   "source": [
    "# 랜덤서치 3-150\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import numpy as np\n",
    "from skorch.callbacks import EarlyStopping,EpochScoring\n",
    "\n",
    "# GPU 자동 선택\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# 데이터 준비\n",
    "X = df.drop('churn', axis=1).values.astype(np.float32)\n",
    "y = df['churn'].values.astype(np.float32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# PyTorch 모델 정의 (BCEWithLogitsLoss용)\n",
    "class ChurnModel(nn.Module):\n",
    "    def __init__(self, layers=[64,32,16], activation=nn.ReLU):\n",
    "        super().__init__()\n",
    "        layer_list = []\n",
    "        input_dim = X_train.shape[1]\n",
    "        for l in layers:\n",
    "            layer_list.append(nn.Linear(input_dim, l))\n",
    "            layer_list.append(activation())\n",
    "            input_dim = l\n",
    "        layer_list.append(nn.Linear(input_dim, 1))  # 마지막 Linear\n",
    "        self.network = nn.Sequential(*layer_list)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.network(X).squeeze(1)\n",
    "\n",
    "# skorch 래퍼\n",
    "net = NeuralNetClassifier(\n",
    "    module=ChurnModel,\n",
    "    max_epochs=10,\n",
    "    lr=0.001,\n",
    "    batch_size=32,\n",
    "    optimizer=optim.Adam,\n",
    "    criterion=nn.BCEWithLogitsLoss,\n",
    "    iterator_train__shuffle=True,\n",
    "    device=device,\n",
    "    callbacks=[EarlyStopping(patience=5), # 개선 없으면 학습 중단\n",
    "        EpochScoring('accuracy', on_train=True, name='train_acc'),\n",
    "        EpochScoring('accuracy', on_train=False, name='valid_acc')\n",
    "    ],\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# 파이프라인 생성\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('net', net)\n",
    "])\n",
    "\n",
    "# 랜덤서치할 파라미터\n",
    "param_dist = {\n",
    "    'net__module__layers': [[16, 8], [16, 8, 4], [16, 8, 16], [16, 32, 16], [64, 32], [64, 32, 16], [64, 32, 64], [128, 64, 32]],\n",
    "    'net__module__activation': [nn.ReLU, nn.Tanh],\n",
    "    'net__optimizer': [optim.Adam, optim.SGD],\n",
    "    'net__lr': [0.001, 0.01, 0.1],\n",
    "    'net__optimizer__weight_decay': [0.0, 0.0001, 0.001],\n",
    "    'net__batch_size': [32, 64, 128],\n",
    "    'net__max_epochs': [10, 20, 30]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=150,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# RandomizedSearchCV 학습\n",
    "random_result = random_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적 모델로 예측\n",
    "best_model = random_result.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# classification metrics\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Precision: {:.4f}\".format(precision_score(y_test, y_pred)))\n",
    "print(\"Recall: {:.4f}\".format(recall_score(y_test, y_pred)))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_score(y_test, y_pred)))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "# 최적 하이퍼파라미터 확인\n",
    "print(\"Best Parameters Found:\")\n",
    "print(random_result.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecec216c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Fitting 3 folds for each of 300 candidates, totalling 900 fits\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.9212\u001b[0m        \u001b[32m0.2531\u001b[0m       \u001b[35m0.9352\u001b[0m        \u001b[31m0.2024\u001b[0m  0.9982\n",
      "      2       0.9341        \u001b[32m0.2063\u001b[0m       0.9365        \u001b[31m0.1998\u001b[0m  1.0180\n",
      "      3       0.9348        \u001b[32m0.2038\u001b[0m       0.9371        \u001b[31m0.1983\u001b[0m  1.0128\n",
      "      4       0.9351        \u001b[32m0.2025\u001b[0m       0.9368        0.1983  1.0089\n",
      "      5       0.9355        \u001b[32m0.2014\u001b[0m       0.9371        \u001b[31m0.1967\u001b[0m  1.0188\n",
      "      6       0.9358        \u001b[32m0.2010\u001b[0m       0.9371        0.1969  1.0305\n",
      "      7       0.9358        \u001b[32m0.2008\u001b[0m       0.9373        \u001b[31m0.1949\u001b[0m  1.0179\n",
      "      8       0.9356        \u001b[32m0.2003\u001b[0m       0.9366        0.1955  1.0047\n",
      "      9       0.9362        \u001b[32m0.1997\u001b[0m       0.9365        0.1968  1.0390\n",
      "     10       0.9362        \u001b[32m0.1992\u001b[0m       0.9373        \u001b[31m0.1941\u001b[0m  1.0367\n",
      "     11       0.9361        \u001b[32m0.1984\u001b[0m       0.9368        0.1941  1.0094\n",
      "     12       0.9362        \u001b[32m0.1982\u001b[0m       0.9368        \u001b[31m0.1937\u001b[0m  1.0294\n",
      "     13       0.9364        \u001b[32m0.1978\u001b[0m       0.9380        0.1948  1.0483\n",
      "     14       0.9366        \u001b[32m0.1976\u001b[0m       0.9380        0.1947  1.0107\n",
      "     15       0.9367        \u001b[32m0.1970\u001b[0m       0.9381        \u001b[31m0.1929\u001b[0m  1.0233\n",
      "     16       0.9364        0.1971       0.9374        0.1934  1.0241\n",
      "     17       0.9367        \u001b[32m0.1963\u001b[0m       0.9375        0.1934  1.0243\n",
      "     18       0.9371        \u001b[32m0.1958\u001b[0m       0.9378        0.1932  1.0370\n",
      "     19       0.9367        \u001b[32m0.1958\u001b[0m       0.9380        \u001b[31m0.1919\u001b[0m  1.0192\n",
      "     20       0.9366        \u001b[32m0.1955\u001b[0m       0.9371        0.1927  1.0377\n",
      "     21       0.9372        \u001b[32m0.1948\u001b[0m       0.9379        \u001b[31m0.1916\u001b[0m  1.0026\n",
      "     22       0.9370        0.1950       0.9377        0.1916  1.0106\n",
      "     23       0.9370        0.1948       0.9383        \u001b[31m0.1913\u001b[0m  1.0377\n",
      "     24       0.9374        \u001b[32m0.1944\u001b[0m       0.9384        \u001b[31m0.1909\u001b[0m  1.0234\n",
      "     25       0.9372        \u001b[32m0.1939\u001b[0m       0.9385        0.1934  1.0139\n",
      "     26       0.9371        \u001b[32m0.1937\u001b[0m       0.9384        0.1921  1.0405\n",
      "     27       0.9372        \u001b[32m0.1936\u001b[0m       0.9382        \u001b[31m0.1903\u001b[0m  1.0337\n",
      "     28       0.9376        \u001b[32m0.1931\u001b[0m       0.9390        0.1909  1.0047\n",
      "     29       0.9373        \u001b[32m0.1929\u001b[0m       0.9380        0.1917  1.0071\n",
      "     30       0.9375        0.1930       0.9388        \u001b[31m0.1897\u001b[0m  1.0226\n",
      "Accuracy: 0.9355\n",
      "Precision: 0.9512\n",
      "Recall: 0.9326\n",
      "F1 Score: 0.9418\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9163    0.9391    0.9276      6327\n",
      "         1.0     0.9512    0.9326    0.9418      8052\n",
      "\n",
      "    accuracy                         0.9355     14379\n",
      "   macro avg     0.9337    0.9359    0.9347     14379\n",
      "weighted avg     0.9358    0.9355    0.9355     14379\n",
      "\n",
      "Best Parameters Found:\n",
      "{'net__optimizer__weight_decay': 0.0001, 'net__optimizer': <class 'torch.optim.adam.Adam'>, 'net__module__layers': [64, 32, 64], 'net__module__activation': <class 'torch.nn.modules.activation.ReLU'>, 'net__max_epochs': 30, 'net__lr': 0.001, 'net__batch_size': 128}\n"
     ]
    }
   ],
   "source": [
    "# 랜덤서치 3-300\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import numpy as np\n",
    "from skorch.callbacks import EarlyStopping,EpochScoring\n",
    "\n",
    "# GPU 자동 선택\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# 데이터 준비\n",
    "X = df.drop('churn', axis=1).values.astype(np.float32)\n",
    "y = df['churn'].values.astype(np.float32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# PyTorch 모델 정의 (BCEWithLogitsLoss용)\n",
    "class ChurnModel(nn.Module):\n",
    "    def __init__(self, layers=[64,32,16], activation=nn.ReLU):\n",
    "        super().__init__()\n",
    "        layer_list = []\n",
    "        input_dim = X_train.shape[1]\n",
    "        for l in layers:\n",
    "            layer_list.append(nn.Linear(input_dim, l))\n",
    "            layer_list.append(activation())\n",
    "            input_dim = l\n",
    "        layer_list.append(nn.Linear(input_dim, 1))  # 마지막 Linear\n",
    "        self.network = nn.Sequential(*layer_list)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.network(X).squeeze(1)\n",
    "\n",
    "# skorch 래퍼\n",
    "net = NeuralNetClassifier(\n",
    "    module=ChurnModel,\n",
    "    max_epochs=10,\n",
    "    lr=0.001,\n",
    "    batch_size=32,\n",
    "    optimizer=optim.Adam,\n",
    "    criterion=nn.BCEWithLogitsLoss,\n",
    "    iterator_train__shuffle=True,\n",
    "    device=device,\n",
    "    callbacks=[EarlyStopping(patience=5), # 개선 없으면 학습 중단\n",
    "        EpochScoring('accuracy', on_train=True, name='train_acc'),\n",
    "        EpochScoring('accuracy', on_train=False, name='valid_acc')\n",
    "    ],\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# 파이프라인 생성\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('net', net)\n",
    "])\n",
    "\n",
    "# 랜덤서치할 파라미터\n",
    "param_dist = {\n",
    "    'net__module__layers': [[16, 8], [16, 8, 4], [16, 8, 16], [16, 32, 16], [64, 32], [64, 32, 16], [64, 32, 64], [128, 64, 32]],\n",
    "    'net__module__activation': [nn.ReLU, nn.Tanh],\n",
    "    'net__optimizer': [optim.Adam, optim.SGD],\n",
    "    'net__lr': [0.001, 0.01, 0.1],\n",
    "    'net__optimizer__weight_decay': [0.0, 0.0001, 0.001],\n",
    "    'net__batch_size': [32, 64, 128],\n",
    "    'net__max_epochs': [10, 20, 30]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter= 300,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# RandomizedSearchCV 학습\n",
    "random_result = random_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적 모델로 예측\n",
    "best_model = random_result.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# classification metrics\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Precision: {:.4f}\".format(precision_score(y_test, y_pred)))\n",
    "print(\"Recall: {:.4f}\".format(recall_score(y_test, y_pred)))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_score(y_test, y_pred)))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "# 최적 하이퍼파라미터 확인\n",
    "print(\"Best Parameters Found:\")\n",
    "print(random_result.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75159df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Fitting 2 folds for each of 600 candidates, totalling 1200 fits\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.9275\u001b[0m        \u001b[32m0.2238\u001b[0m       \u001b[35m0.9356\u001b[0m        \u001b[31m0.2006\u001b[0m  1.5231\n",
      "      2       0.9341        \u001b[32m0.2059\u001b[0m       \u001b[35m0.9350\u001b[0m        \u001b[31m0.1998\u001b[0m  1.4516\n",
      "      3       0.9344        \u001b[32m0.2054\u001b[0m       0.9362        \u001b[31m0.1970\u001b[0m  1.3742\n",
      "      4       0.9353        \u001b[32m0.2037\u001b[0m       0.9361        \u001b[31m0.1948\u001b[0m  1.3873\n",
      "      5       0.9356        \u001b[32m0.2022\u001b[0m       0.9369        0.1955  1.3822\n",
      "      6       0.9356        \u001b[32m0.2015\u001b[0m       0.9371        0.1964  1.4182\n",
      "      7       0.9365        \u001b[32m0.2001\u001b[0m       0.9359        0.1970  1.3885\n",
      "      8       0.9356        0.2003       0.9365        0.1962  1.3784\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "Accuracy: 0.9350\n",
      "Precision: 0.9529\n",
      "Recall: 0.9298\n",
      "F1 Score: 0.9412\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9134    0.9415    0.9272      6327\n",
      "         1.0     0.9529    0.9298    0.9412      8052\n",
      "\n",
      "    accuracy                         0.9350     14379\n",
      "   macro avg     0.9331    0.9357    0.9342     14379\n",
      "weighted avg     0.9355    0.9350    0.9351     14379\n",
      "\n",
      "Best Parameters Found:\n",
      "{'net__optimizer__weight_decay': 0.0, 'net__optimizer': <class 'torch.optim.adam.Adam'>, 'net__module__layers': [16, 8], 'net__module__activation': <class 'torch.nn.modules.activation.ReLU'>, 'net__max_epochs': 30, 'net__lr': 0.01, 'net__batch_size': 64}\n"
     ]
    }
   ],
   "source": [
    "# 랜덤서치 2-600\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import numpy as np\n",
    "from skorch.callbacks import EarlyStopping,EpochScoring\n",
    "\n",
    "# GPU 자동 선택\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# 데이터 준비\n",
    "X = df.drop('churn', axis=1).values.astype(np.float32)\n",
    "y = df['churn'].values.astype(np.float32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# PyTorch 모델 정의 (BCEWithLogitsLoss용)\n",
    "class ChurnModel(nn.Module):\n",
    "    def __init__(self, layers=[64,32,16], activation=nn.ReLU):\n",
    "        super().__init__()\n",
    "        layer_list = []\n",
    "        input_dim = X_train.shape[1]\n",
    "        for l in layers:\n",
    "            layer_list.append(nn.Linear(input_dim, l))\n",
    "            layer_list.append(activation())\n",
    "            input_dim = l\n",
    "        layer_list.append(nn.Linear(input_dim, 1))  # 마지막 Linear\n",
    "        self.network = nn.Sequential(*layer_list)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.network(X).squeeze(1)\n",
    "\n",
    "# skorch 래퍼\n",
    "net = NeuralNetClassifier(\n",
    "    module=ChurnModel,\n",
    "    max_epochs=10,\n",
    "    lr=0.001,\n",
    "    batch_size=32,\n",
    "    optimizer=optim.Adam,\n",
    "    criterion=nn.BCEWithLogitsLoss,\n",
    "    iterator_train__shuffle=True,\n",
    "    device=device,\n",
    "    callbacks=[EarlyStopping(patience=5), # 개선 없으면 학습 중단\n",
    "        EpochScoring('accuracy', on_train=True, name='train_acc'),\n",
    "        EpochScoring('accuracy', on_train=False, name='valid_acc')\n",
    "    ],\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# 파이프라인 생성\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('net', net)\n",
    "])\n",
    "\n",
    "# 랜덤서치할 파라미터\n",
    "param_dist = {\n",
    "    'net__module__layers': [[16, 8], [16, 8, 4], [16, 8, 16], [16, 32, 16], [64, 32], [64, 32, 16], [64, 32, 64], [128, 64, 32]],\n",
    "    'net__module__activation': [nn.ReLU, nn.Tanh],\n",
    "    'net__optimizer': [optim.Adam, optim.SGD],\n",
    "    'net__lr': [0.001, 0.01, 0.1],\n",
    "    'net__optimizer__weight_decay': [0.0, 0.0001, 0.001],\n",
    "    'net__batch_size': [256, 64, 128],\n",
    "    'net__max_epochs': [10, 20, 30]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter= 600,\n",
    "    cv=2,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# RandomizedSearchCV 학습\n",
    "random_result = random_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적 모델로 예측\n",
    "best_model = random_result.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# classification metrics\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Precision: {:.4f}\".format(precision_score(y_test, y_pred)))\n",
    "print(\"Recall: {:.4f}\".format(recall_score(y_test, y_pred)))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_score(y_test, y_pred)))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "# 최적 하이퍼파라미터 확인\n",
    "print(\"Best Parameters Found:\")\n",
    "print(random_result.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ded2bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Fitting 2 folds for each of 150 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "286 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\classifier.py\", line 168, in fit\n",
      "    return super(NeuralNetClassifier, self).fit(X, y, **fit_params)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1351, in fit\n",
      "    self.partial_fit(X, y, **fit_params)\n",
      "    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1310, in partial_fit\n",
      "    self.fit_loop(X, y, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1222, in fit_loop\n",
      "    self.run_single_epoch(iterator_train, training=True, prefix=\"train\",\n",
      "    ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                          step_fn=self.train_step, **fit_params)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1258, in run_single_epoch\n",
      "    step = step_fn(batch, **fit_params)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1137, in train_step\n",
      "    self._step_optimizer(step_fn)\n",
      "    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1092, in _step_optimizer\n",
      "    optimizer.step(step_fn)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py\", line 517, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py\", line 82, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\optim\\sgd.py\", line 127, in step\n",
      "    sgd(\n",
      "    ~~~^\n",
      "        params,\n",
      "        ^^^^^^^\n",
      "    ...<12 lines>...\n",
      "        found_inf=getattr(self, \"found_inf\", None),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\optim\\sgd.py\", line 304, in sgd\n",
      "    func(\n",
      "    ~~~~^\n",
      "        params,\n",
      "        ^^^^^^^\n",
      "    ...<10 lines>...\n",
      "        found_inf=found_inf,\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\optim\\sgd.py\", line 466, in _multi_tensor_sgd\n",
      "    torch._foreach_add_(device_params, device_grads, alpha=-lr)\n",
      "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.AcceleratorError: CUDA error: out of memory\n",
      "Search for `cudaErrorMemoryAllocation' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\classifier.py\", line 168, in fit\n",
      "    return super(NeuralNetClassifier, self).fit(X, y, **fit_params)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1351, in fit\n",
      "    self.partial_fit(X, y, **fit_params)\n",
      "    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1310, in partial_fit\n",
      "    self.fit_loop(X, y, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1222, in fit_loop\n",
      "    self.run_single_epoch(iterator_train, training=True, prefix=\"train\",\n",
      "    ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                          step_fn=self.train_step, **fit_params)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1258, in run_single_epoch\n",
      "    step = step_fn(batch, **fit_params)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1137, in train_step\n",
      "    self._step_optimizer(step_fn)\n",
      "    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1092, in _step_optimizer\n",
      "    optimizer.step(step_fn)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py\", line 517, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py\", line 82, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py\", line 247, in step\n",
      "    adam(\n",
      "    ~~~~^\n",
      "        params_with_grad,\n",
      "        ^^^^^^^^^^^^^^^^^\n",
      "    ...<19 lines>...\n",
      "        decoupled_weight_decay=group[\"decoupled_weight_decay\"],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py\", line 150, in maybe_fallback\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py\", line 953, in adam\n",
      "    func(\n",
      "    ~~~~^\n",
      "        params,\n",
      "        ^^^^^^^\n",
      "    ...<17 lines>...\n",
      "        decoupled_weight_decay=decoupled_weight_decay,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py\", line 684, in _multi_tensor_adam\n",
      "    device_grads = torch._foreach_add(  # type: ignore[assignment]\n",
      "        device_grads, device_params, alpha=weight_decay\n",
      "    )\n",
      "torch.AcceleratorError: CUDA error: out of memory\n",
      "Search for `cudaErrorMemoryAllocation' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "61 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\classifier.py\", line 168, in fit\n",
      "    return super(NeuralNetClassifier, self).fit(X, y, **fit_params)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1351, in fit\n",
      "    self.partial_fit(X, y, **fit_params)\n",
      "    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1310, in partial_fit\n",
      "    self.fit_loop(X, y, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1222, in fit_loop\n",
      "    self.run_single_epoch(iterator_train, training=True, prefix=\"train\",\n",
      "    ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                          step_fn=self.train_step, **fit_params)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1258, in run_single_epoch\n",
      "    step = step_fn(batch, **fit_params)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1137, in train_step\n",
      "    self._step_optimizer(step_fn)\n",
      "    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1092, in _step_optimizer\n",
      "    optimizer.step(step_fn)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py\", line 517, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py\", line 82, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\optim\\sgd.py\", line 116, in step\n",
      "    loss = closure()\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1126, in step_fn\n",
      "    step = self.train_step_single(batch, **fit_params)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1027, in train_step_single\n",
      "    loss.backward()\n",
      "    ~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\_tensor.py\", line 625, in backward\n",
      "    torch.autograd.backward(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self, gradient, retain_graph, create_graph, inputs=inputs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "    ~~~~~~~~~~~~~~~~~~~~^\n",
      "        tensors,\n",
      "        ^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "        accumulate_grad=True,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py\", line 841, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        t_outputs, *args, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )  # Calls into the C++ engine to run the backward pass\n",
      "    ^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\classifier.py\", line 168, in fit\n",
      "    return super(NeuralNetClassifier, self).fit(X, y, **fit_params)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1351, in fit\n",
      "    self.partial_fit(X, y, **fit_params)\n",
      "    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1310, in partial_fit\n",
      "    self.fit_loop(X, y, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1222, in fit_loop\n",
      "    self.run_single_epoch(iterator_train, training=True, prefix=\"train\",\n",
      "    ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                          step_fn=self.train_step, **fit_params)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1258, in run_single_epoch\n",
      "    step = step_fn(batch, **fit_params)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1137, in train_step\n",
      "    self._step_optimizer(step_fn)\n",
      "    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1092, in _step_optimizer\n",
      "    optimizer.step(step_fn)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py\", line 517, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py\", line 82, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py\", line 226, in step\n",
      "    loss = closure()\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1126, in step_fn\n",
      "    step = self.train_step_single(batch, **fit_params)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1027, in train_step_single\n",
      "    loss.backward()\n",
      "    ~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\_tensor.py\", line 625, in backward\n",
      "    torch.autograd.backward(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self, gradient, retain_graph, create_graph, inputs=inputs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "    ~~~~~~~~~~~~~~~~~~~~^\n",
      "        tensors,\n",
      "        ^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "        accumulate_grad=True,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py\", line 841, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        t_outputs, *args, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )  # Calls into the C++ engine to run the backward pass\n",
      "    ^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "81 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\classifier.py\", line 168, in fit\n",
      "    return super(NeuralNetClassifier, self).fit(X, y, **fit_params)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1351, in fit\n",
      "    self.partial_fit(X, y, **fit_params)\n",
      "    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1310, in partial_fit\n",
      "    self.fit_loop(X, y, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1222, in fit_loop\n",
      "    self.run_single_epoch(iterator_train, training=True, prefix=\"train\",\n",
      "    ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                          step_fn=self.train_step, **fit_params)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1258, in run_single_epoch\n",
      "    step = step_fn(batch, **fit_params)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1137, in train_step\n",
      "    self._step_optimizer(step_fn)\n",
      "    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1092, in _step_optimizer\n",
      "    optimizer.step(step_fn)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py\", line 517, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py\", line 82, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py\", line 226, in step\n",
      "    loss = closure()\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1126, in step_fn\n",
      "    step = self.train_step_single(batch, **fit_params)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1027, in train_step_single\n",
      "    loss.backward()\n",
      "    ~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\_tensor.py\", line 625, in backward\n",
      "    torch.autograd.backward(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self, gradient, retain_graph, create_graph, inputs=inputs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "    ~~~~~~~~~~~~~~~~~~~~^\n",
      "        tensors,\n",
      "        ^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "        accumulate_grad=True,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py\", line 841, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        t_outputs, *args, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )  # Calls into the C++ engine to run the backward pass\n",
      "    ^\n",
      "torch.AcceleratorError: CUDA error: out of memory\n",
      "Search for `cudaErrorMemoryAllocation' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "55 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\classifier.py\", line 168, in fit\n",
      "    return super(NeuralNetClassifier, self).fit(X, y, **fit_params)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1351, in fit\n",
      "    self.partial_fit(X, y, **fit_params)\n",
      "    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1310, in partial_fit\n",
      "    self.fit_loop(X, y, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1222, in fit_loop\n",
      "    self.run_single_epoch(iterator_train, training=True, prefix=\"train\",\n",
      "    ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                          step_fn=self.train_step, **fit_params)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1258, in run_single_epoch\n",
      "    step = step_fn(batch, **fit_params)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1137, in train_step\n",
      "    self._step_optimizer(step_fn)\n",
      "    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1092, in _step_optimizer\n",
      "    optimizer.step(step_fn)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py\", line 517, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py\", line 82, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\optim\\sgd.py\", line 116, in step\n",
      "    loss = closure()\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1126, in step_fn\n",
      "    step = self.train_step_single(batch, **fit_params)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1027, in train_step_single\n",
      "    loss.backward()\n",
      "    ~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\_tensor.py\", line 625, in backward\n",
      "    torch.autograd.backward(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self, gradient, retain_graph, create_graph, inputs=inputs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "    ~~~~~~~~~~~~~~~~~~~~^\n",
      "        tensors,\n",
      "        ^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "        accumulate_grad=True,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py\", line 841, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        t_outputs, *args, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )  # Calls into the C++ engine to run the backward pass\n",
      "    ^\n",
      "torch.AcceleratorError: CUDA error: out of memory\n",
      "Search for `cudaErrorMemoryAllocation' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\classifier.py\", line 168, in fit\n",
      "    return super(NeuralNetClassifier, self).fit(X, y, **fit_params)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1351, in fit\n",
      "    self.partial_fit(X, y, **fit_params)\n",
      "    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1310, in partial_fit\n",
      "    self.fit_loop(X, y, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1222, in fit_loop\n",
      "    self.run_single_epoch(iterator_train, training=True, prefix=\"train\",\n",
      "    ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                          step_fn=self.train_step, **fit_params)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1258, in run_single_epoch\n",
      "    step = step_fn(batch, **fit_params)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1137, in train_step\n",
      "    self._step_optimizer(step_fn)\n",
      "    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1092, in _step_optimizer\n",
      "    optimizer.step(step_fn)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py\", line 517, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py\", line 82, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\optim\\sgd.py\", line 127, in step\n",
      "    sgd(\n",
      "    ~~~^\n",
      "        params,\n",
      "        ^^^^^^^\n",
      "    ...<12 lines>...\n",
      "        found_inf=getattr(self, \"found_inf\", None),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\optim\\sgd.py\", line 304, in sgd\n",
      "    func(\n",
      "    ~~~~^\n",
      "        params,\n",
      "        ^^^^^^^\n",
      "    ...<10 lines>...\n",
      "        found_inf=found_inf,\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\optim\\sgd.py\", line 424, in _multi_tensor_sgd\n",
      "    device_grads = torch._foreach_add(  # type: ignore[assignment]\n",
      "        device_grads, device_params, alpha=weight_decay\n",
      "    )\n",
      "torch.AcceleratorError: CUDA error: out of memory\n",
      "Search for `cudaErrorMemoryAllocation' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\classifier.py\", line 168, in fit\n",
      "    return super(NeuralNetClassifier, self).fit(X, y, **fit_params)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1351, in fit\n",
      "    self.partial_fit(X, y, **fit_params)\n",
      "    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1310, in partial_fit\n",
      "    self.fit_loop(X, y, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1222, in fit_loop\n",
      "    self.run_single_epoch(iterator_train, training=True, prefix=\"train\",\n",
      "    ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                          step_fn=self.train_step, **fit_params)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1258, in run_single_epoch\n",
      "    step = step_fn(batch, **fit_params)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1137, in train_step\n",
      "    self._step_optimizer(step_fn)\n",
      "    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1092, in _step_optimizer\n",
      "    optimizer.step(step_fn)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py\", line 517, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py\", line 82, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py\", line 226, in step\n",
      "    loss = closure()\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1126, in step_fn\n",
      "    step = self.train_step_single(batch, **fit_params)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1025, in train_step_single\n",
      "    y_pred = self.infer(Xi, **fit_params)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\skorch\\net.py\", line 1553, in infer\n",
      "    return self.module_(x, **fit_params)\n",
      "           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_16316\\535915590.py\", line 37, in forward\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 250, in forward\n",
      "    input = module(input)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 134, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\USER\\Desktop\\프로젝트2\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [       nan 0.93448436 0.93361499        nan        nan        nan\n",
      "        nan 0.92615587        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.92412139\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.9307\u001b[0m        \u001b[32m0.2192\u001b[0m       \u001b[35m0.9356\u001b[0m        \u001b[31m0.2000\u001b[0m  0.9607\n",
      "      2       0.9338        \u001b[32m0.2083\u001b[0m       0.9363        \u001b[31m0.1990\u001b[0m  0.8904\n",
      "      3       0.9339        \u001b[32m0.2067\u001b[0m       0.9359        0.2000  0.9135\n",
      "      4       0.9344        \u001b[32m0.2058\u001b[0m       \u001b[35m0.9352\u001b[0m        0.2013  0.9010\n",
      "      5       0.9344        0.2063       \u001b[35m0.9346\u001b[0m        0.1998  0.9279\n",
      "      6       0.9341        \u001b[32m0.2048\u001b[0m       0.9371        \u001b[31m0.1980\u001b[0m  0.9048\n",
      "      7       0.9343        0.2055       0.9350        0.2040  0.9126\n",
      "      8       0.9346        \u001b[32m0.2042\u001b[0m       0.9370        0.1995  0.9302\n",
      "      9       0.9345        0.2042       0.9368        \u001b[31m0.1955\u001b[0m  0.8867\n",
      "     10       0.9348        \u001b[32m0.2036\u001b[0m       0.9366        0.1990  0.9257\n",
      "Accuracy: 0.9337\n",
      "Precision: 0.9473\n",
      "Recall: 0.9334\n",
      "F1 Score: 0.9403\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9168    0.9339    0.9253      6327\n",
      "         1.0     0.9473    0.9334    0.9403      8052\n",
      "\n",
      "    accuracy                         0.9337     14379\n",
      "   macro avg     0.9321    0.9337    0.9328     14379\n",
      "weighted avg     0.9339    0.9337    0.9337     14379\n",
      "\n",
      "Best Parameters Found:\n",
      "{'net__optimizer__weight_decay': 0.0001, 'net__optimizer': <class 'torch.optim.adam.Adam'>, 'net__module__layers': [64, 32], 'net__module__activation': <class 'torch.nn.modules.activation.Tanh'>, 'net__max_epochs': 10, 'net__lr': 0.01, 'net__batch_size': 128}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 랜덤서치 2 150\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import numpy as np\n",
    "from skorch.callbacks import EarlyStopping,EpochScoring\n",
    "\n",
    "# GPU 자동 선택\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# 데이터 준비\n",
    "X = df.drop('churn', axis=1).values.astype(np.float32)\n",
    "y = df['churn'].values.astype(np.float32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# PyTorch 모델 정의 (BCEWithLogitsLoss용)\n",
    "class ChurnModel(nn.Module):\n",
    "    def __init__(self, layers=[64,32,16], activation=nn.ReLU):\n",
    "        super().__init__()\n",
    "        layer_list = []\n",
    "        input_dim = X_train.shape[1]\n",
    "        for l in layers:\n",
    "            layer_list.append(nn.Linear(input_dim, l))\n",
    "            layer_list.append(activation())\n",
    "            input_dim = l\n",
    "        layer_list.append(nn.Linear(input_dim, 1))  # 마지막 Linear\n",
    "        self.network = nn.Sequential(*layer_list)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.network(X).squeeze(1)\n",
    "\n",
    "# skorch net\n",
    "net = NeuralNetClassifier(\n",
    "    module=ChurnModel,\n",
    "    max_epochs=20,         # 최대 epoch 줄임\n",
    "    lr=0.001,\n",
    "    batch_size=64,         # 배치 크기 늘림\n",
    "    optimizer=optim.Adam,\n",
    "    criterion=nn.BCEWithLogitsLoss,\n",
    "    iterator_train__shuffle=True,\n",
    "    device=device,\n",
    "    callbacks=[EarlyStopping(patience=5), # 개선 없으면 학습 중단\n",
    "        EpochScoring('accuracy', on_train=True, name='train_acc'),\n",
    "        EpochScoring('accuracy', on_train=False, name='valid_acc')\n",
    "    ],\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# 파이프라인 생성\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('net', net)\n",
    "])\n",
    "\n",
    "# 랜덤서치할 파라미터\n",
    "param_dist = {\n",
    "    'net__module__layers': [[16, 8], [16, 8, 4], [16, 8, 16], [16, 32, 16], [64, 32], [64, 32, 16], [64, 32, 64], [128, 64, 32]],\n",
    "    'net__module__activation': [nn.ReLU, nn.Tanh],\n",
    "    'net__optimizer': [optim.Adam, optim.SGD],\n",
    "    'net__lr': [0.001, 0.01, 0.1],\n",
    "    'net__optimizer__weight_decay': [0.0, 0.0001, 0.001],\n",
    "    'net__batch_size': [256, 64, 128],\n",
    "    'net__max_epochs': [10, 20, 30]\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=150,           # 500 -> 150으로 줄임\n",
    "    cv=2,                 # 3-fold -> 2-fold\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# RandomizedSearchCV 학습\n",
    "random_result = random_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적 모델로 예측\n",
    "best_model = random_result.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# classification metrics\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Precision: {:.4f}\".format(precision_score(y_test, y_pred)))\n",
    "print(\"Recall: {:.4f}\".format(recall_score(y_test, y_pred)))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_score(y_test, y_pred)))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "# 최적 하이퍼파라미터 확인\n",
    "print(\"Best Parameters Found:\")\n",
    "print(random_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54670417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "# best_model 가져오기\n",
    "best_model = random_result.best_estimator_\n",
    "\n",
    "# skorch history 접근\n",
    "history = best_model.named_steps['net'].history\n",
    "\n",
    "# epoch별 train/valid loss, accuracy\n",
    "train_loss = [h['train_loss'] for h in history]\n",
    "valid_loss = [h['valid_loss'] for h in history]\n",
    "train_acc = [h['train_acc'] for h in history if 'train_acc' in h]\n",
    "valid_acc = [h['valid_acc'] for h in history if 'valid_acc' in h]\n",
    "epochs = range(1, len(train_loss)+1)\n",
    "\n",
    "# 손실값 시각화\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(epochs, train_loss, label='Train Loss')\n",
    "plt.plot(epochs, valid_loss, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 정확도 시각화\n",
    "if train_acc and valid_acc:\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(epochs, train_acc, label='Train Accuracy')\n",
    "    plt.plot(epochs, valid_acc, label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training & Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
